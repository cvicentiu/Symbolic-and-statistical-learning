<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML><HEAD><TITLE>LING 188 / LING 288 / CS 224U: Natural Language Understanding</TITLE>
<META http-equiv=Content-Type content="text/html; charset=iso-8859-1">
<META http-equiv=Pragma content=no-cache>
<META http-equiv=Expires content=-1>
<META http-equiv=Pragma content=no-cache>
<META http-equiv=Expires content=-1>
<META content="MSHTML 6.00.2800.1458" name=GENERATOR></HEAD>
<BODY style="BACKGROUND-COLOR: rgb(255,255,255)" vLink=#cc0000 link=#990000>
<TABLE borderColor=#990000 width="100%" border=7>
  <TBODY>
  <TR>
    <TD borderColor=#ffffff><IMG style="WIDTH: 160px; HEIGHT: 140px" alt="" 
      src="ConversationSeat.jpg"></TD>
    <TD borderColor=#ffffff width="100%">
      <BLOCKQUOTE>
        <P><FONT size=+2><STRONG><FONT color=#000000>LING 188 / LING 288 / CS 224U</FONT>
</STRONG></FONT><FONT color=#000000><STRONG><BR><FONT 
        size=+2>Natural Language Understanding</FONT>
<BR><FONT size=+2>Winter 2006 </FONT></STRONG></FONT><FONT 
        color=#990000><STRONG><FONT 
      size=+2></FONT></STRONG></FONT></P></BLOCKQUOTE></TD></TR></TBODY></TABLE>
<P>
<TABLE cellSpacing=2 cellPadding=5 width="100%" border=2>
  <TBODY>
  <TR bgColor=#990000>
    <TD>
      <DIV align=left><FONT color=#ffffff size=+2><STRONG>PROJECT IDEAS</STRONG></FONT></DIV></TD></TR>

  <TR>
<TD> 
        
The final project: a research project, where cross-disciplinary research is encouraged; form groups of 2-3 people, strive for 
a combination of people from different backgrounds (linguistics / statistical / logic) and levels. Dates:
 <ul>
  <li>January 24: think what project you want to do.
  <li>January 26: submit a one paragraph description of the project you want to do.
  <li>February 2: submit a list of 5 papers you will write about in your literature review.
  <li>February 13: submit a 15-page double spaced literature review of about 5 papers that are relevant for your project.
  <li>February 20 (noon): submit a one page project description,
outlining the details of your project goal(s), the methods to be used, and perhaps dated milestones to help you plan your 
work.
  <li>March 14/16: project presentation in class.
  <li>March 20: final project due at 5pm.
 </ul>

You may come up with your own topic (with our approval) or select from the list
of projects below. 

</td>
</tr>

  <TR bgColor=#990000>
    <TD>
      <DIV align=left><FONT color=#ffffff size=+2><STRONG>General</STRONG></FONT></DIV></TD></TR>

<tr><td>

Implement just about any paper we've read about. This is a good way to understand a paper in depth.
(Not publishable, unless your system has better performance).

<p>Or combine the ideas of two or more papers. (Potentially publishable, depending on the work).

</td></tr>

  <TR bgColor=#990000>
    <TD>
      <DIV align=left><FONT color=#ffffff size=+2><STRONG>Lexical Semantics</STRONG></FONT></DIV></TD></TR>

<tr><td>

<b>Verb and Noun Similarity</b>

<p>This is a research idea which is a sub-project of the Robust Textual Inference research
group with Chris Manning and Dan Jurafsky.
The idea is to build a word similarity metric which specifically
works for verbs and the nouns that are built from them (nominalizations).
Recall that Dekang Lin's similarity  metric was verb-verb or noun-noun.
There is a new resource called NomBank just released that could help with this.
<p>(Potentially publishable)
</td></tr>
<tr><td>

<b>Applying FrameNet parsing to improve Textual Inference or Information Extraction</b>

<p>Applying a framenet parser (a classifier that assigns framenet roles
to the constituents in a setence) to try to improve other NLP aplications.

<p>(Potentially publishable)
</td></tr>
<tr><td>


<b>Sense Relations</b>

<p>Design an algorithm to distinguish
polysemy from homonymy

<p>(Potentially publishable)


</td></tr>

<tr><td>

<b>Word Sense Disambiguation</b>

<p>Implement a word sense
disambiguation algorithm.

<p>(Potentially publishable)

</td></tr>


<tr>
<td>
<b>The Class Notes project</b>

<p>Daniel McFarland of the Education
School has a project involving a large
corpus of "class notes" that people
saved and typed in from high school
(pre-SMS). He has some ideas about
using LSA to cluster the notes and
explore other semantic aspects.

<p>(Potentially publishable)

</td></tr>

<tr><td>

<b>Semantic Role Parser</b>

<p>Implement and/or extend
Semantic Role parsers in English
or Chinese.

<p>(Probably not publishable)

</td></tr>

<tr><td>

<b>Semantic Role Parser + CYC</b>

<p>Integrate CYC with a semantic role
parser.

<p>(Potentially publishable)

</td></tr>

<tr><td>

<b>Understanding for a Stanford Robot</b>

<p>To work together with students working with Andrew Ng and Dan Jurafsky,
some of whom are in this class, to design
the natural language interface to the new Stanford Robot STAIR.

<p>(Potentially publishable)
</td></tr>
<tr><td>

<b>Inducing Complex Lexical Semantic Knowledge</b>

<ol>
 <li>
Induce framenet-style semantic frames.
 <li>OR:
Induce
from text STRIPS-style preconditions and results for
actions (i.e. figure out that "go from A to B" requires
that you have been at A beforehand, and that you are
at B afterwards).
(This could be part of the Robust Textual Inference project) 
</ol>

(Potentially publishable)

</td></tr>


  <TR bgColor=#990000>
    <TD>
      <DIV align=left><FONT color=#ffffff size=+2><STRONG>Entailment and Inference</STRONG></FONT></DIV></TD></TR>

<TR>
<TD>

<b>Robust Textual Inference</b>

<p>Look at:
<a href="http://www.pascal-network.org/Challenges/RTE2/">
http://www.pascal-network.org/Challenges/RTE2/</a>.

<p>Textual entailment recognition is the task of deciding,
given two text fragments, whether the meaning of one
text is entailed (can be inferred) from another text.

<p>Stanford has a group led by grad student Bill
MacCartney and including students of Chris Manning
and Dan Jurafsky working on textual entailment. There
are various potential projects in improving our current
textual entailment systems.

<p>(Potentially publishable)

</td></tr>

<tr><td>

<b>Precise Textual (Logical) Inference</b>

<p>The task is to determine whether the meaning of one sentence is logically entailed
from one or more premise sentences. This could also be put in terms of answering a question based 
on the information given in the premises.

<p>Example inference:
<br>&nbsp;&nbsp;&nbsp;&nbsp; Not everything that can be counted counts and not everything that counts
can be counted. [Albert Einstein] =>
<br>&nbsp;&nbsp;&nbsp;&nbsp; Something that can be counted does not count and something that counts
cannot be counted.
<!-- <br>(more examples: 
<a href="http://www.cogsci.ed.ac.uk/~fracas/deliverables.html">
deliverable 16, pp 63-120</a>) -->

<p>While this sort of inference will eventually be integrated into robust textual inference, the two projects
currnetly concentrate on different issues.
Logical inference concentrates on high-precision understanding of the meaning of functional 
words from <i>closed</i> syntactic categories 
(quantifiers, determiners, connectives, modals, etc.) as well as of morphological inflections
(e.g. 's' and 'ing' suffixes of nouns and verbs), whereas robust textual inference 
concentrates mostly on the meaning of open category words (nouns, verbs, prepositions, adjectives).
Also, while the robust inference concentrates on just one entailment step, the high-quality nature of 
logical entailment supports a chain of several inference steps, thus allowing to combine
the information from several sentences, and to support complex inference tasks such as solving logic puzzles.

<p>Currently Iddo Lev is working on this research, and there are various potential projects in it (<a 
href="http://www.stanford.edu/class/linguist288/project_more.html">see more info</a>).

<p>(Potentially publishable)



</td></tr>


  <TR bgColor=#990000>
    <TD>
      <DIV align=left><FONT color=#ffffff size=+2><STRONG>Discourse and Coherence</STRONG></FONT></DIV></TD></TR>


<tr><td>

<b>Anaphora / Coreference resolution</b>

<p>Build an anaphora resolution
algorithm or a coreference
algorithm.

<p>(Not publishable)

</td></tr>

<tr><td>

<b>Discovering Rhetorical Relations</b>

<p>Consider the Lapata & Lascarides unsupervised (or
weakly supervised) method for discovering temporal
relations between clauses. Apply this method to do
unsupervised parsing of the rhetorical relations of Wolf
& Gibson.

<p>(Potentially publishable)


</td></tr>


  <TR bgColor=#990000>
    <TD>
      <DIV align=left><FONT color=#ffffff size=+2><STRONG>Dialogue and Conversation</STRONG></FONT></DIV></TD></TR>

<tr><td>
<b>Combining semantically interpreted parse
fragments</b>

<p>A fragment-producing parser and semantic
interpreter are available from a Stanford project on
understanding speech in meetings, as are
transcripts annotated with the correct combination.

<p>(Could be publishable)
</td></tr>


<tr><td>
<b>Classification of utterances (or sequences of them)
as `action items'</b>

<p>Includes the task of identifying which (sequences of)
utterances formulate an action item, and determining
what the components of that action item are (e.g.
person responsible, deadline, what is to be done)

<p>Some feature extractors (from parsed/interpreted
utterances) are available as well as annotated data.

<p>(Potentially publishable)
</td></tr>

<tr><td>
<b>Automating construction of patterns to extract semantic
information from a statistical parser’s output</b>

<p>This could be approached by mapping dependency trees to
frames and/or to dialogue moves (plus database query
constraints where appropriate). One question to answer is
whether and how this is easier to accomplish than mapping
directly from words (plus part-of-speech tags) to frames
and/or dialogue moves/query constraints.

<p>Parser output and annotated data are available.

<p>(Potentially publishable)
</td></tr>

<tr><td>
<b>Salience list and anaphora resolution.</b>

<p>Support anaphoric reference to propositions by including
these in a salience ‘list’ along with other entities, and
implement discourse constraints on resolution of anaphora,
e.g. by enforcing accessibility constraints in terms of
dialogue move trees.

<p>
This could take either an empirical direction (annotate
antecedents from data (some are available) and learn a
strategy), or a theoretical direction (try to integrate notions
from centering theory or RST approaches).

<p>(Potentially publishable, depending on directions taken)
</td></tr>

<tr><td>
<b>Dialogue System</b>

<p>Implement a dialogue system (e.g. a
restaurant recommendation system) as
an activity-based dialogue system.

<p>This would involve defining a sensible
taxonomy of database query tasks, and
developing proper activity models from
specific task scripts.

<p>(Probably not publishable)
</td></tr>

<tr><td>
<b>Determining clarification strategies in dialogue (by
machine learning?)</b>

<p>
This would involve implementing implicit clarification,
determining good thresholds for explicit/implicit
clarification vs. failure, putting together an integrated
confidence score (including ASR confidence, parse
confidence, etc.).

<p>Data are available from dialogues with music player &
restaurant recommendation systems, and others.

<p>(Potentially publishable)
</td></tr>

<tr><td>
<b>Semi-automatic annotation of wizard-of-oz data with dialogue move
trees.</b>

<p>E.g. automatically annotate (perhaps with n-best hypotheses) and
allow manual editing afterwards. Ideally would flag situations with
low-confidence hypotheses as most likely to need manual annotation.
Probably emphasize accuracy of node attachment decisions, possibly
also ranking of options for response generation. A parser test tool is
available as a starting point.

<p>Determining node type choice & attachment strategies (by machine
learning?).

<p>This could use data produced from the project above plus some other
hand-labeled data.

<p>(May not be publishable)
</td></tr>


</TBODY></TABLE></P>

</BODY></HTML>
