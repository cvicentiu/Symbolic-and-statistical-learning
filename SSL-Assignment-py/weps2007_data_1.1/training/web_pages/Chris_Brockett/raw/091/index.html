<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:st1="urn:schemas-microsoft-com:office:smarttags"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=big5">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 10">
<meta name=Originator content="Microsoft Word 10">
<link rel=File-List href="http://www.cs.cornell.edu/~ves/ACL2006schedule/Abstracts%20by%20Session%2004_files/filelist.xml">
<title>3-Paper</title>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="time"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="PlaceType"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="PlaceName"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="City"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="place"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="stockticker"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="date"/>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>student</o:Author>
  <o:LastAuthor>Veselin Stoyanov</o:LastAuthor>
  <o:Revision>10</o:Revision>
  <o:TotalTime>540</o:TotalTime>
  <o:LastPrinted>2006-06-19T12:24:00Z</o:LastPrinted>
  <o:Created>2006-06-19T16:17:00Z</o:Created>
  <o:LastSaved>2006-06-20T04:27:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>41418</o:Words>
  <o:Characters>236085</o:Characters>
  <o:Company>City University of Hong Kong</o:Company>
  <o:Lines>1967</o:Lines>
  <o:Paragraphs>553</o:Paragraphs>
  <o:CharactersWithSpaces>276950</o:CharactersWithSpaces>
  <o:Version>10.2625</o:Version>
 </o:DocumentProperties>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:HideSpellingErrors/>
  <w:PunctuationKerning/>
  <w:DrawingGridHorizontalSpacing>6 pt</w:DrawingGridHorizontalSpacing>
  <w:DrawingGridVerticalSpacing>8.15 pt</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:DisplayVerticalDrawingGridEvery>2</w:DisplayVerticalDrawingGridEvery>
  <w:Compatibility>
   <w:SpaceForUL/>
   <w:BalanceSingleByteDoubleByteWidth/>
   <w:DoNotLeaveBackslashAlone/>
   <w:ULTrailSpace/>
   <w:DoNotExpandShiftReturn/>
   <w:FootnoteLayoutLikeWW8/>
   <w:ShapeLayoutLikeWW8/>
   <w:AlignTablesRowByRow/>
   <w:ForgetLastTabAlignment/>
   <w:LayoutRawTableWidth/>
   <w:LayoutTableRowsApart/>
   <w:UseWord97LineBreakingRules/>
   <w:UseFELayout/>
  </w:Compatibility>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
 </w:WordDocument>
</xml><![endif]--><!--[if !mso]><object
 classid="clsid:38481807-CA0E-42D2-BF39-B33AF135CC4D" id=ieooui></object>
<style>
st1\:*{behavior:url(#ieooui) }
</style>
<![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Helvetica;
	panose-1:2 11 5 4 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Courier;
	panose-1:2 7 4 9 2 2 5 2 4 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-format:other;
	mso-font-pitch:fixed;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Tms Rmn";
	panose-1:2 2 6 3 4 5 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Helv;
	panose-1:2 11 6 4 2 2 2 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"New York";
	panose-1:2 4 5 3 6 5 6 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:System;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134676480 16 0 131072 0;}
@font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"MS Mincho";
	panose-1:2 2 6 9 4 2 5 8 3 4;
	mso-font-alt:"MS Mincho";
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-pitch:fixed;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:Batang;
	panose-1:2 3 6 0 0 1 1 1 1 1;
	mso-font-alt:Batang;
	mso-font-charset:129;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-alt:SimSun;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 135135232 16 0 262145 0;}
@font-face
	{font-family:PMingLiU;
	panose-1:2 2 3 0 0 0 0 0 0 0;
	mso-font-alt:PMingLiU;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 137232384 22 0 1048577 0;}
@font-face
	{font-family:"MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;
	mso-font-alt:"MS Gothic";
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:Dotum;
	panose-1:2 11 6 0 0 1 1 1 1 1;
	mso-font-alt:Dotum;
	mso-font-charset:129;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:SimHei;
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-alt:SimHei;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:1 135135232 16 0 262144 0;}
@font-face
	{font-family:MingLiU;
	panose-1:2 2 3 9 0 0 0 0 0 0;
	mso-font-alt:MingLiU;
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:3 137232384 22 0 1048577 0;}
@font-face
	{font-family:Mincho;
	panose-1:2 2 6 9 4 3 5 8 3 5;
	mso-font-alt:Mincho;
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:fixed;
	mso-font-signature:1 134676480 16 0 131072 0;}
@font-face
	{font-family:Gulim;
	panose-1:2 11 6 0 0 1 1 1 1 1;
	mso-font-alt:Gulim;
	mso-font-charset:129;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:Century;
	panose-1:2 4 6 4 5 5 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Angsana New";
	panose-1:2 2 6 3 5 4 5 2 3 4;
	mso-font-charset:222;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:16777217 0 0 0 65536 0;}
@font-face
	{font-family:"Cordia New";
	panose-1:2 11 3 4 2 2 2 2 2 4;
	mso-font-charset:222;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:16777217 0 0 0 65536 0;}
@font-face
	{font-family:Mangal;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:32771 0 0 0 1 0;}
@font-face
	{font-family:Latha;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:1048579 0 0 0 1 0;}
@font-face
	{font-family:Sylfaen;
	panose-1:1 10 5 2 5 3 6 3 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:67110535 0 0 0 159 0;}
@font-face
	{font-family:Vrinda;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Raavi;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:131075 0 0 0 1 0;}
@font-face
	{font-family:Shruti;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:262147 0 0 0 1 0;}
@font-face
	{font-family:Sendnya;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Gautami;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:2097155 0 0 0 1 0;}
@font-face
	{font-family:Tunga;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:4194307 0 0 0 1 0;}
@font-face
	{font-family:"Estrangella Edessa";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:"Arial Unicode MS";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:1627421319 -2147483648 8 0 66047 0;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:\5168\771F\7C97\9ED1\9AD4;
	mso-font-alt:"Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:"\@PMingLiU";
	panose-1:2 2 3 0 0 0 0 0 0 0;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 137232384 22 0 1048577 0;}
@font-face
	{font-family:"\@SimSun";
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 135135232 16 0 262145 0;}
@font-face
	{font-family:"\@\5168\771F\7C97\9ED1\9AD4";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:"\@MingLiU";
	panose-1:2 2 3 9 0 0 0 0 0 0;
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:3 137232384 22 0 1048577 0;}
@font-face
	{font-family:Marlett;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Lucida Console";
	panose-1:2 11 6 9 4 5 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147482993 6144 0 0 31 0;}
@font-face
	{font-family:"Lucida Sans Unicode";
	panose-1:2 11 6 2 3 5 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147476737 14699 0 0 63 0;}
@font-face
	{font-family:Verdana;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:536871559 0 0 0 415 0;}
@font-face
	{font-family:"Arial Black";
	panose-1:2 11 10 4 2 1 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Comic Sans MS";
	panose-1:3 15 7 2 3 3 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Impact;
	panose-1:2 11 8 6 3 9 2 5 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Georgia;
	panose-1:2 4 5 2 5 4 5 2 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Franklin Gothic Medium";
	panose-1:2 11 6 3 2 1 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Palatino Linotype";
	panose-1:2 4 5 2 5 5 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870009 1073741843 0 0 415 0;}
@font-face
	{font-family:"Trebuchet MS";
	panose-1:2 11 6 3 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Webdings;
	panose-1:5 3 1 2 1 5 9 6 7 3;
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Estrangelo Edessa";
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:-2147459005 0 128 0 1 0;}
@font-face
	{font-family:"MV Boli";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 0 256 0 1 0;}
@font-face
	{font-family:"Microsoft Sans Serif";
	panose-1:2 11 6 4 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:553679495 -2147483648 8 0 66047 0;}
@font-face
	{font-family:"Arial Narrow";
	panose-1:2 11 5 6 2 2 2 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Bookman Old Style";
	panose-1:2 5 6 4 5 5 5 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Garamond;
	panose-1:2 2 4 4 3 3 1 1 8 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"MS Outlook";
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Monotype Corsiva";
	panose-1:3 1 1 1 1 2 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:HE_TERMINAL;
	panose-1:2 11 6 9 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Century Gothic";
	panose-1:2 11 5 2 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Haettenschweiler;
	panose-1:2 11 7 6 4 9 2 6 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Wingdings 2";
	panose-1:5 2 1 2 1 5 7 7 7 7;
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Wingdings 3";
	panose-1:5 4 1 2 1 8 7 7 7 7;
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"MS Mincho";
	panose-1:2 2 6 9 4 2 5 8 3 4;
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-pitch:fixed;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:"MS PMincho";
	panose-1:2 2 6 0 4 2 5 8 3 4;
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:"MS PMincho";
	panose-1:2 2 6 0 4 2 5 8 3 4;
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:"MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:"MS PGothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:"MS PGothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:"MS UI Gothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:"\@MS UI Gothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 1757936891 16 0 131231 0;}
@font-face
	{font-family:"\@Gulim";
	panose-1:2 11 6 0 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:GulimChe;
	panose-1:2 11 6 9 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@GulimChe";
	panose-1:2 11 6 9 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@Dotum";
	panose-1:2 11 6 0 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:DotumChe;
	panose-1:2 11 6 9 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@DotumChe";
	panose-1:2 11 6 9 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@Batang";
	panose-1:2 3 6 0 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:BatangChe;
	panose-1:2 3 6 9 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@BatangChe";
	panose-1:2 3 6 9 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:Gungsuh;
	panose-1:2 3 6 0 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@Gungsuh";
	panose-1:2 3 6 0 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:GungsuhChe;
	panose-1:2 3 6 9 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@GungsuhChe";
	panose-1:2 3 6 9 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:NSimSun;
	panose-1:2 1 6 9 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:3 135135232 16 0 262145 0;}
@font-face
	{font-family:"\@NSimSun";
	panose-1:2 1 6 9 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:3 135135232 16 0 262145 0;}
@font-face
	{font-family:"\@SimHei";
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:1 135135232 16 0 262144 0;}
@font-face
	{font-family:"Myriad Web Pro";
	panose-1:2 11 5 3 3 4 3 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483601 1342185546 0 0 147 0;}
@font-face
	{font-family:"Myriad Web Pro Condensed";
	panose-1:2 11 5 6 3 4 3 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483601 1342185546 0 0 147 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
h1
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:12.0pt;
	margin-left:0in;
	text-align:center;
	page-break-before:always;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	font-size:12.0pt;
	mso-bidi-font-size:16.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-font-family:Arial;
	mso-font-kerning:16.0pt;
	mso-ansi-language:EN-AU;
	mso-fareast-language:EN-US;}
h2
	{mso-style-next:Normal;
	margin-top:6.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	mso-pagination:none;
	page-break-after:avoid;
	mso-outline-level:2;
	border:none;
	mso-border-alt:solid windowtext .5pt;
	padding:0in;
	mso-padding-alt:1.0pt 4.0pt 1.0pt 4.0pt;
	font-size:11.0pt;
	mso-bidi-font-size:14.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:Arial;
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;
	mso-bidi-font-style:italic;}
h3
	{mso-style-next:Normal;
	margin-top:6.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	mso-pagination:none;
	page-break-after:avoid;
	mso-outline-level:3;
	border:none;
	mso-border-bottom-alt:solid windowtext .5pt;
	padding:0in;
	mso-padding-alt:0in 0in 1.0pt 0in;
	font-size:11.0pt;
	mso-bidi-font-size:13.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:Arial;
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
h4
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	mso-pagination:none;
	page-break-after:avoid;
	mso-outline-level:4;
	font-size:11.0pt;
	mso-bidi-font-size:14.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:PMingLiU;
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex1, li.MsoIndex1, div.MsoIndex1
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex2, li.MsoIndex2, div.MsoIndex2
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:24.0pt;
	margin-bottom:.0001pt;
	text-indent:-12.0pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex3, li.MsoIndex3, div.MsoIndex3
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	margin-bottom:.0001pt;
	text-indent:-12.0pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex4, li.MsoIndex4, div.MsoIndex4
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:48.0pt;
	margin-bottom:.0001pt;
	text-indent:-12.0pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex5, li.MsoIndex5, div.MsoIndex5
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:60.0pt;
	margin-bottom:.0001pt;
	text-indent:-12.0pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex6, li.MsoIndex6, div.MsoIndex6
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:1.0in;
	margin-bottom:.0001pt;
	text-indent:-12.0pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex7, li.MsoIndex7, div.MsoIndex7
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:84.0pt;
	margin-bottom:.0001pt;
	text-indent:-12.0pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex8, li.MsoIndex8, div.MsoIndex8
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:96.0pt;
	margin-bottom:.0001pt;
	text-indent:-12.0pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndex9, li.MsoIndex9, div.MsoIndex9
	{mso-style-update:auto;
	mso-style-noshow:yes;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:1.5in;
	margin-bottom:.0001pt;
	text-indent:-12.0pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:none;
	tab-stops:center 207.65pt right 415.3pt;
	layout-grid-mode:char;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoFooter, li.MsoFooter, div.MsoFooter
	{margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:none;
	tab-stops:center 207.65pt right 415.3pt;
	layout-grid-mode:char;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoIndexHeading, li.MsoIndexHeading, div.MsoIndexHeading
	{mso-style-noshow:yes;
	mso-style-next:"Index 1";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoListBullet, li.MsoListBullet, div.MsoListBullet
	{mso-style-update:auto;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:.25in;
	text-indent:-.25in;
	mso-pagination:widow-orphan;
	mso-list:l0 level1 lfo3;
	tab-stops:list .25in;
	font-size:11.0pt;
	mso-bidi-font-size:12.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-font-family:"Times New Roman";
	mso-ansi-language:EN-AU;
	mso-fareast-language:EN-US;}
p.MsoBodyText, li.MsoBodyText, div.MsoBodyText
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.MsoPlainText, li.MsoPlainText, div.MsoPlainText
	{margin:0in;
	margin-bottom:.0001pt;
	line-height:18.0pt;
	mso-line-height-rule:exactly;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:MingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.18, li.18, div.18
	{mso-style-name:\7C97\9ED118;
	mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:18.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:\5168\771F\7C97\9ED1\9AD4;
	mso-fareast-language:ZH-TW;
	mso-no-proof:yes;}
p.AbstractTitle, li.AbstractTitle, div.AbstractTitle
	{mso-style-name:"Abstract Title";
	margin:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:none;
	page-break-after:avoid;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:Arial;
	mso-fareast-language:ZH-TW;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.AbstractAuthor, li.AbstractAuthor, div.AbstractAuthor
	{mso-style-name:"Abstract Author";
	mso-style-parent:"Body Text";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:none;
	page-break-after:avoid;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-fareast-language:ZH-TW;}
p.SessionChair, li.SessionChair, div.SessionChair
	{mso-style-name:"Session Chair";
	mso-style-parent:"Body Text";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:none;
	page-break-after:avoid;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-fareast-language:ZH-TW;}
p.PosterAbstractText, li.PosterAbstractText, div.PosterAbstractText
	{mso-style-name:"Poster Abstract Text";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	mso-pagination:none;
	page-break-after:avoid;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:Arial;
	mso-fareast-language:ZH-TW;}
p.SlotAndSpot, li.SlotAndSpot, div.SlotAndSpot
	{mso-style-name:"Slot And Spot";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:9.0pt;
	margin-left:0in;
	mso-pagination:none;
	font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:PMingLiU;
	mso-bidi-font-family:"Times New Roman";
	mso-font-kerning:1.0pt;
	mso-ansi-language:EN-GB;
	mso-fareast-language:ZH-TW;}
ins
	{mso-style-type:export-only;
	text-decoration:none;}
span.msoIns
	{mso-style-type:export-only;
	mso-style-name:"";
	text-decoration:underline;
	text-underline:single;}
span.msoDel
	{mso-style-type:export-only;
	mso-style-name:"";
	text-decoration:line-through;
	color:red;}
 /* Page Definitions */
 @page
	{mso-page-border-surround-header:no;
	mso-page-border-surround-footer:no;
	mso-footnote-separator:url("Abstracts%20by%20Session%2004_files/header.htm") fs;
	mso-footnote-continuation-separator:url("Abstracts%20by%20Session%2004_files/header.htm") fcs;
	mso-endnote-separator:url("Abstracts%20by%20Session%2004_files/header.htm") es;
	mso-endnote-continuation-separator:url("Abstracts%20by%20Session%2004_files/header.htm") ecs;}
@page Section1
	{size:595.35pt 842.0pt;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-footer:url("Abstracts%20by%20Session%2004_files/header.htm") f1;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
@page Section2
	{size:595.35pt 842.0pt;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-columns:2 even .5in;
	mso-footer:url("Abstracts%20by%20Session%2004_files/header.htm") f1;
	mso-paper-source:0;}
div.Section2
	{page:Section2;}
@page Section3
	{size:595.35pt 842.0pt;
	margin:1.0in 1.0in 1.0in 1.0in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-footer:url("Abstracts%20by%20Session%2004_files/header.htm") f1;
	mso-paper-source:0;}
div.Section3
	{page:Section3;}
 /* List Definitions */
 @list l0
	{mso-list-id:-119;
	mso-list-type:simple;
	mso-list-template-ids:-1394032704;}
@list l0:level1
	{mso-level-number-format:bullet;
	mso-level-style-link:"List Bullet";
	mso-level-text:\F0B7;
	mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;
	font-family:Symbol;}
ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";}
</style>
<![endif]-->
</head>

<body lang=EN-US style='tab-interval:24.0pt;text-justify-trim:punctuation'>

<div class=Section1>

<h1><span lang=EN-AU>Main Conference Sessions</span></h1>

<p class=MsoBodyText>All ¡¥A¡¦ sessions are held in the Bayside Auditorium A; ¡¥B¡¦
sessions are in Bayside 103; ¡¥C¡¦ sessions are in Bayside 104; and ¡¥D¡¦ sessions
and the Student Research Workshop sessions are in Bayside 102.</p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><st1:date Year="930" Day="17" Month="7">Monday <span style='font-size:10.0pt;
 mso-bidi-font-size:14.0pt'>17th</span> July 930</st1:date>am¡V1030am</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3>1A: Machine Translation I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></h3>

</div>

<p class=SessionChair>Session Chair: David Chiang<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b1A1></a>Combination of Arabic Preprocessing
Schemes for Statistical Machine Translation</p>

<p class=AbstractAuthor>Fatiha Sadat<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sadat, F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Nizar Habash<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Habash, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Statistical machine
translation is quite robust when it comes to the choice of input
representation. It only requires consistency between training and testing. As a
result, there is a wide range of possible preprocessing choices for data used
in statistical machine translation. This is even more so for morphologically
rich languages such as Arabic. In this paper, we study the effect of different
word-level preprocessing schemes for Arabic on the quality of phrase-based
statistical machine translation. We also present and evaluate different methods
for combining preprocessing schemes resulting in improved translation quality.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b1A2></a>Going Beyond <st1:stockticker>AER</st1:stockticker>:
An Extensive Analysis of Word Alignments and Their Impact on MT</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Necip Fazil
Ayan</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Ayan, N.F.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><span style='mso-spacerun:yes'>&nbsp;</span>and
Bonnie J. Dorr</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Dorr, B.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper presents an
extensive evaluation of five different alignments and investigates their impact
on the corresponding MT system output. We introduce new measures for intrinsic
evaluations and examine the distribution of phrases and untranslated words
during decoding to identify which characteristics of different alignments
affect translation. We show that precision-oriented alignments yield better MT
output (translating more words and using longer phrases) than recall-oriented
alignments.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>1B: Topic
Segmentation<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Martha Palmer<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b1B1></a>Unsupervised Topic Modelling for
Multi-Party Spoken Discourse</p>

<p class=AbstractAuthor>Matthew Purver<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Purver, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Konrad P. K&ouml;rding<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;K&ouml;rding, K.P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Thomas L. Griffiths<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Griffiths, T.L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Joshua B. Tenebaum<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tenebaum, J.B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We present a method for
unsupervised topic modelling which adapts methods used in document
classification (Blei et al., 2003; Griffiths and Steyvers, 2004) to unsegmented
multi-party discourse transcripts. We show how Bayesian inference in this
generative model can be used to simultaneously address the problems of topic
segmentation and topic identification: automatically segmenting multi-party
meetings into topically coherent segments with performance which compares well
with previous unsupervised segmentation-only methods (Galley et al., 2003)
while simultaneously extracting topics which rate highly when assessed for
coherence by human judges. We also show that this method appears robust in the
face of off-topic dialogue and speech recognition errors.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b1B2></a>Minimum Cut Model for Spoken Lecture
Segmentation</p>

<p class=AbstractAuthor>Igor Malioutov<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Malioutov, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and <st1:City><st1:place>Regina</st1:place></st1:City>
Barzilay<!--[if supportFields]><span style='mso-element:field-begin'></span> XE
&quot;Barzilay, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We consider the task of
unsupervised lecture segmentation. We formalize segmentation as a
graph-partitioning task that optimizes the normalized cut criterion. Our
approach moves beyond localized comparisons and takes into account long-range
cohesion dependencies. Our results demonstrate that global analysis improves
the segmentation accuracy and is robust in the presence of speech recognition
errors.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>1C: Coreference<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Vincent Ng<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b1C1></a>Bootstrapping Path-Based Pronoun
Resolution</p>

<p class=AbstractAuthor>Shane Bergsma<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bergsma, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dekang Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
present an approach to pronoun resolution based on syntactic paths. Through a
simple bootstrapping procedure, we learn the likelihood of coreference between
a pronoun and a candidate noun based on the path in the parse tree between the
two entities. This path information enables us to handle previously challenging
resolution instances, and also robustly addresses traditional syntactic
coreference constraints. Highly coreferent paths also allow mining of precise
probabilistic gender/number information. We combine statistical knowledge with
well-known features in a Support Vector Machine pronoun resolution classifier.
Significant gains in performance are observed on several datasets.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b1C2></a>Kernel-Based Pronoun Resolution with
Structured Syntactic Knowledge</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Xiaofeng
Yang</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Yang, X.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'>, Jian Su</span><!--[if supportFields]><span
style='mso-element:field-begin'></span><span lang=FR style='mso-ansi-language:
FR'> XE &quot;Su, J.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><span style='mso-spacerun:yes'>&nbsp;</span>and
Chew Lim Tan</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Tan, C.L.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=MsoBodyText>Syntactic knowledge is important for pronoun resolution. Traditionally,
the syntactic information for pronoun resolution is represented in terms of
features that have to be selected and defined heuristically. In the paper, we
propose a kernel-based method that can automatically mine the syntactic
information from the parse trees for pronoun resolution. Specifically, we
utilize the parse trees directly as a structured feature and apply kernel
functions to this feature, as well as other normal features, to learn the
resolution classifier. In this way, our approach avoids the efforts of decoding
the parse trees into the set of flat syntactic features. The experimental
results show that our approach can bring significant performance improvement
and is reliably effective for the pronoun resolution task.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>1D: Grammars I<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span
style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Martin Kay<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b1D1></a>A Finite-State Model of Human Sentence
Processing</p>

<p class=AbstractAuthor><st1:place><st1:PlaceName>Jihyun</st1:PlaceName> <st1:PlaceType>Park</st1:PlaceType></st1:place><!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Park, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Chris Brew<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Brew, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'>It has previously been assumed in the psycholinguistic literature that
finite-state models of language are crucially limited in their explanatory
power by the locality of the probability distribution and the narrow scope of
information used by the model. We show that a simple computational model (a
bigram part-of-speech tagger based on the design used by Corley and Crocker
(2000) makes correct predictions on processing difficulty observed in a wide
range of empirical sentence processing data.<span
style='mso-spacerun:yes'>&nbsp; </span>We use two modes of evaluation: one that
relies on comparison with a control sentence, paralleling practice in human studies;
another that measures probability drop in the disambiguating region of the
sentence. Both are surprisingly good indicators of the processing difficulty of
garden-path sentences. The sentences tested are drawn from published sources
and systematically explore five different types of ambiguity: previous studies
have been narrower in scope and smaller in scale. We do not deny the
limitations of finite-state models, but argue that our results show that their
usefulness has been underestimated.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b1D2></a>Acceptability Prediction by Means of
Grammaticality Quantification</p>

<p class=AbstractAuthor>Philippe Blache<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Blache, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Barbara Hemforth<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hemforth, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and St&eacute;phane Rauzy<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Rauzy, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We propose in this paper a method for quantifying sentence<span
style='mso-ansi-language:EN-GB'> </span>grammaticality. The approach based on
Property Grammars, a<span style='mso-ansi-language:EN-GB'> </span>constraint-based
syntactic formalism, makes it possible to evaluate<span style='mso-ansi-language:
EN-GB'> </span>a grammaticality index for any kind of sentence, including<span
style='mso-ansi-language:EN-GB'> </span>ill-formed ones. We compare on a sample
of sentences the<span style='mso-ansi-language:EN-GB'> </span>grammaticality
indices obtained from PG formalism and the<span style='mso-ansi-language:EN-GB'>
</span>acceptability judgements measured by means of a psycholinguistic<span
style='mso-ansi-language:EN-GB'> </span>analysis. The results show that the
derived grammaticality index is<span style='mso-ansi-language:EN-GB'> </span>a
fairly good tracer of acceptability scores.<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><st1:date Year="1100" Day="17" Month="7">Monday 17th July 1100</st1:date>am¡V1230pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>2A: M</span>achin<span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>e Translation II<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: David Chiang<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b2A1></a>Discriminative Word Alignment with
Conditional Random Fields</p>

<p class=AbstractAuthor>Phil Blunsom<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Blunsom, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Trevor Cohn<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Cohn, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In this
paper we present a novel approach for inducing word alignments from sentence-aligned
data. We use a Conditional Random Field (CRF), a discriminative model, which is
estimated on a small supervised training set. The CRF is conditioned on both
the source and target texts, and thus allows for the use of arbitrary and
overlapping features over these data. Moreover, the CRF has efficient training
and decoding processes which both find globally optimal solutions.<o:p></o:p></span></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We apply
this alignment model to both French-English and Romanian-English language
pairs. We show how a large number of highly predictive features can be easily
incorporated into the CRF, and demonstrate that even with only a few hundred
word-aligned training sentences, our model improves over the current
state-of-the-art with alignment error rates of 5.29 and 25.8 for the two tasks
respectively.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b2A2></a>Named Entity Transliteration with
Comparable Corpora</p>

<p class=AbstractAuthor>Richard Sproat<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sproat, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Tao Tao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tao, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and ChengXiang Zhai<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhai, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>In this paper we investigate Chinese-English name transliteration
using comparable corpora, corpora where texts in the two languages deal in some
of the same topics --- and therefore share references to named entities --- but
are not translations of each other.<span style='mso-spacerun:yes'>&nbsp;
</span>We present two distinct methods for transliteration, one approach using
phonetic transliteration, and the second using the temporal distribution of
candidate pairs.<span style='mso-spacerun:yes'>&nbsp; </span>Each of these
approaches works quite well, but by combining the approaches one can achieve
even better results. We then propose a novel score propagation method that
utilizes the co-occurrence of transliteration pairs within document pairs. This
propagation method achieves further improvement over the best results from the
previous step.</p>

<p class=AbstractTitle><a name=b2A3></a>Extracting Parallel Sub-Sentential
Fragments from Non-Parallel Corpora</p>

<p class=AbstractAuthor>Dragos Stefan Munteanu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Munteanu, D.S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Daniel Marcu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Marcu, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We present a novel method for extracting parallel
sub-sentential fragments from comparable, non-parallel bilingual corpora. By
analyzing potentially similar sentence pairs using a signal processing-inspired
approach, we detect which segments of the source sentence are translated into
segments in the target sentence, and which are not. This method enables us to
extract useful machine translation training data even from very non-parallel
corpora, which contain no parallel sentence pairs. We evaluate the quality of
the extracted data by showing that it improves the performance of a
state-of-the-art statistical machine translation system.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>2B: Word Sense
Disambiguation I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Martha Palmer<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b2B1></a>Estimating Class Priors in Domain
Adaptation for Word Sense Disambiguation</p>

<p class=AbstractAuthor>Yee Seng Chan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chan, Y.S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hwee Tou Ng<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ng, H.T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Instances of a word drawn from different domains may have different<span
style='mso-ansi-language:EN-GB'> </span>sense priors (the proportions of the
different senses of a word). This<span style='mso-ansi-language:EN-GB'> </span>in
turn affects the accuracy of word sense disambiguation (WSD)<span
style='mso-ansi-language:EN-GB'> </span>systems trained and applied on
different domains. This paper presents<span style='mso-ansi-language:EN-GB'> </span>a
method to estimate the sense priors of words drawn from a new<span
style='mso-ansi-language:EN-GB'> </span>domain, and highlights the importance
of using well-calibrated<span style='mso-ansi-language:EN-GB'> </span>probabilities
when performing these estimations.<span style='mso-spacerun:yes'>&nbsp;
</span>By using well<span lang=EN-GB style='mso-ansi-language:EN-GB'>-calibrated</span>
probabilities, we are able to estimate the sense priors<span style='mso-ansi-language:
EN-GB'> </span>effectively to achieve significant improvements in WSD accuracy.<span
style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b2B2></a>Ensemble Methods for Unsupervised WSD</p>

<p class=AbstractAuthor>Samuel Brody<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Brody, S.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Roberto Navigli<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Navigli<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>, R.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mirella Lapata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lapata, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Combination methods are an effective way of improving
system performance. This paper examines the benefits of system combination for
unsupervised WSD. We investigate several voting- and arbiter-based combination
strategies over a diverse pool of unsupervised WSD systems. Our combination
methods rely on predominant senses which are derived automatically from raw
text. Experiments using the SemCor and Senseval-3 data sets demonstrate that
our ensembles yield significantly better results when compared with
state-of-the-art.</p>

<p class=AbstractTitle><a name=b2B3></a>Meaningful Clustering of Senses Helps
Boost Word Sense Disambiguation Performance</p>

<p class=AbstractAuthor>Roberto Navigli<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Navigli<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>, R.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Fine-grained sense distinctions are one of the major
obstacles to successful Word Sense Disambiguation. In this paper, we present a
method for reducing the granularity of the WordNet sense inventory based on the
mapping to a manually crafted dictionary encoding sense hierarchies, namely the
Oxford Dictionary of English. We assess the quality of the mapping and the
induced clustering, and evaluate the performance of coarse WSD systems in the
Senseval-3 English all-words task.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>2C: Information
Extraction I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Vincent Ng<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b2C1></a>Espresso: Leveraging Generic Patterns
for Automatically Harvesting Semantic Relations</p>

<p class=AbstractAuthor>Patrick Pantel<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pantel, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Marco Pennacchiotti<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pennacchiotti, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In this
paper, we present Espresso, a weakly-supervised, general-purpose, and accurate
algorithm for harvesting semantic relations. The main contributions are: i) a
method for exploiting generic patterns by filtering incorrect instances using
the Web; and ii) a principled measure of pattern and instance reliability
enabling the filtering algorithm. We present an empirical comparison of
Espresso with various state of the art systems, on different size and genre
corpora, on extracting various general and specific relations. Experimental
results show that our exploitation of generic patterns substantially increases
system recall with small effect on overall precision.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b2C2></a>Modeling Commonality among Related
Classes in Relation Extraction</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Zhou GuoDong</span><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span>
XE &quot;Zhou, G.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'>, Su Jian</span><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span>
XE &quot;Su, J.&quot; </span><![endif]--><!--[if supportFields]><span lang=FR
style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><span
style='mso-spacerun:yes'>&nbsp;</span>and Zhang Min</span><!--[if supportFields]><span
style='mso-element:field-begin'></span><span lang=FR style='mso-ansi-language:
FR'> XE &quot;Zhang, M.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=MsoBodyText>This paper proposes a novel hierarchical learning strategy
to deal with the<span style='mso-ansi-language:EN-GB'> </span>data sparseness
problem in relation extraction by modeling the commonality<span
style='mso-ansi-language:EN-GB'> </span>among related classes. For each class
in the hierarchy either predefined<span style='mso-ansi-language:EN-GB'> </span>manually
or automatically clustered, a linear discriminative function is<span
style='mso-ansi-language:EN-GB'> </span>determined in a top-down way using a
perceptron algorithm with the lower-level<span style='mso-ansi-language:EN-GB'>
</span>weight vector derived from the upper-level weight vector. As the
upper-level<span style='mso-ansi-language:EN-GB'> </span>class normally has
much more positive training examples than the lower-level<span
style='mso-ansi-language:EN-GB'> </span>class, the corresponding linear
discriminative function can be determined more<span style='mso-ansi-language:
EN-GB'> </span>reliably. The upper-level discriminative function then can
effectively guide<span style='mso-ansi-language:EN-GB'> </span>the
discriminative function learning in the lower-level, which otherwise might<span
style='mso-ansi-language:EN-GB'> </span>suffer from limited training data.
Evaluation on the ACE <st1:stockticker>RDC</st1:stockticker> 2003 corpus shows<span
style='mso-ansi-language:EN-GB'> </span>that the hierarchical strategy much
improves the performance by 5.6 and 5.1 in<span style='mso-ansi-language:EN-GB'>
</span>F-measure on least- and medium- frequent relations respectively. It also
shows<span style='mso-ansi-language:EN-GB'> </span>that our system outperforms
the previous best-reported system by 2.7 in<span style='mso-ansi-language:EN-GB'>
</span>F-measure on the 24 subtypes using the same feature set.</p>

<p class=AbstractTitle><a name=b2C3></a>Relation Extraction Using Label
Propagation Based Semi-supervised Learning</p>

<p class=AbstractAuthor>Jinxiu Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, J.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Donghong Ji<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ji, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chew Lim Tan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tan, C.L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Zhengyu Niu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Niu, Z.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Shortage
of manually labeled data is an obstacle to supervised relation extraction
methods. In this paper we investigate a graph based semi-supervised learning
algorithm, a label propagation (LP) algorithm, for relation extraction. It
represents labeled and unlabeled examples and their distances as the nodes and
the weights of edges of a graph, and tries to obtain a labeling function to
satisfy two constraints: 1) it should be fixed on the labeled nodes, 2) it
should be smooth on the whole graph. Experiment results on the ACE corpus
showed that this LP algorithm achieves better performance than </span><st1:stockticker><span
 lang=EN-GB style='mso-ansi-language:EN-GB'>SVM</span></st1:stockticker><span
lang=EN-GB style='mso-ansi-language:EN-GB'> when only very few labeled examples
are available, and it also performs better than bootstrapping for the relation
extraction task.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>2D: Grammars II<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Martin Kay<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b2D1></a>Polarized Unification Grammars</p>

<p class=AbstractAuthor>Sylvain Kahane<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kahane, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper proposes a
generic mathematical formalism for the combination of various structures:
strings, trees, dags, graphs and products of them. The polarization of the
objects of the elementary structures controls the saturation of the final
structure. This formalism is both elementary and powerful enough to strongly
simulate many grammar formalisms, such as rewriting systems, dependency
grammars, </span><st1:stockticker><span style='mso-font-kerning:0pt'>TAG</span></st1:stockticker><span
style='mso-font-kerning:0pt'>, HPSG and </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>LFG</span></st1:stockticker><span
style='mso-font-kerning:0pt'>.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b2D2></a>Partially Specified Signatures: a
Vehicle for Grammar Modularity</p>

<p class=AbstractAuthor>Yael Cohen-Sygal<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Cohen-Sygal, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Shuly Wintner<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wintner, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This work provides the
essential foundations</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>for modular construction of
(typed)</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>unification grammars for natural languages.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>Much of the information in such</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>grammars is encoded in the signature, and</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>hence the key is facilitating a modularized</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>development of type signatures. We introduce</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>a definition of signature modules and</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>show how two modules combine. Our definitions</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>are motivated by the actual needs</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>of grammar developers obtained through a</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>careful examination of large scale grammars.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>We show that our definitions meet</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>these needs by conforming to a detailed set</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>of desiderata.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b2D3></a>Morphology-Syntax Interface for Turkish
<st1:stockticker>LFG</st1:stockticker></p>

<p class=AbstractAuthor>&Ouml;zlem &Ccedil;etino&#287;lu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;&Ccedil;etino&#287;lu, &Ouml;.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kemal Oflazer<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Oflazer, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'>This paper investigates the use of sublexical units as a solution to
handling the complex morphology with productive derivational processes, in the
development of a lexical functional grammar for Turkish. Such sublexical units
make it possible to expose the internal structure of words with multiple
derivations to the grammar rules in a uniform manner. This in turn leads to
more succinct and manageable rules. Further, the semantics of the derivations
can also be systematically reflected in a compositional way by constructing </span><st1:stockticker><span
 lang=EN-GB style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'>PRED</span></st1:stockticker><span
lang=EN-GB style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> values on the
fly. We illustrate how we use sublexical units for handling simple productive
derivational morphology and more interesting cases such as causativization,
etc., which change verb valency. Our priority is to handle several linguistic
phenomena in order to observe the effects of our approach on both the
c-structure and the f-structure representation, and grammar writing, leaving
the coverage and evaluation issues aside for the moment.<o:p></o:p></span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><st1:date Year="200" Day="17" Month="7">Monday 17th July <span
 style='font-size:10.0pt;mso-bidi-font-size:14.0pt'>200</span></st1:date><span
style='font-size:10.0pt;mso-bidi-font-size:14.0pt'>pm</span>¡V330pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>3A: Parsing I<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Joakim Nivre<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b3A1></a>PCFGs with Syntactic and Prosodic
Indicators of Speech Repairs</p>

<p class=AbstractAuthor>John Hale<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Hale, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Izhak Shafran<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shafran, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Lisa Yung<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yung, L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Bonnie Dorr<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Dorr, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Mary Harper<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Harper, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Anna Krasnyanskaya<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Krasnyanskaya, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Matthew Lease<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lease, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yang Liu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Liu, Y.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Brian Roark<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Roark, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Matthew Snover<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Snover, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Robin Stewart<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Stewart, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>A grammatical method of
combining two kinds of speech repair cues is presented. One cue, prosodic
disjuncture, is detected by a decision tree-based ensemble classifier that uses
acoustic cues to identify where normal prosody seems to be interrupted
(Lickley, 1996). The other cue, syntactic parallelism, codifies the expectation
that repairs continue a syntactic category that was left unfinished in the
reparandum (Levelt, 1983). The two cues are combined in a Treebank PCFG whose
states are split using a few simple tree transformations. Parsing performance
on the Switchboard and Fisher corpora suggests that these two cues help to
locate speech repairs in a synergistic way.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b3A2></a>Dependency Parsing of Japanese Spoken
Monologue Based on Clause Boundaries</p>

<p class=AbstractAuthor>Tomohiro Ohno<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ohno, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Shigeki Matsubara<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Matsubara, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hideki Kashioka<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kashioka, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Takehiko Maruyama<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Maruyama, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Yasuyoshi Inagaki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Inagaki, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Spoken monologues feature greater sentence length and
structural complexity<span style='mso-ansi-language:EN-GB'> </span>than do
spoken dialogues.<span style='mso-ansi-language:EN-GB'> </span>To achieve high
parsing performance for spoken monologues, it could prove effective to simplify
the structure by dividing a sentence into suitable language units. This paper
proposes a method for dependency parsing of Japanese monologues based on
sentence segmentation. In this method, the dependency parsing is executed in
two stages: at the clause level and the sentence level. First, the dependencies
within a clause are identified by dividing a sentence into clauses and
executing stochastic dependency parsing for each clause. Next, the dependencies
over clause boundaries are identified stochastically, and the dependency
structure of the entire sentence is thus completed. An experiment using a
spoken monologue corpus shows this method to be effective for efficient dependency
parsing of Japanese monologue sentences.</p>

<p class=AbstractTitle><a name=b3A3></a>Trace Prediction and Recovery With
Unlexicalized PCFGs and Slash Features</p>

<p class=AbstractAuthor>Helmut Schmid<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Schmid, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper describes a
parser which generates</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>parse trees with empty
elements in</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>which traces and fillers are co-indexed.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>The parser is an unlexicalized PCFG</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>parser which is guaranteed to return the</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>most probable parse. The grammar is</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>extracted from a version of the </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>PENN</span></st1:stockticker><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>treebank which was automatically annotated</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>with features in the style of Klein</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>and Manning (2003). The annotation includes</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>GPSG-style slash features which</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>link traces and fillers, and other features</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>which improve the general parsing accuracy.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>In an evaluation on the </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>PENN</span></st1:stockticker><span
style='mso-font-kerning:0pt'> treebank</span><span style='mso-font-kerning:
0pt;mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>(Marcus
et al., 1993), the parser</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>outperformed other
unlexicalized PCFG</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>parsers in terms of labeled
bracketing f-score.</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>Its results for the empty
category</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>prediction task and the trace-filler coindexation</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>task exceed all previously reported</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>results with 84.1% and 77.4% f-score,</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>respectively.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>3B: Dialogue I<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Stanley Peters<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b3B1></a>Learning More Effective Dialogue
Strategies Using Limited Dialogue Move Features</p>

<p class=AbstractAuthor>Matthew Frampton<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Frampton, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Oliver Lemon<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lemon, O.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We explore the use of
restricted dialogue contexts in reinforcement learning (RL) of effective
dialogue strategies for information seeking spoken dialogue systems (e.g.
COMMUNICATOR (Walker et al., 2001)). The contexts we use are richer than
previous research in this area, e.g. (Levin and Pieraccini, 1997; Schefer and
Young, 2001; Singh et al., 2002; Pietquin, 2004), which use only slot-based
information, but are much less complex than the full dialogue Information
States explored in (Henderson et al., 2005), for which tractable learning is an
issue. We explore how incrementally adding richer features allows learning of
more effective dialogue strategies. We use 2 user simulations learned from
COMMUNICATOR data (Walker et al., 2001; Georgila et al., 2005b) to explore the
effects of different features on learned dialogue strategies. Our results show
that adding the dialogue moves of the last system and user turns increases the
average reward of the automatically learned strategies by 65:9% over the
original (hand-coded) COMMUNICATOR systems, and by 7:8% over a baseline RL
policy that uses only slot-status features. We show that the learned strategies
exhibit an emergent focus switching strategy and effective use of the `give
help' action.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b3B2></a>Dependencies between Student State and
Speech Recognition Problems in Spoken Tutoring Dialogues</p>

<p class=AbstractAuthor>Mihai Rotaru<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Rotaru, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Diane J. Litman<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Litman, D.J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Speech recognition
problems are a reality in current spoken dialogue systems. In order to better
understand these phenomena, we study dependencies between speech recognition
problems and several higher level dialogue factors that define our notion of
student state: frustration/anger, certainty and correctness. We apply Chi
Square (£q2) analysis to a corpus of speech-based computer tutoring dialogues to
discover these dependencies both within and across turns. Significant
dependencies are combined to produce interesting insights regarding speech
recognition problems and to propose new strategies for handling these problems.
We also find that tutoring, as a new domain for speech applications, exhibits
interesting tradeoffs and new factors to consider for spoken dialogue design.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b3B3></a>Learning the Structure of Task-driven
Human-Human Dialogs</p>

<p class=AbstractAuthor>Srinivas Bangalore<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bangalore, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Giuseppe Di Fabbrizio<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Di Fabbrizio, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Amanda Stent<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Stent, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Data-driven techniques
have been used for many computational linguistics tasks. Models derived from
data are generally more robust than hand-crafted systems since they better
reflect the distribution of the phenomena being modeled. With the availability
of large corpora of spoken dialog, dialog management is now reaping the
benefits of data-driven techniques. In this paper, we compare two approaches to
modeling subtask structure in dialog: a chunk-based model of subdialog
sequences, and a parse-based, or hierarchical, model. We evaluate these models
using customer agent dialogs from a catalog service domain.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>3C: Machine
Learning Methods I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Hal Daum&eacute; <st1:stockticker>III</st1:stockticker><span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b3C1></a>Semi-Supervised Conditional Random
Fields for Improved Sequence Segmentation and Labeling</p>

<p class=AbstractAuthor>Feng Jiao<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Jiao, F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Shaojun Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, S.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chi-Hoon Lee<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lee, C-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Russell Greiner<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Greiner, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dale Schuurmans<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Schuurmans, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We present a new semi-supervised training procedure for<span
style='mso-ansi-language:EN-GB'> </span>conditional random fields (CRFs) that
can be used to train<span style='mso-ansi-language:EN-GB'> </span>sequence
segmentors and labelers from a combination of labeled and<span
style='mso-ansi-language:EN-GB'> </span>unlabeled training data. Our approach
is based on extending the<span style='mso-ansi-language:EN-GB'> </span>minimum entropy
regularization framework to the structured<span style='mso-ansi-language:EN-GB'>
</span>prediction case, yielding a training objective that combines<span
style='mso-ansi-language:EN-GB'> </span>unlabeled conditional entropy with
labeled conditional likelihood.<span style='mso-ansi-language:EN-GB'> </span>Although
the training objective is no longer concave, it can still<span
style='mso-ansi-language:EN-GB'> </span>be used to improve an initial model
(e.g. obtained from supervised<span style='mso-ansi-language:EN-GB'> </span>training)
by iterative ascent. We apply our new training algorithm<span style='mso-ansi-language:
EN-GB'> </span>to the problem of identifying gene and protein mentions in<span
style='mso-ansi-language:EN-GB'> </span>biological texts, and show that
incorporating unlabeled data<span style='mso-ansi-language:EN-GB'> </span>improves
the performance of the supervised CRF in this case.</p>

<p class=AbstractTitle><a name=b3C2></a>Training Conditional Random Fields with
Multivariate Evaluation Measures</p>

<p class=AbstractAuthor>Jun Suzuki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Suzuki, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Erik McDermott<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;McDermott, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hideki Isozaki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Isozaki, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper proposes a framework for training Conditional Random Fields (CRFs) to
optimize multivariate evaluation measures, including non-linear measures such
as F-score. Our proposed framework is derived from an error minimization
approach that provides a simple solution for directly optimizing any evaluation
measure. Specifically focusing on sequential segmentation tasks, i.e. text
chunking and named entity recognition, we introduce a loss function which
closely reflects the target evaluation measure for these tasks, namely, segmentation
F-score. Our experiments show that our method performs better than standard CRF
training.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b3C3></a>Approximation Lasso Methods for
Language Modeling</p>

<p class=AbstractAuthor>Jianfeng Gao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gao, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hisami Suzuki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Suzuki, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Bin Yu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yu, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Lasso is a regularization method for parameter estimation
in linear models. It optimizes the model parameters with respect to a loss
function subject to model complexities. This paper explores the use of lasso
for statistical language modeling for text input. Owing to the very large
number of parameters, directly optimizing the penalized lasso loss function is
impossible. Therefore, we investigate two approximation methods, the boosted
lasso (BLasso) and the forward stagewise linear regression (FSLR). Both
methods, when used with the exponential loss function, bear strong resemblance
to the boosting algorithm which has been used as a discriminative training
method for language modeling. Evaluations on the task of Japanese text input
show that BLasso is able to produce the best approximation to the lasso
solution, and leads to a significant improvement, in terms of character error
rate, over boosting and the traditional maximum likelihood estimation.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>3D: Applications I<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: John Prager<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b3D1></a>Automated Japanese Essay Scoring System
based on Articles Written by Experts</p>

<p class=AbstractAuthor>Tsunenori Ishioka<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ishioka, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Masayuki Kameda<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kameda, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We have
developed an automated Japanese essay scoring system called Jess. The system
needs expert writings rather than expert raters to build the evaluation model.
By detecting statistical outliers of predetermined aimed essay features
compared with many professional writings for each prompt, our system can
evaluate essays. The following three features are examined: (1) rhetoric ¡V
syntactic variety, or the use of various structures in the arrangement of
phases, clauses, and sentences, (2) organization ¡V characteristics associated
with the orderly presentation of ideas, such as rhetorical features and
linguistic cues, and (3) content ¡V vocabulary related to the topic, such as
relevant information and precise or specialized vocabulary. The final
evaluation score is calculated by deducting from a perfect score assigned by a
learning process using editorials and columns from the Mainichi Daily News
newspaper. A diagnosis for the essay is also given.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b3D2></a>A Feedback-Augmented Method for
Detecting Errors in the Writing of Learners of English</p>

<p class=AbstractAuthor>Ryo Nagata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nagata, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Atsuo Kawai<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kawai, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Koichiro Morihiro<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Morihiro, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Naoki Isu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Isu, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper proposes a method for detecting errors in
article usage and singular plural usage based on the mass count distinction.
First, it learns decision lists from training data generated automatically to
distinguish mass and count nouns. Then, in order to improve its performance, it
is augmented by feedback that is obtained from the writing of learners.
Finally, it detects errors by applying rules to the mass count distinction.
Experiments show that it achieves a recall of 0.71 and a precision of 0.72 and
outperforms other methods used for comparison when augmented by feedback.</p>

<p class=AbstractTitle><a name=b3D3></a>Correcting <st1:stockticker>ESL</st1:stockticker>
Errors Using Phrasal <st1:stockticker>SMT</st1:stockticker> Techniques</p>

<p class=AbstractAuthor>Chris Brockett<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Brockett, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, William B. Dolan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Dolan, W.B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Michael Gamon<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gamon, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper presents a
pilot study of the use of phrasal Statistical Machine Translation (</span><st1:stockticker><span
 style='mso-font-kerning:0pt'>SMT</span></st1:stockticker><span
style='mso-font-kerning:0pt'>) techniques to identify and correct writing
errors made by learners of English as a Second Language (</span><st1:stockticker><span
 style='mso-font-kerning:0pt'>ESL</span></st1:stockticker><span
style='mso-font-kerning:0pt'>). Using examples of mass noun errors found in the
Chinese Learner Error Corpus (</span><st1:stockticker><span style='mso-font-kerning:
 0pt'>CLEC</span></st1:stockticker><span style='mso-font-kerning:0pt'>) to
guide creation of an engineered training set, we show that application of the </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>SMT</span></st1:stockticker><span
style='mso-font-kerning:0pt'> paradigm can capture errors not well addressed by
widely-used proofing tools designed for native speakers. Our system was able to
correct 61.81% of mistakes in a set of naturally- occurring examples of mass
noun errors found on the World Wide Web, suggesting that efforts to collect
alignable corpora of pre- and post-editing </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>ESL</span></st1:stockticker><span
style='mso-font-kerning:0pt'> writing samples offer can enable the development
of </span><st1:stockticker><span style='mso-font-kerning:0pt'>SMT</span></st1:stockticker><span
style='mso-font-kerning:0pt'>-based writing assistance tools capable of
repairing many of the complex syntactic and lexical problems found in the
writing of </span><st1:stockticker><span style='mso-font-kerning:0pt'>ESL</span></st1:stockticker><span
style='mso-font-kerning:0pt'> learners.<o:p></o:p></span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><st1:date Year="400" Day="17" Month="7">Monday 17th July 400</st1:date>pm¡V430pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>4A: Parsing II<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Joakim Nivre<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b4A1></a>Graph Transformations in Data-Driven
Dependency Parsing</p>

<p class=AbstractAuthor>Jens Nilsson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nilsson, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Joakim Nivre<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nivre, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Johan Hall<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hall, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Transforming syntactic representations in order to improve
parsing accuracy<span style='mso-ansi-language:EN-GB'> </span>has been
exploited successfully in statistical parsing systems using<span
style='mso-ansi-language:EN-GB'> </span>constituency-based representations. In
this paper, we show that similar<span style='mso-ansi-language:EN-GB'> </span>transformations
can give substantial improvements also in data-driven<span style='mso-ansi-language:
EN-GB'> </span>dependency parsing. Experiments on the Prague Dependency
Treebank show<span style='mso-ansi-language:EN-GB'> </span>that systematic
transformations of coordinate structures and verb groups result in a 10% error
reduction for a deterministic data-driven dependency parser. Combining these
transformations with previously proposed techniques for recovering
non-projective dependencies leads to state-of-the-art accuracy for the given
data set.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>4B: Dialogue II<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Stanley Peters<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b4B1></a>Learning to Generate Naturalistic
Utterances Using Reviews in Spoken Dialogue Systems</p>

<p class=AbstractAuthor>Ryuichiro Higashinaka<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Higashinaka, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Rashmi Prasad<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Prasad, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Marilyn A. Walker<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Walker, M.A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Spoken language
generation for dialogue systems requires a dictionary of mappings between
semantic representations of concepts the system wants to express and realizations
of those concepts. Dictionary creation is a costly process; it is currently
done by hand for each dialogue domain. We propose a novel unsupervised method
for learning such mappings from user reviews in the target domain, and test it
on restaurant reviews. We test the hypothesis that user reviews that provide
individual ratings for distinguished attributes of the domain entity make it
possible to map review sentences to their semantic representation with high
precision. Experimental analyses show that the mappings learned cover most of
the domain ontology, and provide good linguistic variation. A subjective user
evaluation shows that the consistency between the semantic representations and
the learned realizations is high and that the naturalness of the realizations
is higher than a hand-crafted baseline.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>4C: Linguistic
Kinships<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair><a name=b4C1></a>Session Chair: Hal Daum&eacute; <st1:stockticker>III</st1:stockticker><span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle>Measuring Language Divergence by Intra-Lexical
Comparison</p>

<p class=AbstractAuthor>T. Mark Ellison<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ellison, T.M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Simon Kirby<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kirby, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper presents a method for building genetic language
taxonomies<span style='mso-ansi-language:EN-GB'> </span>based on a new approach
to comparing lexical forms. Instead of<span style='mso-ansi-language:EN-GB'> </span>comparing
forms cross-linguistically, a matrix of language-internal<span
style='mso-ansi-language:EN-GB'> </span>similarities between forms is
calculated. These matrices are then<span style='mso-ansi-language:EN-GB'> </span>compared
to give distances between languages. We argue that this<span style='mso-ansi-language:
EN-GB'> </span>coheres better with current thinking in linguistics and<span
style='mso-ansi-language:EN-GB'> </span>psycholinguistics. An implementation of
this approach, called<span style='mso-ansi-language:EN-GB'> </span>PHILOLOGICON,
is described, along with its application to Dyen et<span style='mso-ansi-language:
EN-GB'> </span>al.'s (1992) ninety-five wordlists from Indo-European languages.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>4D: Applications
II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: John Prager<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b4D1></a>Enhancing electronic dictionaries with
an index based on associations</p>

<p class=AbstractAuthor>Olivier Ferret<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ferret, O.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Michael Zock<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zock, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>A good dictionary
contains not only</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>many entries and a lot of
information</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>concerning each one of them, but also</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>adequate means to reveal the stored information.
Information access depends</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>crucially on the quality of
the index. We</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'>
</span><span style='mso-font-kerning:0pt'>will present here some ideas of how a</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>dictionary could be enhanced to support a</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>speaker/writer to find the word s/he is</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>looking for. To this end we suggest to</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>add to an existing electronic resource an</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>index based on the notion of association.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>We will also present preliminary work of</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>how a subset of such associations, for example,</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>topical associations, can be acquired</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>by filtering a network of lexical</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>co-occurrences extracted from a corpus.<o:p></o:p></span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Tuesday 18th <span style='font-size:10.0pt;mso-bidi-font-size:14.0pt'>July</span>
1000am¡V1030am</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>5A: Parsing </span><st1:stockticker><span
 style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>III</span></st1:stockticker><span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'><span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Dan Klein<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b5A1></a>Guiding a Constraint Dependency Parser
with Supertags</p>

<p class=AbstractAuthor>K<span style='mso-fareast-font-family:SimSun;
mso-fareast-language:ZH-CN'>i</span>lian A. Foth<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Foth, K.A.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Tomas By<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>By, T.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Wolfgang Menzel<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Menzel, W.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We investigate the utility of supertag information for
guiding an existing<span style='mso-ansi-language:EN-GB'> </span>dependency
parser of German. Using weighted constraints to integrate the<span
style='mso-ansi-language:EN-GB'> </span>additionally available information, the
decision process of the parser is<span style='mso-ansi-language:EN-GB'> </span>influenced
by changing its preferences, without excluding alternative<span
style='mso-ansi-language:EN-GB'> </span>structural interpretations from being
considered. The paper reports on a series<span style='mso-ansi-language:EN-GB'>
</span>of experiments using varying models of supertags that significantly
increase<span style='mso-ansi-language:EN-GB'> </span>the parsing accuracy. In
addition, an upper bound on the accuracy that can be<span style='mso-ansi-language:
EN-GB'> </span>achieved with perfect supertags is estimated.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>5B: Lexical Issues
I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Chu Ren Huang<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b5B1></a>Efficient Unsupervised Discovery of
Word Categories Using Symmetric Patterns and High Frequency Words</p>

<p class=AbstractAuthor>Dmitry Davidov<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Davidov, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Ari Rappoport<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Rappoport, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We present
a novel approach for discovering word categories, sets of words sharing a
significant aspect of their meaning. We utilize meta-patterns of high-frequency
words and content words in order to discover pattern candidates. Symmetric
patterns are then identified using graph-based measures, and word categories
are created based on graph clique sets. Our method is the first pattern-based
method that requires no corpus annotation or manually provided seed patterns or
words. We evaluate our algorithm on very large corpora in two languages, using
both human judgments and WordNet-based evaluation. Our fully unsupervised
results are superior to previous work that used a </span><st1:stockticker><span
 lang=EN-GB style='mso-ansi-language:EN-GB'>POS</span></st1:stockticker><span
lang=EN-GB style='mso-ansi-language:EN-GB'> tagged corpus, and computation time
for huge corpora are orders of magnitude faster than previously reported.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>5C: Summarization
I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Simone Teufel<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b5C1></a>Bayesian Query-Focused Summarization</p>

<p class=AbstractAuthor>Hal Daum&eacute; <st1:stockticker>III</st1:stockticker><!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Daum&eacute; III, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Daniel Marcu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Marcu, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We present BayeSum (for &quot;Bayesian
summarization&quot;), a model for<span style='mso-ansi-language:EN-GB'> </span>sentence
extraction in query-focused summarization. BayeSum leverages<span
style='mso-ansi-language:EN-GB'> </span>the common case in which multiple
documents are relevant to a single<span style='mso-ansi-language:EN-GB'> </span>query.
Using these documents as reinforcement for query terms,<span style='mso-ansi-language:
EN-GB'> </span>BayeSum is not afflicted by the paucity of information in short
queries. We show that approximate inference in BayeSum is possible on<span
style='mso-ansi-language:EN-GB'> </span>large data sets and results in a
state-of-the-art summarization<span style='mso-ansi-language:EN-GB'> </span>system.
Furthermore, we show how BayeSum can be understood as a<span style='mso-ansi-language:
EN-GB'> </span>justified query expansion technique in the language modeling for
IR<span style='mso-ansi-language:EN-GB'> </span>framework.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>5D: Semantics I<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Johan Bos<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b5D1></a>Expressing Implicit Semantic Relations
without Supervision</p>

<p class=AbstractAuthor>Peter D. Turney<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Turney, P.D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoNormal><span lang=EN-GB style='mso-bidi-font-family:Arial;
mso-ansi-language:EN-GB'>We present an unsupervised learning algorithm that mines
large text corpora for patterns that express implicit semantic relations. F</span>o<span
lang=EN-GB style='mso-bidi-font-family:Arial;mso-ansi-language:EN-GB'>r a given
input word pair X:Y with some unspecified semantic relations, the corresponding
output list of patterns &lt;P1,...,Pm&gt; is ranked according to how well each
pattern Pi expresses the relations between X and Y. For example, given
X=ostrich and Y=bird, the two highest-ranking output patterns are &quot;X is
the largest Y&quot; and &quot;Y such as the X&quot;. The output patterns are
intended to be useful for finding further pairs with the same relations, to
support the construction of lexicons, ontologies, and semantic networks. The
patterns are sorted by pertinence, where the pertinence of a pattern Pi for a
word pair X:Y is the expected relational similarity between the given pair and
typical pairs for Pi. The algorithm is empirically evaluated on two tasks,
solving multiple-choice </span><st1:stockticker><span lang=EN-GB
 style='mso-bidi-font-family:Arial;mso-ansi-language:EN-GB'>SAT</span></st1:stockticker><span
lang=EN-GB style='mso-bidi-font-family:Arial;mso-ansi-language:EN-GB'> word
analogy questions and classifying semantic relations in noun-modifier pairs. On
both tasks, the algorithm achieves state-of-the-art results, performing significantly
better than several alternative pattern-ranking algorithms, based on tf-idf.</span><span
style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><st1:date Year="1100" Day="18" Month="7">Tuesday 18th July 1100</st1:date>am¡V1230pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>6A: Parsing IV<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Owen Rambow<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6A1></a>Hybrid Parsing: Using Probabilistic
Models as Predictors for a Symbolic Parser</p>

<p class=AbstractAuthor>Kilian A. Foth<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Foth, K.A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Wolfgang Menzel<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Menzel, W.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>In this paper we investigate the benefit of stochastic
predictor components for<span style='mso-ansi-language:EN-GB'> </span>the
parsing quality which can be obtained with a rule-based dependency grammar.<span
style='mso-ansi-language:EN-GB'> </span>By including a chunker, a supertagger,
a PP attacher, and a fast probabilistic<span style='mso-ansi-language:EN-GB'> </span>parser
we were able to improve upon the baseline by 3.2%, bringing the overall<span
style='mso-ansi-language:EN-GB'> </span>labelled accuracy to 91.1% on the
German NEGRA corpus. We attribute the<span style='mso-ansi-language:EN-GB'> </span>successful
integration to the ability of the underlying grammar model to<span
style='mso-ansi-language:EN-GB'> </span>combine uncertain evidence in a soft
manner, thus avoiding the problem of error<span style='mso-ansi-language:EN-GB'>
</span>propagation.<span style='mso-tab-count:5'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6A2></a>Error mining in parsing results</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Beno&icirc;t Sagot</span><!--[if supportFields]><span
style='mso-element:field-begin'></span><span lang=FR style='mso-ansi-language:
FR'> XE &quot;Sagot, B.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><span style='mso-spacerun:yes'>&nbsp;</span>and
&Eacute;ric de La Clergerie</span><!--[if supportFields]><span lang=FR
style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span> XE
&quot;de La Clergerie, &Eacute;.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
introduce an error mining technique for automatically detecting errors in
resources that are used in parsing systems. We applied this technique on
parsing results produced on several million words by two distinct parsing
systems, which share the syntactic lexicon and the pre-parsing processing
chain. We were thus able to identify missing and erroneous information in these
resources.</span><span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6A3></a>Reranking and Self-Training for Parser
Adaptation</p>

<p class=AbstractAuthor>David McClosky<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;McClosky, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Eugene Charniak<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Charniak, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mark Johnson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Johnson, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Statistical
parsers trained and tested on the Penn Wall Street Journal (WSJ) treebank have
shown vast improvements over the last 10 years. Much of this improvement,
however, is based upon an ever-increasing number of features to be trained on
(typically) the WSJ treebank data. This has led to concern that such parsers
may be too finely tuned to this corpus at the expense of portability to other
genres. Such worries have merit. The standard &quot;Charniak parser&quot;
checks in at a labeled precision-recall f-measure of 89.7% on the Penn WSJ test
set, but only 82.9% on the test set from the Brown treebank corpus.<o:p></o:p></span></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper should allay these fears. In particular, we show that the reranking
parser described in Charniak and Johnson (2005) improves performance of the
parser on Brown to 85.2%.<span style='mso-spacerun:yes'>&nbsp;
</span>Furthermore, use of the self-training techniques described in (McClosky
et al. 2006) raise this to 87.8% (an error reduction of 28%) again without any
use of labeled Brown data.<span style='mso-spacerun:yes'>&nbsp; </span>This is
remarkable since training the parser and reranker on labeled Brown data
achieves only 88.4%.</span><span style='mso-tab-count:1'>&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>6B: Lexical Issues
II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Chu Ren Huang<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6B1></a>Automatic Classification of Verbs in
Biomedical Texts</p>

<p class=AbstractAuthor>Anna Korhonen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Korhonen, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yuval Krymolowski<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Krymolowski, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Nigel Collier<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Collier, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Lexical classes, when
tailored to the application and domain in question, can provide an effective
means to deal with a number of natural language processing (NLP) tasks. While
manual construction of such classes is difficult, recent research shows that it
is possible to automatically induce verb classes from cross-domain corpora with
promising accuracy. We report a novel experiment where similar technology is
applied to the important, challenging domain of biomedicine. We show that the
resulting classification, acquired from a corpus of biomedical journal
articles, is highly accurate and strongly domain specific. It can be used to
aid </span><st1:stockticker><span style='mso-font-kerning:0pt'>BIO</span></st1:stockticker><span
style='mso-font-kerning:0pt'>-NLP directly or as useful material for
investigating the syntax and semantics of verbs in biomedical texts.</span></p>

<p class=AbstractTitle><a name=b6B2></a>Selection of Effective Contextual
Information for Automatic Synonym Acquisition </p>

<p class=AbstractAuthor>Masato Hagiwara<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hagiwara, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yasuhiro Ogawa<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ogawa, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Katsuhiko Toyama<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Toyama, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Various methods </span>have
been<span style='mso-font-kerning:0pt'> proposed for automatic synonym
acquisition, as synonyms are one of the most fundamental lexical knowledge.
Whereas many methods are based on contextual clues of words, little attention
has been paid to what kind of categories of contextual information are useful
for the purpose. This study has experimentally investigated the impact of
contextual information selection, by extracting three kinds of word
relationships from corpora: dependency, sentence co-occurrence, and proximity.
The evaluation result shows that while dependency and proximity perform
relatively well by themselves, combination of two or more kinds of contextual
information gives more stable performance. We¡¦ve further investigated useful
selection of dependency relations and modification categories, and it is found
that modification has the greatest contribution, even greater than the widely
adopted subject object combination.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6B3></a>Scaling Distributional Similarity to
Large Corpora</p>

<p class=AbstractAuthor>James Gorman<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gorman, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and James R. Curran<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Curran, J.R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Accurately representing
synonymy using distributional similarity requires large volumes of data to
reliably represent infrequent words. However, the naive nearest-neighbour
approach to comparing context vectors extracted from large corpora scales
poorly (O (n2) in the vocabulary size).<o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>In this paper, we
compare several existing approaches to approximating the nearest-neighbour
search for distributional similarity. We investigate the trade-off between efficiency
and accuracy, and find that SASH (Houle and Sakuma, 2005) provides the best
balance.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>6C: Summarization
II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Simone Teufel<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6C1></a>Extractive Summarization using Inter-
and Intra- Event Relevance</p>

<p class=AbstractAuthor>Wenjie Li<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Li, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Mingli Wu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wu, M.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Qin Lu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lu, Q.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Wei Xu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Xu, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Chunfa Yuan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yuan, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Event-based summarization attempts to select and organize
sentences in a summary with respect to events or sub-events that the sentences
describe. Each<span style='mso-ansi-language:EN-GB'> </span>event has its own
internal structure and meanwhile relates to the other events<span
style='mso-ansi-language:EN-GB'> </span>semantically, temporally, spatially,
causally or conditionally. In this paper,<span style='mso-ansi-language:EN-GB'>
</span>we define an event as one or more event terms along with the named
entities<span style='mso-ansi-language:EN-GB'> </span>associated, and present a
novel approach to derive intra- and inter- event<span style='mso-ansi-language:
EN-GB'> </span>relevance using the information of internal association,
semantic related-ness,<span style='mso-ansi-language:EN-GB'> </span>distributional
similarity and named entity clustering. We then apply PageRank<span
style='mso-ansi-language:EN-GB'> </span>ranking algorithm to estimate the
significance of an event for inclusion in a<span style='mso-ansi-language:EN-GB'>
</span>summary from the event relevance derived. Experiments on the DUC 2001
test<span style='mso-ansi-language:EN-GB'> </span>data shows that the relevance
of the named entities involved in events achieves better result when their
relevance is derived from the event terms they associate. It also reveals that
the topic-specific from documents themselves outperforms the semantic relevance
from a general purpose knowledge<span style='mso-ansi-language:EN-GB'> </span>base
like Word-Net.</p>

<p class=AbstractTitle><a name=b6C2></a>Models for Sentence Compression: A
Comparison across Domains, Training Requirements and Evaluation Measures</p>

<p class=AbstractAuthor>James Clarke<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Clarke, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mirella Lapata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lapata, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'>Sentence compression is the task of producing a summary at the sentence
level.<span style='mso-spacerun:yes'>&nbsp; </span>This paper focuses on three
aspects of this task which have not received detailed treatment in the
literature: training requirements, scalability, and automatic evaluation. We
provide a novel comparison between a supervised constituent-based and a weakly
supervised word-based compression algorithm and examine how these models port
to different domains (written vs. spoken text).<span
style='mso-spacerun:yes'>&nbsp; </span>To achieve this, a human-authored
compression corpus has been created and our study highlights potential problems
with the automatically gathered compression corpora currently used. Finally, we
assess whether automatic evaluation measures can be used to determine
compression quality.</span><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6C3></a>A Bottom-up Approach to Sentence
Ordering for Multi-document Summarization</p>

<p class=AbstractAuthor>Danushka Bollegala<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bollegala, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Naoaki Okazaki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Okazaki, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mitsuru Ishizuka<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ishizuka, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Ordering information is a difficult but important task for
applications generating natural-language text. We present a bottom-up approach
to arranging sentences extracted for multi-document summarization. To capture
the association and order of two textual segments (eg, sentences), we define
four criteria, chronology, topical-closeness, precedence, and succession. These
criteria are integrated into a criterion by a supervised learning approach. We
repeatedly concatenate two textual segments into one segment based on the
criterion until we obtain the overall segment with all sentences arranged. Our
experimental results show a significant improvement over existing sentence
ordering strategies.<span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>6D: Semantics II<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Johan Bos<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6D1></a>Learning Event Durations from Event
Descriptions</p>

<p class=AbstractAuthor>Feng Pan<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Pan, F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Rutu Mulkar<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mulkar, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jerry R. Hobbs<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hobbs, J.R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We have constructed a corpus of news articles in which
events are annotated for estimated bounds on their durations. Here we describe
a method for measuring inter-annotator agreement for these event duration
distributions. We then show that machine learning techniques applied to this
data yield coarse-grained event duration information, considerably outperforming
a baseline and approaching human performance.</p>

<p class=AbstractTitle><a name=b6D2></a>Automatic learning of textual
entailments with cross-pair similarities</p>

<p class=AbstractAuthor>Fabio Massimo Zanzotto<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zanzotto, F.M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Alessandro Moschitti<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Moschitti, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In this
paper we define a novel similarity measure between examples of textual
entailments and we use it as a kernel function in Support Vector Machines
(SVMs). This allows us to automatically learn the rewrite rules that describe a
non trivial set of entailment cases. The experiments with the data sets of the
RTE 2005 challenge show an improvement of 4.4% over the state-of-the-art
methods.</span><span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b6D3></a>An Improved Redundancy Elimination
Algorithm for Underspecified Representations</p>

<p class=AbstractAuthor>Alexander Koller<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Koller, A.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Stefan Thater<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Thater<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>, S.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
present an efficient algorithm for the redundancy elimination problem: Given an
underspecified semantic representation (USR) of a scope ambiguity, compute an
USR with fewer mutually equivalent readings. The algorithm operates on
underspecified chart representations which are derived from dominance graphs;
it can be applied to the USRs computed by large-scale grammars. We evaluate the
algorithm on a corpus, and show that it reduces the degree of ambiguity
significantly while taking negligible runtime.</span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Tuesday 18th <span style='font-size:10.0pt;mso-bidi-font-size:14.0pt'>July</span>
200pm¡V330pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>7A: Parsing V<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Takashi Ninomiya<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7A1></a>Integrating Syntactic Priming into an
Incremental Probabilistic Parser, with an Application to Psycholinguistic
Modeling</p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Amit Dubey</span><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-begin'></span></span>
XE &quot;<span style='mso-font-kerning:0pt'>Dubey, A.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'>, Frank Keller</span><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-begin'></span></span>
XE &quot;<span style='mso-font-kerning:0pt'>Keller, F.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'><span style='mso-spacerun:yes'>&nbsp;</span>and
Patrick Sturt</span><!--[if supportFields]><span style='mso-font-kerning:0pt'><span
style='mso-element:field-begin'></span></span> XE &quot;<span style='mso-font-kerning:
0pt'>Sturt, P.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'><o:p></o:p></span></p>

<p class=MsoBodyText>The psycholinguistic literature provides evidence for
syntactic priming, i.e., the tendency to repeat structures.<span
style='mso-spacerun:yes'>&nbsp; </span>This paper describes a method for incorporating
priming into an incremental probabilistic parser. Three models are compared,
which involve priming of rules between sentences, within sentences, and within
coordinate structures. These models simulate the reading time advantage for
parallel structures found in human data, and also yield a small increase in
overall parsing accuracy.<span style='mso-tab-count:5'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7A2></a>A Fast, Accurate Deterministic Parser
for Chinese</p>

<p class=AbstractAuthor>Mengqiu Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Kenji Sagae<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sagae, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Teruko Mitamura<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mitamura, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We present a novel classifier-based deterministic parser
for Chinese constituency parsing. Our parser computes parse trees from bottom
up in one pass, and uses classifiers to make shift-reduce decisions. Trained
and evaluated on the standard training and test sets, our best model (using
stacked classifiers) runs in linear time and has labeled precision and recall
above 88% using gold-standard part-of-speech tags, surpassing the best
published results. Our <st1:stockticker>SVM</st1:stockticker> parser is 2-13
times faster than state-of-the-art parsers, while producing more accurate
results. Our Maxent and DTree parsers run at speeds 40-270 times faster than
state-of-the-art parsers, but with 5-6% losses in accuracy.</p>

<p class=AbstractTitle><a name=b7A3></a>Learning Accurate, Compact, and
Interpretable Tree Annotation</p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Slav Petrov</span><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-begin'></span></span>
XE &quot;<span style='mso-font-kerning:0pt'>Petrov, S.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'>, Leon Barrett</span><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-begin'></span></span>
XE &quot;<span style='mso-font-kerning:0pt'>Barrett, L.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'>, Romain Thibaux</span><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-begin'></span></span>
XE &quot;<span style='mso-font-kerning:0pt'>Thibaux, R.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'><span style='mso-spacerun:yes'>&nbsp;</span>and
Dan Klein</span><!--[if supportFields]><span style='mso-font-kerning:0pt'><span
style='mso-element:field-begin'></span></span> XE &quot;<span style='mso-font-kerning:
0pt'>Klein, D.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'><o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We present an automatic
approach to tree annotation in which basic nonterminal symbols are alternately
split and merged to maximize the likelihood of a training treebank. Starting
with a simple Xbar grammar, we learn a new grammar whose nonterminals are
subsymbols of the original nonterminals. In contrast with previous work, we are
able to split various terminals to different degrees, as appropriate to the
actual complexity in the data. Our grammars automatically learn the kinds of
linguistic distinctions exhibited in previous work on manual tree annotation.
On the other hand, our grammars are much more compact and substantially more
accurate than previous work on automatic annotation. Despite its simplicity,
our best grammar achieves an F<sub>1</sub> of 90.2% on the Penn Treebank,
higher than fully lexicalized systems.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>7B: Word Sense
Disambiguation II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Hwee Tou Ng<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7B1></a>Semi-Supervised Learning of Partial
Cognates using Bilingual Bootstrapping</p>

<p class=AbstractAuthor>Oana Frunza<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Frunza, O.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Diana Inkpen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Inkpen, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Partial cognates are pairs of words in two languages that
have the same meaning in some, but not all contexts. Detecting the actual
meaning of a partial cognate in con-text can be useful for Machine Translation
tools and for Computer-Assisted Language Learning tools. In this paper we
propose a supervised and a semi-supervised method to disambiguate partial
cognates between two languages: French and English. The methods use only
automatically-labeled data; therefore they can be applied for other pairs of
languages as well. We also show that our methods perform well when using
corpora from different domains.<span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span
style='mso-tab-count:4'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7B2></a>Direct Word Sense Matching for Lexical
Substitution</p>

<p class=AbstractAuthor>Ido Dagan<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Dagan, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Oren Glickman<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Glickman, O.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Alfio Gliozzo<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gliozzo, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Efrat Marmorshtein<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Marmorshtein, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Carlo Strapparava<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Strapparava, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper investigates
conceptually and empirically the novel sense matching task, which requires to
recognize whether the senses of two synonymous words match in context. We
suggest direct approaches to the problem, which avoid the intermediate step of
explicit word sense disambiguation, and demonstrate their appealing advantages
and stimulating potential for future research.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b7B3></a>An Equivalent Pseudoword for
Unsupervised Chinese Word Sense Disambiguation</p>

<p class=AbstractAuthor>Zhimao Lu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Lu, Z.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Haifeng Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jianmin Yao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yao, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ting Liu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Liu, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Sheng Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Li, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper presents a new approach based on Equivalent
Pseudowords (EPs) to tackle Word Sense Disambiguation (WSD) in Chinese
language. EPs are particular artificial ambiguous words, which can be used to realize
unsupervised WSD. A Bayesian classifier is implemented to test the efficacy of
the EP solution on Senseval-3 Chinese test set. The performance is better than
state-of-the-art results with an average F-measure of 0.80. The experiment
verifies the value of EP for unsupervised WSD.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>7C: Information
Extraction II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Ming Zhou<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7C1></a>Improving the Scalability of
Semi-Markov Conditional Random Fields for Named Entity Recognition</p>

<p class=AbstractAuthor>Daisuke Okanohara<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Okanohara, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yusuke Miyao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Miyao, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yoshimasa Tsuruoka<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsuruoka, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jun'ichi Tsujii<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsujii, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper presents techniques to apply semi-CRFs to Named Entity Recognition tasks
with a tractable computational cost. Our framework can handle an </span><st1:stockticker><span
 lang=EN-GB style='mso-ansi-language:EN-GB'>NER</span></st1:stockticker><span
lang=EN-GB style='mso-ansi-language:EN-GB'> task that has long named entities
and many labels which increase the computational cost. To reduce the
computational cost, we propose two techniques: the first is the use of feature
forests, which enables us to pack feature-equivalent states, and the second is
the introduction of a filtering process which significantly reduces the number
of candidate states. This framework allows us to use a rich set of features
extracted from the chunk-based representation that can capture informative
characteristics of entities. We also introduce a simple trick to transfer
information about distant entities by embedding label information into
non-entity labels. Experimental results show that our model achieves an F-score
of 71.48% on the JNLPBA 2004 shared task without using any external resources
or post-processing techniques.</span><span style='mso-tab-count:1'>&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7C2></a>Factorizing Complex Models: A Case
Study in Mention Detection</p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Radu Florian</span><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-begin'></span></span>
XE &quot;<span style='mso-font-kerning:0pt'>Florian, R.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'>, Hongyan Jing</span><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-begin'></span></span>
XE &quot;<span style='mso-font-kerning:0pt'>Jing, H.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'>, Nanda Kambhatla</span><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-begin'></span></span>
XE &quot;<span style='mso-font-kerning:0pt'>Kambhatla, N.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'><span style='mso-spacerun:yes'>&nbsp;</span>and
Imed Zitouni</span><!--[if supportFields]><span style='mso-font-kerning:0pt'><span
style='mso-element:field-begin'></span></span> XE &quot;<span style='mso-font-kerning:
0pt'>Zitouni, I.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-font-kerning:0pt'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-font-kerning:0pt'><o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>As natural language
processing moves towards natural language understanding, the tasks are becoming
more and more subtle: we are interested in more nuanced word characteristics,
more linguistic properties, more semantic and syntactic features. One such example,
which we consider in this article, is the mention detection in the ACE project
(NIST, 2004), where the goal is to identify named, nominal or pronominal
references to real-world entities ¡V mentions ¡V and label them with three types
of information: entity type, entity subtype and mention type. In this article,
we investigate several methods to assign these related tags and compare them on
several data sets. A system based on the methods presented in this article
ranked very well in the ACE¡¦04 evaluation.</span><span style='mso-tab-count:
3'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7C3></a>Segment-based Hidden Markov Models for
Information Extraction</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Zhenmei Gu</span><!--[if supportFields]><span
style='mso-element:field-begin'></span><span lang=FR style='mso-ansi-language:
FR'> XE &quot;Gu, Z.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><span style='mso-spacerun:yes'>&nbsp;</span>and
Nick Cercone</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Cercone, N.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Hidden Markov models
(HMMs) are powerful statistical models that have found successful applications in
Information Extraction (IE). In current approaches to applying HMMs to IE, an
HMM is used to model text at the document level. This modeling might cause
undesired redundancy in extraction in the sense that more than one filler is
identified and extracted. We propose to use HMMs to model text at the segment
level, in which the extraction process consists of two steps: a segment
retrieval step followed by an extraction step. In order to retrieve extraction
relevant segments from documents, we introduce a method to use HMMs to model
and retrieve segments. Our experimental results show that the resulting segment
HMM IE system not only achieves near zero extraction redundancy, but also has
better overall extraction performance than traditional document HMM IE systems.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>7D: Resources I<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Erhard Hinrichs<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7D1></a>A <st1:stockticker>DOM</st1:stockticker>
Tree Alignment Model for Mining Parallel Data from the Web</p>

<p class=AbstractAuthor>Lei Shi<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Shi, L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Cheng Niu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Niu, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ming Zhou<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhou, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jianfeng Gao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gao, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper presents a
new web mining</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'>
</span><span style='mso-font-kerning:0pt'>scheme for parallel data acquisition.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>Based on the Document Object Model</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>(</span><st1:stockticker><span style='mso-font-kerning:
 0pt'>DOM</span></st1:stockticker><span style='mso-font-kerning:0pt'>), a web
page is represented as a</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><st1:stockticker><span style='mso-font-kerning:0pt'>DOM</span></st1:stockticker><span
style='mso-font-kerning:0pt'> tree. Then a </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>DOM</span></st1:stockticker><span
style='mso-font-kerning:0pt'> tree alignment</span><span style='mso-font-kerning:
0pt;mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>model
is proposed to identify the translationally</span><span style='mso-font-kerning:
0pt;mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>equivalent
texts and hyperlinks</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>between two parallel </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>DOM</span></st1:stockticker><span
style='mso-font-kerning:0pt'> trees. By</span><span style='mso-font-kerning:
0pt;mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>tracing
the identified parallel hyperlinks, parallel web documents are recursively</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>mined. Compared with previous mining</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>schemes, the benchmarks show that this</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>new mining scheme improves the mining</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>coverage, reduces mining bandwidth, and</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>enhances the quality of mined parallel</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>sentences.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b7D2></a>QuestionBank: Creating a Corpus of
Parse-Annotated Questions </p>

<p class=AbstractAuthor>John Judge<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Judge, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Aoife Cahill<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Cahill, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Josef van Genabith<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;van Genabith, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper describes
the development of QuestionBank, a corpus of 4000 parse annotated questions for
(i) use in training parsers employed in QA, and (ii) evaluation of question
parsing. We present a series of experiments to investigate the effectiveness of
QuestionBank as both an exclusive and supplementary training resource for a
state-of-the-art parser in parsing both question and non-question test sets. We
introduce a new method for recovering empty nodes and their antecedents
(capturing long distance dependencies) from parser output in CFG trees using </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>LFG</span></st1:stockticker><span
style='mso-font-kerning:0pt'> f-structure reentrancies. Our main findings are
(i) using QuestionBank training data improves parser performance to 89.75%
labelled bracketing f-score, an increase of almost 11% over the baseline; (ii)
back-testing experiments on nonquestion data (Penn-II WSJ Section 23) shows
that the retrained parser does not suffer a performance drop on non-question
material; (iii) ablation experiments show that the size of training material
provided by QuestionBank is sufficient to achieve optimal results; (iv) our
method for recovering empty nodes captures long distance dependencies in
questions from the </span><st1:stockticker><span style='mso-font-kerning:0pt'>ATIS</span></st1:stockticker><span
style='mso-font-kerning:0pt'> corpus with high precision (96.82%) and low
recall (39.38%). In summary, QuestionBank provides a useful new resource in
parser-based QA research.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b7D3></a>Creating a CCGbank and a wide-coverage <st1:stockticker>CCG</st1:stockticker>
lexicon for German</p>

<p class=AbstractAuthor>Julia Hockenmaier<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hockenmaier, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We present an algorithm
which creates a German CCGbank by translating the syntax graphs in the German
Tiger corpus into </span><st1:stockticker><span style='mso-font-kerning:0pt'>CCG</span></st1:stockticker><span
style='mso-font-kerning:0pt'> derivation trees. The resulting corpus contains
46,628 derivations, covering 95% of all complete sentences in Tiger. Lexicons
extracted from this corpus contain correct lexical entries for 94% of all known
tokens in unseen text.<o:p></o:p></span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><st1:date Year="400" Day="18" Month="7">Tuesday 18th July 400</st1:date>pm¡V530pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>8A: Machine
Translation </span><st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:
 13.0pt'>III</span></st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:
13.0pt'><span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Kevin Knight<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b8A1></a>Improved Discriminative Bilingual Word
Alignment</p>

<p class=AbstractAuthor>Robert C. Moore<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Moore, R.C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Wen-tau Yih<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yih, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Andreas Bode<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bode, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>For many years, statistical machine translation relied on
generative models to provide bilingual word alignments.<span
style='mso-spacerun:yes'>&nbsp; </span>In 2005, several independent efforts
showed that discriminative models could be used to enhance or replace the
standard generative approach.<span style='mso-spacerun:yes'>&nbsp;
</span>Building on this work, we demonstrate substantial improvement in
word-alignment accuracy, partly though improved training methods, but
predominantly through selection of more and better features.<span
style='mso-spacerun:yes'>&nbsp; </span>Our best model produces the lowest
alignment error rate yet reported on Canadian Hansard¡¦s bilingual data.</p>

<p class=AbstractTitle><a name=b8A2></a>Maximum Entropy Based Phrase Reordering
Model for Statistical Machine Translation</p>

<p class=AbstractAuthor>Deyi Xiong<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Xiong, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Qun Liu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Liu, Q.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Shouxun Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We propose a novel reordering model for<span
style='mso-ansi-language:EN-GB'> </span>phrase-based statistical machine translation
(<st1:stockticker>SMT</st1:stockticker>) that uses a maximum entropy<span
style='mso-ansi-language:EN-GB'> </span>(MaxEnt) model to predicate reorderings<span
style='mso-ansi-language:EN-GB'> </span>of neighbor blocks (phrase pairs). The<span
style='mso-ansi-language:EN-GB'> </span>model provides content-dependent,
hierarchical<span style='mso-ansi-language:EN-GB'> </span>phrasal reordering
with generalization<span style='mso-ansi-language:EN-GB'> </span>based on
features automatically<span style='mso-ansi-language:EN-GB'> </span>learned from
a real-world bitext. We<span style='mso-ansi-language:EN-GB'> </span>present an
algorithm to extract all reordering<span style='mso-ansi-language:EN-GB'> </span>events
of neighbor blocks from bilingual<span style='mso-ansi-language:EN-GB'> </span>data.
In our experiments on Chinese-to-English translation, this MaxEnt-based<span
style='mso-ansi-language:EN-GB'> </span>reordering model obtains significant
improvements<span style='mso-ansi-language:EN-GB'> </span>in BLEU score on the
NIST MT-05 and IWSLT-04 tasks.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span
style='mso-tab-count:5'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b8A3></a>Distortion Models for Statistical
Machine Translation</p>

<p class=AbstractAuthor>Yaser Al-Onaizan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Al-Onaizan, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kishore Papineni<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Papineni, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>In this paper, we argue that n-gram language models are
not sufficient to address word reordering required for Machine Translation. We
propose a new distortion model that can be used with existing phrase-based <st1:stockticker>SMT</st1:stockticker>
decoders to address those n-gram language model limitations. We present
empirical results in Arabic to English Machine Translation that show
statistically significant improvements when our proposed model is used. We also
propose a novel metric to measure word order similarity (or difference) between
any pair of languages based on word alignments.<span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>8B: Text
Classification I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Janyce Wiebe<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b8B1></a>A Study on Automatically Extracted
Keywords in Text Categorization</p>

<p class=AbstractAuthor>Anette Hulth<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hulth, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Be&aacute;ta B. Megyesi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Megyesi, B.B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper presents a study
on if and how automatically extracted keywords can be used to improve text
categorization. In summary we show that a higher performance ¡V as measured by
micro-averaged F-measure on a standard text categorization collection ¡V is
achieved when the full-text representation is combined with the automatically
extracted keywords. The combination is obtained by giving higher weights to
words in the full-texts that are also extracted as keywords. We also present
results for experiments in which the keywords are the only input to the
categorizer, either represented as unigrams or intact. Of these two
experiments, the unigrams have the best performance, although neither performs
as well as headlines only</span><span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span
style='mso-tab-count:4'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b8B2></a>A Comparison and Semi-Quantitative
Analysis of Words and Character-Bigrams as Features in Chinese Text
Categorization</p>

<p class=AbstractAuthor>Jingyang Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Li, J.</span>(3)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Maosong Sun<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sun<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>, M.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Xian Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>, X.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Words and
character-bigrams are both</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>used as features in Chinese
text processing</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'>
</span><span style='mso-font-kerning:0pt'>tasks, but no systematic comparison</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>or analysis of their values as features for</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>Chinese text categorization has been reported</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>heretofore. We carry out here a</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>full performance comparison between</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>them by experiments on various document</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>collections (including a manually</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>word-segmented corpus as a golden standard),</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>and a semi-quantitative analysis to</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>elucidate the characteristics of their behavior;</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>and try to provide some preliminary</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>clue for feature term choice (in most</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>cases, character-bigrams are better than</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>words) and dimensionality setting in text</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>categorization systems.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b8B3></a>Exploiting Comparable Corpora and
Bilingual Dictionaries for Cross-Language Text Categorization</p>

<p class=AbstractAuthor>Alfio Gliozzo<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gliozzo, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Carlo Strapparava<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Strapparava, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Cross-language
Text Categorization is the task to assign semantic classes to documents written
in a target language (e.g. English) while the system is trained using labeled
documents in a source language (e.g. Italian).<o:p></o:p></span></p>

<p class=MsoNormal style='text-align:justify;text-justify:inter-ideograph'><span
lang=EN-GB style='mso-bidi-font-family:Arial;mso-ansi-language:EN-GB'>In this
work we present many solutions according to the availability of bilingual
resources, and we show that it is possible to deal with the problem even when
no such resources are accessible. The core technique relies on the automatic
acquisition of Multilingual Domain Models from comparable corpora.<o:p></o:p></span></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Experiments
show the effectiveness of our approach, providing a low cost solution for the
Cross Language Text Categorization task. In particular, when bilingual
dictionaries are available the performance of the categorization gets close to
that of monolingual text categorization.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>8C: Machine
Learning Methods II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Anoop Sarkar<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b8C1></a>A Progressive Feature Selection
Algorithm for Ultra Large Feature Spaces</p>

<p class=AbstractAuthor>Qi Zhang<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Zhang, Q.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Fuliang Weng<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Weng, F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Zhe Feng<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Feng, Z.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Recent developments in statistical modeling of various
linguistic phenomena have shown that additional features give consistent
performance improvements. Quite often, improvements are limited by the number
of features a system is able to explore. This paper describes a novel
progressive training algorithm that selects features from virtually unlimited
feature spaces for conditional maximum entropy (<st1:stockticker>CME</st1:stockticker>)
modeling. Experimental results in edit region identification demonstrate the
benefits of the progressive feature selection (PFS) algorithm: the PFS
algorithm maintains the same accuracy performance as previous <st1:stockticker>CME</st1:stockticker>
feature selection algorithms (e.g., Zhou et al., 2003) when the same feature
spaces are used. When additional features and their combinations are used, the
PFS gives 17.66% relative improvement over the previously reported best result
in edit region identification on Switchboard corpus (Kahn et al., 2005), which
leads to a 20% relative error reduction in parsing the Switchboard corpus when
gold edits are used as the upper bound.</p>

<p class=AbstractTitle><a name=b8C2></a>Annealing Structural Bias in
Multilingual Weighted Grammar Induction</p>

<p class=AbstractAuthor>Noah A. Smith<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Smith, N.A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jason Eisner<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Eisner, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We first show how a structural locality bias can improve
the accuracy of state-of-the-art dependency grammar induction models trained by
EM from unannotated examples (Klein and Manning, 2004).<span
style='mso-spacerun:yes'>&nbsp; </span>Next, by annealing the free parameter
that controls this bias, we achieve further improvements.<span
style='mso-spacerun:yes'>&nbsp; </span>We then describe an alternative kind of
structural bias, toward &quot;broken&quot; hypotheses consisting of partial
structures over segmented sentences, and show a similar pattern of improvement.
We relate this approach to contrastive estimation (Smith and Eisner, 2005),
apply the latter to grammar induction in si languages, and show that our new
approach improves accuracy by 1-17% (absolute) over CE (and 8-30% over EM),
achieving to our knowledge the best results on this task to date.<span
style='mso-spacerun:yes'>&nbsp; </span>Our method, structural annealing, is a general
technique with broad applicability to hidden-structure discovery problems.</p>

<p class=AbstractTitle><a name=b8C3></a>Maximum Entropy Based Restoration of
Arabic Diacritics</p>

<p class=AbstractAuthor>Imed Zitouni<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zitouni, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jeffrey S. Sorensen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sorensen, J.S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Ruhi Sarikaya<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sarikaya, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Short vowels and other
diacritics are not part of written Arabic scripts. Exceptions are made for
important political and religious texts and in scripts for beginning students
of Arabic. Script without diacritics have considerable ambiguity because many
words with different diacritic patterns appear identical in a diacritic-less
setting. We propose in this paper a maximum entropy approach for restoring
diacritics in a document. The approach can easily integrate and make effective
use of diverse types of information; the model we propose integrates a wide
array of lexical, segment based and part-of-speech tag features. The
combination of these feature types leads to a state-of-the-art diacritization
model. Using a publicly available corpus (LDC's Arabic Treebank Part 3), we
achieve a diacritic error rate of 5:1%, a segment error rate 8:5%, and a word
error rate of 17:3%. In case-ending-less setting, we obtain a diacritic error
rate of 2:2%, a segment error rate 4:0%, and a word error rate of 7:2%.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>8D: Information
Retrieval I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Jian-Yun Nie<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b8D1></a>An Iterative Implicit Feedback Approach
to Personalized Search</p>

<p class=AbstractAuthor>Yuanhua Lv<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lv, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Le Sun<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sun, L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Junlin Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, J.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jian-Yun Nie<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nie, J-Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Wan Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, W.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Wei Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>General information retrieval systems are designed to
serve all users without considering individual needs. In this paper, we propose
a novel approach to personalized search. It can, in a unified way, exploit and
utilize implicit feedback information, such as query logs and immediately
viewed documents. Moreover, our approach can implement result re-ranking and
query expansion simultaneously and collaboratively. Based on this approach, we
develop a client-side personalized web search agent PAIR (Personalized Assistant
for Information Retrieval), which supports both English and Chinese. Our
experiments on TREC and HTRDP collections clearly show that the new approach is
both effective and efficient.<span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b8D2></a>The Effect of Translation Quality in
MT-Based Cross-Language Information Retrieval</p>

<p class=AbstractAuthor>Jiang Zhu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Zhu, J.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Haifeng Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper explores the relationship between the translation quality and the
retrieval effectiveness in Machine Translation (MT) based Cross-Language
Information Retrieval (CLIR). To obtain MT systems of different translation
quality, we degrade a rule-based MT system by decreasing the size of the rule
base and the size of the dictionary. We use the degraded MT systems to
translate queries and submit the translated queries of varying quality to the
IR system. Retrieval effectiveness is found to correlate highly with the
translation quality of the queries. We further analyze the factors that affect
the retrieval effectiveness. Title queries are found to be preferred in MT-based
CLIR. In addition, dictionary-based degradation is shown to have stronger
impact than rule-based degradation in MT-based CLIR.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b8D3></a>A Comparison of Document, Sentence, and
Term Event Spaces </p>

<p class=AbstractAuthor>Catherine Blake<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Blake, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>The trend in information
retrieval systems is from document to sub-document retrieval, such as sentences
in a summarization system and words or phrases in question-answering system.
Despite this trend, systems continue to model language at a document level
using the inverse document frequency (IDF). In this paper, we compare and
contrast IDF with inverse sentence frequency (ISF) and inverse term frequency
(ITF). A direct comparison reveals that all language models are highly
correlated; however, the average ISF and ITF values are 5.5 and 10.4 higher
than IDF. All language models appeared to follow a power law distribution with
a slope coefficient of 1.6 for documents and 1.7 for sentences and terms. We
conclude with an analysis of IDF stability with respect to random, journal, and
section partitions of the 100,830 full-text scientific articles in our
experimental corpus.</span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Thursday 20th July 900am¡V930am</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>Best Asian
Language Paper Nominees<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=AbstractTitle><a name=b9A1></a>Tree-to-String Alignment Template for
Statistical Machine Translation</p>

<p class=AbstractAuthor>Yang Liu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Liu, Y.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Qun Liu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Liu, Q.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Shouxun Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We present a novel translation model based on
tree-to-string<span style='mso-ansi-language:EN-GB'> </span>alignment template
(TAT) which describes the alignment between a<span style='mso-ansi-language:
EN-GB'> </span>source parse tree and a target string. A TAT is capable of<span
style='mso-ansi-language:EN-GB'> </span>generating both terminals and
non-terminals and performing<span style='mso-ansi-language:EN-GB'> </span>reordering
at both low and high levels. The model is<span style='mso-ansi-language:EN-GB'>
</span>linguistically syntax-based because TATs are extracted<span
style='mso-ansi-language:EN-GB'> </span>automatically from word-aligned, source
side parsed parallel<span style='mso-ansi-language:EN-GB'> </span>texts. To
translate a source sentence, we first employ a parser to<span style='mso-ansi-language:
EN-GB'> </span>produce a source parse tree and then apply TATs to transform the<span
style='mso-ansi-language:EN-GB'> </span>tree into a target string. Our
experiments show that the TAT-based model<span lang=EN-GB style='mso-ansi-language:
EN-GB'> significantly outperforms </span>Pharaoh, a state-of-the-art decoder
for phrase-based models.</p>

<p class=AbstractTitle><a name=b9B1></a>Incorporating speech recognition
confidence into discriminative named entity recognition of speech data</p>

<p class=AbstractAuthor>Katsuhito Sudoh<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sudoh, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hajime Tsukada<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsukada, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hideki Isozaki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Isozaki, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper proposes a named entity recognition (<st1:stockticker>NER</st1:stockticker>)
method for speech recognition results that uses confidence on automatic speech
recognition (<st1:stockticker>ASR</st1:stockticker>) as a feature. The <st1:stockticker>ASR</st1:stockticker>
confidence feature indicates whether each word has been correctly recognized.
The <st1:stockticker>NER</st1:stockticker> model is trained using <st1:stockticker>ASR</st1:stockticker>
results with named entity (NE) labels as well as the corresponding
transcriptions with NE labels. In experiments using support vector machines
(SVMs) and speech data from Japanese newspaper articles, the proposed method
outperformed a simple application of text-based <st1:stockticker>NER</st1:stockticker>
to <st1:stockticker>ASR</st1:stockticker> results in <st1:stockticker>NER</st1:stockticker>
F-measure by improving precision. These results show that the proposed method
is effective in <st1:stockticker>NER</st1:stockticker> for noisy inputs.</p>

<p class=AbstractTitle><a name=b9C1></a>Exploiting Syntactic Patterns as Clues
in Zero-Anaphora Resolution</p>

<p class=AbstractAuthor>Ryu Iida<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Iida, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->,<span style='mso-bidi-font-weight:
bold'> Kentaro Inui</span><!--[if supportFields]><span style='mso-bidi-font-weight:
bold'><span style='mso-element:field-begin'></span></span> XE &quot;<span
style='mso-bidi-font-weight:bold'>Inui, K.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-bidi-font-weight:bold'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-bidi-font-weight:bold'><span
style='mso-spacerun:yes'>&nbsp;</span>and Yuji Matsumoto</span><!--[if supportFields]><span
style='mso-bidi-font-weight:bold'><span style='mso-element:field-begin'></span></span>
XE &quot;Matsumoto, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-bidi-font-weight:bold'><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We approach the
zero-anaphora resolution problem by decomposing it into intra-sentential and
inter-sentential zero-anaphora resolution. For the former problem, syntactic patterns
of the appearance of zero-pronouns and their antecedents are useful clues.
Taking Japanese as a target language, we empirically demonstrate that
incorporating rich syntactic pattern features in a state-of-the-art
learning-based anaphora resolution model dramatically improves the accuracy of
intra-sentential zero-anaphora, which consequently improves the overall
performance of zero-anaphora resolution.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b9D1></a>Self-Organizing n-gram Model for
Automatic Word Spacing</p>

<p class=AbstractAuthor>Seong-Bae Park<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Park, S-B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yoon-Shik Tae<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tae, Y-S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Se-Young Park<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Park, S-Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Automatic
word spacing is one of the important tasks in Korean language processing and
information retrieval. Since there are a number of confusing cases in word
spacing of Korean, there are some mistakes in many texts including news
articles. This paper presents a high-accurate method for automatic word spacing
based on self-organizing n-gram model. This method is basically a variant of
n-gram model, but achieves high accuracy by automatically adapting context
size.<o:p></o:p></span></p>

<p class=MsoNormal style='text-align:justify;text-justify:inter-ideograph'><span
lang=EN-GB style='mso-bidi-font-family:Arial;mso-ansi-language:EN-GB'>In order
to find the optimal context size, the proposed method automatically increases
the context size when the contextual distribution after increasing it does not
agree with that of the current context. It also decreases the context size when
the distribution of reduced context is similar to that of the current context.
This approach achieves high accuracy by considering higher dimensional data in
case of necessity, and the increased computational cost are compensated by the
reduced context size. The experimental results show that the self-organizing
structure of n-gram model enhances the basic model.<o:p></o:p></span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Thursday 20th July 1030am¡V1230pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>10A: Asian
Language Processing<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Michael White<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b10A1></a>Concept Unification of Terms in
Different Languages for IR</p>

<p class=AbstractAuthor>Qing Li<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Li, Q.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Sung-Hyon Myaeng<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Myaeng, S-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yun Jin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Jin, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Bo-yeong Kang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kang, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Due to the historical and cultural reasons, English
phases, especially the<span style='mso-ansi-language:EN-GB'> </span>proper
nouns and new words, frequently appear in Web pages written primarily in<span
style='mso-ansi-language:EN-GB'> </span>Asian languages such as Korean and
Chinese. Although these English terms and<span style='mso-ansi-language:EN-GB'>
</span>their equivalences in the Asian language refer to the same concept, they
are<span style='mso-ansi-language:EN-GB'> </span>erroneously treated as
independent index units in traditional Information<span style='mso-ansi-language:
EN-GB'> </span>Retrieval (IR). This paper describes the degree to which the
problem arises in<span style='mso-ansi-language:EN-GB'> </span>IR and suggests
a novel technique to solve it. Our method firstly extracts the English phrase
from Asian language Web pages, and then unifies the extracted phrase and its
equivalence(s) in the language<span style='mso-ansi-language:EN-GB'> </span>as
one index unit. Experimental results show that the high precision of our<span
style='mso-ansi-language:EN-GB'> </span>conceptual unification approach greatly
improves the IR performance.</p>

<p class=AbstractTitle><a name=b10A2></a>Word Alignment in English-Hindi
Parallel Corpus Using Recency-Vector Approach: Some Studies</p>

<p class=AbstractAuthor>Niladri Chatterjee<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chatterjee, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Saumya Agrawal<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Agrawal, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Word alignment using
recency-vector</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'>
</span><span style='mso-font-kerning:0pt'>based approach has recently become
popular.</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>One major advantage of these techniques</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>is that unlike other approaches they</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>perform well even if the size of the parallel</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>corpora is small. This makes these</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>algorithms worth-studying for languages</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>where resources are scarce. In this work</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>we studied the performance of two very</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>popular recency-vector based approaches,</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>proposed in (Fung and McKeown, 1994)</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>and (Somers, 1998), respectively, for word</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>alignment in English-Hindi parallel corpus.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>But performance of the above algorithms</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>was not found to be satisfactory.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>However, subsequent addition of</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>some new constraints improved the performance</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>of the recency-vector based alignment</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>technique significantly for the said</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>corpus. The present paper discusses the</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>new version of the algorithm and its</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>performance</span><span style='mso-font-kerning:
0pt;mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>in
detail.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b10A3></a>Extracting loanwords from Mongolian
corpora and producing a Japanese-Mongolian bilingual dictionary</p>

<p class=AbstractAuthor>Badam-Osor Khaltar<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Khaltar, B-O.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Atsushi Fujii<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Fujii, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Tetsuya Ishikawa<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ishikawa, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper proposes methods for extracting loanwords from
Cyrillic Mongolian corpora and producing a Japanese¡VMongolian bilingual
dictionary. We extract loanwords from Mongolian corpora using our own
handcrafted rules. To complement the rule-based extraction, we also extract
words in Mongolian corpora that are phonetically similar to Japanese Katakana
words as loanwords. In addition, we correspond the extracted loanwords to
Japanese words and produce a bilingual dictionary. We propose a stemming method
for Mongolian to extract loanwords correctly. We verify the effectiveness of
our methods experimentally.<span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>10B: Morphology
and Word Segmentation<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Yuji Matsumoto<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b10B1></a>An Unsupervised Morpheme-Based HMM for
Hebrew Morphological Disambiguation </p>

<p class=AbstractAuthor>Meni Adler<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Adler, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Michael Elhadad<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Elhadad, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Morphological disambiguation is the process of assigning
one set of morphological features to each individual word in a text.<span
style='mso-spacerun:yes'>&nbsp; </span>When the word is ambiguous (there are
several possible analyses for the word), a disambiguation procedure based on
the word context must be applied. This paper deals with morphological
disambiguation of the Hebrew language, which combines morphemes into a word in
both agglutinative and fusional ways.<span style='mso-spacerun:yes'>&nbsp;
</span>We present an unsupervised stochastic model - the only resource we use
is a morphological analyzer - which deals with the data sparseness problem
caused by the affixational morphology of the Hebrew language.</p>

<p class=MsoBodyText>We present a text encoding method for languages with
affixational morphology in which the knowledge of word formation rules (which
are quite restricted in Hebrew) helps in the disambiguation. We adapt HMM
algorithms for learning and searching this text representation, in such a way
that segmentation and tagging can be learned in parallel in one step. Results
on a large-scale evaluation indicate that this learning improves disambiguation
for complex tag sets.<span style='mso-spacerun:yes'>&nbsp; </span>Our method is
applicable to other languages with affix morphology.</p>

<p class=AbstractTitle><a name=b10B2></a>Contextual Dependencies in
Unsupervised Word Segmentation</p>

<p class=AbstractAuthor>Sharon Goldwater<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Goldwater, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Thomas L. Griffiths<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Griffiths, T.L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mark Johnson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Johnson, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Developing better methods for segmenting continuous text
into words is important for improving the processing of Asian languages, and
may shed light on how humans learn to segment speech.<span
style='mso-spacerun:yes'>&nbsp; </span>We propose two new Bayesian word
segmentation methods that assume unigram and bigram models of word dependencies
respectively.<span style='mso-spacerun:yes'>&nbsp; </span>The bigram model
greatly outperforms the unigram model (and previous probabilistic models), demonstrating
the importance of such dependencies for word segmentation.<span
style='mso-spacerun:yes'>&nbsp; </span>We also show that previous probabilistic
models rely crucially on suboptimal search procedures.</p>

<p class=AbstractTitle><a name=b10B3></a>MAGEAD: A Morphological Analyzer and
Generator for the Arabic Dialects</p>

<p class=AbstractAuthor>Nizar Habash<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Habash, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Owen Rambow<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Rambow, O.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We present MAGEAD, a morphological analyzer and generator
for the Arabic language family.<span style='mso-spacerun:yes'>&nbsp; </span>Our
work is novel in that it explicitly addresses the need for processing the
morphology of the dialects. MAGEAD performs an on-line analysis to or
generation from a root+pattern+features representation, it has separate
phonological and orthographic representations, and it allows for combining<span
style='mso-spacerun:yes'>&nbsp;&nbsp; </span>morphemes from different dialects.<span
style='mso-spacerun:yes'>&nbsp; </span>We present a detailed evaluation of
MAGEAD.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>10C: Tagging and
Chunking<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Jan Haji&#269;<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b10C1></a>Noun Phrase Chunking in Hebrew ¡V
Influence of Lexical and Morphological Features</p>

<p class=AbstractAuthor>Yoav Goldberg<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Goldberg, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Meni Adler<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Adler, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Michael Elhadad<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Elhadad, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We present a method for Noun Phrase chunking in Hebrew. We
show that the traditional definition of base-NPs as non-recursive noun phrases
does not apply in Hebrew, and propose an alternative definition of Simple
NPs.<span style='mso-spacerun:yes'>&nbsp; </span>We review syntactic properties
of Hebrew related to noun phrases, which indicate that the task of Hebrew
SimpleNP chunking is harder than base-NP chunking in English. As a
confirmation, we apply methods known to work well for English to Hebrew data.
These methods give low results (F from 76 to 86) in Hebrew. We then discuss our
method, which applies <st1:stockticker>SVM</st1:stockticker> induction over
lexical and morphological features. Morphological features improve the average
precision by ~0.5%, recall by ~1%, and F-measure by ~0.75, resulting in a
system with average performance of 93% precision, 93.4% recall and 93.2
F-measure.</p>

<p class=AbstractTitle><a name=b10C2></a>Multi-Tagging for Lexicalized-Grammar
Parsing</p>

<p class=AbstractAuthor>James R. Curran<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Curran, J.R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Stephen Clark<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Clark, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and David Vadas<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Vadas, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>With performance above
97% accuracy for newspaper text, part of speech (</span><st1:stockticker><span
 style='mso-font-kerning:0pt'>POS</span></st1:stockticker><span
style='mso-font-kerning:0pt'>) tagging might be considered a solved problem.
Previous studies have shown that allowing the parser to resolve </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>POS</span></st1:stockticker><span
style='mso-font-kerning:0pt'> tag ambiguity does not improve performance.
However, for grammar formalisms which use more fine-grained grammatical
categories, for example </span><st1:stockticker><span style='mso-font-kerning:
 0pt'>TAG</span></st1:stockticker><span style='mso-font-kerning:0pt'> and </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>CCG</span></st1:stockticker><span
style='mso-font-kerning:0pt'>, tagging accuracy is much lower. In fact, for
these formalisms, premature ambiguity resolution makes parsing infeasible.<o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We describe a
multi-tagging approach which maintains a suitable level of lexical category
ambiguity for accurate and efficient </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>CCG</span></st1:stockticker><span
style='mso-font-kerning:0pt'> parsing. We extend this multi-tagging approach to
the </span><st1:stockticker><span style='mso-font-kerning:0pt'>POS</span></st1:stockticker><span
style='mso-font-kerning:0pt'> level to overcome errors introduced by
automatically assigned </span><st1:stockticker><span style='mso-font-kerning:
 0pt'>POS</span></st1:stockticker><span style='mso-font-kerning:0pt'> tags.
Although </span><st1:stockticker><span style='mso-font-kerning:0pt'>POS</span></st1:stockticker><span
style='mso-font-kerning:0pt'> tagging accuracy seems high, maintaining some </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>POS</span></st1:stockticker><span
style='mso-font-kerning:0pt'> tag ambiguity in the language processing pipeline
results in more accurate </span><st1:stockticker><span style='mso-font-kerning:
 0pt'>CCG</span></st1:stockticker><span style='mso-font-kerning:0pt'>
supertagging.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b10C3></a>Guessing Parts-of-Speech of Unknown
Words Using Global Information</p>

<p class=AbstractAuthor>Tetsuji Nakagawa<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nakagawa, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Yuji Matsumoto<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Matsumoto, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>In this paper, we
present a method for</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>guessing </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>POS</span></st1:stockticker><span
style='mso-font-kerning:0pt'> tags of unknown words using</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>local and global information. Although</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>many existing methods use only</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>local information (i.e. limited window</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>size or intra-sentential features), global
information</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>(extra-sentential features) provides</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>valuable clues for predicting </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>POS</span></st1:stockticker><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>tags of unknown words. We propose a</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>probabilistic model for </span><st1:stockticker><span
 style='mso-font-kerning:0pt'>POS</span></st1:stockticker><span
style='mso-font-kerning:0pt'> guessing of</span><span style='mso-font-kerning:
0pt;mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>unknown
words using global information</span><span style='mso-font-kerning:0pt;
mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>as well as
local information, and estimate</span><span style='mso-font-kerning:0pt;
mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>its
parameters using Gibbs sampling. We</span><span style='mso-font-kerning:0pt;
mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>also
attempt to apply the model to semisupervised</span><span style='mso-font-kerning:
0pt;mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>learning,
and conduct experiments</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>on multiple corpora.</span><span
style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>SRW</span></st1:stockticker><span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'> 1: Multilinguality<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Marine Carpuat<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b10D1></a>S1<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Discursive
Usage of Six Chinese Punctuation Marks</p>

<p class=AbstractAuthor>Ming Yue<span style='mso-tab-count:1'>&nbsp; </span></p>

<p class=MsoBodyText>Both rhetorical structure and punctuation have been helpful
in discourse processing. Based on a corpus annotation project, this paper
reports the discursive usage of 6 Chinese punctuation marks in news commentary
texts: Colon, Dash, Ellipsis, Exclamation Mark, Question Mark, and Semicolon.
The rhetorical patterns of these marks are compared against patterns around cue
phrases in general. Results show that these Chinese punctuation marks, though
fewer in number than cue phrases, are easy to identify, have strong correlation
with certain relations, and can be used as distinctive indicators of nuclearity
in Chinese texts.<span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span
style='mso-tab-count:3'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b10D2></a>S2<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Integrated
Morphological and Syntactic Disambiguation for Modern Hebrew</p>

<p class=AbstractAuthor>Reut Tsarfaty</p>

<p class=MsoBodyText>Current parsing models are not immediately applicable for
languages that exhibit strong interaction between morphology and syntax, e.g.,
Modern Hebrew (MH), Arabic and other Semitic languages. This work represents a
first attempt at modeling morphological-syntactic interaction in a generative
probabilistic framework to allow for MH parsing. We show that morphological
information selected in tandem with syntactic categories is instrumental for
parsing Semitic languages. We further show that redundant morphological
information helps syntactic disambiguation.<span style='mso-tab-count:4'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b10D3></a>S3<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>A
Hybrid Relational Approach for WSD</p>

<p class=AbstractAuthor>Lucia Specia</p>

<p class=MsoBodyText>We present a novel hybrid approach for Word Sense
Disambiguation (WSD) which makes use of a relational formalism to represent
instances and background knowledge. It is built using Inductive Logic
Programming techniques to combine evidence coming from both sources during the
learning process, producing a rule-based WSD model. We experimented with this
approach to disambiguate 7 highly ambiguous verbs in English- Portuguese
translation. Results showed that the approach is promising, achieving an average
accuracy of 75%, which outperforms the other machine learning techniques
investigated (66%).<span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span
style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=MsoNormal><span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Thursday 20th July 230pm¡V330pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>11A: Machine
Translation IV<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Alon Lavie<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b11A1></a>A Clustered Global Phrase Reordering
Model for Statistical Machine Translation</p>

<p class=AbstractAuthor>Masaaki Nagata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nagata, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Kuniko Saito<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Saito, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Kazuhide Yamamoto<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yamamoto, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kazuteru Ohashi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ohashi, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>In this paper, we present a novel global reordering model
that can be incorporated into standard phrase-based statistical machine
translation. Unlike previous local reordering models that emphasize the
reordering of adjacent phrase pairs [Tillmann-Zhang05], our model explicitly
models the reordering of long distances by directly estimating the parameters
from the phrase alignments of bilingual training sentences. In principle, the
global phrase-reordering model is conditioned on the source and target phrases
that are currently being translated, and the previously translated source and target
phrases. To cope with sparseness, we use N-best phrase alignments and bilingual
phrase clustering, and investigate a variety of combinations of conditioning
factors. Through experiments, we show, that the global reordering model
significantly improves the translation accuracy of a standard Japanese-English
translation task.</p>

<p class=AbstractTitle><a name=b11A2></a>A Discriminative Global Training
Algorithm for Statistical MT</p>

<p class=AbstractAuthor>Christoph Tillmann<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tillmann, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Tong Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper presents a novel training algorithm for a linearly-scored block sequence
translation model. The key component is a new procedure to directly optimize
the global scoring function used by a </span><st1:stockticker><span lang=EN-GB
 style='mso-ansi-language:EN-GB'>SMT</span></st1:stockticker><span lang=EN-GB
style='mso-ansi-language:EN-GB'> decoder.<span style='mso-spacerun:yes'>&nbsp;
</span>No translation, language, or distortion model probabilities are used as
in earlier work on </span><st1:stockticker><span lang=EN-GB style='mso-ansi-language:
 EN-GB'>SMT</span></st1:stockticker><span lang=EN-GB style='mso-ansi-language:
EN-GB'>. Therefore our method, which employs less domain specific knowledge, is
both simpler and more extensible than previous approaches. Moreover, the
training procedure treats the decoder as a black-box, and thus can be used to
optimize any decoding scheme. The training algorithm is evaluated on a standard
Arabic-English translation task.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>11B: Speech<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=MsoBodyText>Session Chair: Roland Kuhn<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b11B1></a>Phoneme-to-Text Transcription System
with an Infinite Vocabulary</p>

<p class=AbstractAuthor>Shinsuke Mori<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mori, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Daisuke Takuma<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Takuma, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Gakuto Kurata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kurata, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>The noisy
channel model approach is successfully applied to various natural language
processing tasks. Currently the main research focus of this approach is
adaptation methods, how to capture characteristics of words and expressions in
a target domain given example sentences in that domain. As a solution we
describe a method enlarging the vocabulary of a language model to an almost
infinite size and capturing their context information. Especially the new
method is suitable for languages in which words are not delimited by
whitespace. We applied our method to a phoneme-to-text transcription task in
Japanese and reduced about 10% of the errors in the results of an existing
method.</span><span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b11B2></a>Automatic Generation of Domain Models
for Call Centers from Noisy Transcriptions</p>

<p class=AbstractAuthor>Shourya Roy<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Roy, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and L Venkata Subramaniam<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Subramaniam, L.V.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Call centers handle
customer queries from various domains such as computer sales and support,
mobile phones, car rental, etc. Each such domain generally has a domain model
which is essential to handle customer complaints. These models contain common
problem categories, typical customer issues and their solutions, greeting
styles. Currently these models are manually created over time. Towards this, we
propose an unsupervised technique to generate domain models automatically from
call transcriptions. We use a state of the art Automatic Speech Recognition
system to transcribe the calls between agents and customers, which still
results in high word error rates (40%) and show that even from these noisy
transcriptions of calls we can automatically build a domain model. The domain
model is comprised of primarily a topic taxonomy where every node is
characterized by topic(s), typical Questions-Answers (Q&amp;As), typical
actions and call statistics. We show how such a domain model can be used for
topic identification of unseen calls. We also propose applications for aiding
agents while handling calls and for agent monitoring based on the domain model.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>11C: Discourse<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Daniel Marcu<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b11C1></a>Proximity in Context: an empirically
grounded computational model of proximity for processing topological spatial
expressions</p>

<p class=AbstractAuthor>John D. Kelleher<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kelleher, J.D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Geert-Jan M. Kruijff<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kruijff, G-J. M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Fintan J. Costello<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Costello, F.J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>The paper presents a new model for context-dependent
interpretation of linguistic expressions about spatial proximity between
objects in a natural scene. The paper discusses novel psycholinguistic
experimental data that tests and verifies the model. The model has been
implemented, and enables a conversational robot to identify objects in a scene
through topological spatial relations (e.g. ¡§X near Y''). The model can help
motivate the choice between topological and projective prepositions.<span
style='mso-tab-count:1'>&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b11C2></a>Machine Learning of Temporal Relations
</p>

<p class=AbstractAuthor>Inderjeet Mani<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mani, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Marc Verhagen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Verhagen, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ben Wellner<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wellner, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chong Min Lee<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lee, C.M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and James Pustejovsky<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pustejovsky, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper investigates a machine learning approach for
temporally ordering and anchoring events in natural language texts. To address
data sparseness, we used temporal reasoning as an over-sampling method to
dramatically expand the amount of training data, resulting in predictive
accuracy on link labeling as high as 93% using a Maximum Entropy classifier on
human annotated data. This method compared favorably against a series of
increasingly sophisticated baselines involving expansion of rules derived from
human intuitions.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>SRW</span></st1:stockticker><span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'> 2: Speech<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Kevin Duh<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b11D1></a>S4<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>On2L
- A Framework for Incremental Ontology Learning in Spoken Dialog Systems</p>

<p class=AbstractAuthor>Berenike Loos</p>

<p class=MsoBodyText>An open-domain spoken dialog system has to deal with the
challenge of lacking lexical as well as conceptual knowledge. As the real world
is constantly changing, it is not possible to store all necessary knowledge
beforehand. Therefore, this knowledge has to be acquired during the run time of
the system, with the help of the out-of-vocabulary information of a speech
recognizer. As every word can have various meanings depending on the context in
which it is uttered, additional context information is taken into account, when
searching for the meaning of such a word. In this paper, I will present the
incremental ontology learning framework On2L. The defined tasks for the
framework are: the hypernym extraction from Internet texts for unknown terms
delivered by the speech recognizer; the mapping of those and their hypernyms
into ontological concepts and instances; and the following integration of them
into the system¡¦s ontology.<span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b11D2></a>S5<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Focus
to Emphasize Tone Structures for Prosodic Analysis in Spoken Language
Generation</p>

<p class=AbstractAuthor>Lalita Narupiyakul<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=MsoBodyText>We analyze the concept of focus in speech and the
relationship between focus and speech acts for prosodic generation. We
determine how the speaker¡¦s utterances are influenced by speaker¡¦s intention.
The relationship between speech acts and focus information is used to define
which parts of the sentence serve as the focus parts. We propose the Focus to
Emphasize Tones (FET) structure to analyze the focus components. We also design
the FET grammar to analyze the intonation patterns and produce tone marks as a
result of our analysis. We present a proof-of-the-concept working example to
validate our proposal. More comprehensive evaluations are part of our current
work.<span style='mso-tab-count:4'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Thursday 20th July <span style='font-size:10.0pt;mso-bidi-font-size:14.0pt'>400pm</span>¡V530pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>12A: Machine
Translation V<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Alon Lavie<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12A1></a>An End-to-End Discriminative Approach
to Machine Translation</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Percy Liang</span><!--[if supportFields]><span
style='mso-element:field-begin'></span><span lang=FR style='mso-ansi-language:
FR'> XE &quot;Liang, P.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'>, Alexandre Bouchard-C&ocirc;t&eacute;</span><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span>
XE &quot;Bouchard-C&ocirc;t&eacute;, A.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'>, Dan Klein</span><!--[if supportFields]><span
style='mso-element:field-begin'></span><span lang=FR style='mso-ansi-language:
FR'> XE &quot;Klein, D.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><span style='mso-spacerun:yes'>&nbsp;</span>and
Ben Taskar</span><!--[if supportFields]><span lang=FR style='mso-ansi-language:
FR'><span style='mso-element:field-begin'></span> XE &quot;Taskar, B.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We present a
perceptron-style discriminative approach to machine translation in which large
feature sets can be exploited. Unlike discriminative reranking approaches, our
system can take advantage of learned features in all stages of decoding. We
first discuss several challenges to error-driven discriminative approaches. In
particular, we explore different ways of updating parameters given a training
example. We find that making frequent but smaller updates is preferable to
making fewer but larger updates. Then, we discuss an array of features and show
both how they quantitatively increase BLEU score and how they qualitatively
interact on specific examples. One particular feature we investigate is a novel
way to introduce learning into the initial phrase extraction process, which has
previously been entirely heuristic.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b12A2></a>Semi-Supervised Training for
Statistical Word Alignment</p>

<p class=AbstractAuthor>Alexander Fraser<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Fraser, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Daniel Marcu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Marcu, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We introduce a semi-supervised approach to training for
statistical machine translation that alternates the traditional Expectation
Maximization step that is applied on a large training corpus with a
discriminative step aimed at increasing word-alignment quality on a small,
manually word-aligned sub-corpus. We show that our algorithm leads not only to
improved alignments but also to machine translation outputs of higher quality.</p>

<p class=AbstractTitle><a name=b12A3></a>Left-to-Right Target Generation for
Hierarchical Phrase-based Translation</p>

<p class=AbstractAuthor>Taro Watanabe<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Watanabe, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hajime Tsukada<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsukada, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hideki Isozaki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Isozaki, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We present a hierarchical
phrase-based statistical machine translation in which</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>a target sentence is efficiently generated in
left-to-right order. The model is</span><span style='mso-font-kerning:0pt;
mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>a class of
synchronous-CFG with a Greibach Normal Form-like structure for the</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>projected production rule:</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>The paired target-side of a production rule takes
a phrase-prefixed form. The</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>decoder for the
target-normalized form is based on an Early-style top down</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>parser on the source side. The target-normalized
form coupled with our top down</span><span style='mso-font-kerning:0pt;
mso-ansi-language:EN-GB'> </span><span style='mso-font-kerning:0pt'>parser
implies a left-to-right generation of translations which enables us a</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>straightforward integration with ngram language
models. Our model was</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>experimented on a
Japanese-to-English newswire translation task, and showed</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>statistically significant performance improvements
against a phrase-based</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>translation system.</span><span
style='mso-tab-count:1'>&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>12B: Lexical
Issues </span><st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:
 13.0pt'>III</span></st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:
13.0pt'><span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=MsoBodyText>Session Chair: Nicoletta Calzolari<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12B1></a>You Can't Beat Frequency (Unless You
Use Linguistic Knowledge) ¡V A Qualitative Evaluation of Association Measures
for Collocation and Term Extraction</p>

<p class=AbstractAuthor>Joachim Wermter<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wermter, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Udo Hahn<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hahn, U.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>In the past years, a number of lexical association
measures have been studied to help extract new scientific terminology or general-language
collocations. The implicit assumption of this research was that newly designed
term measures involving more sophisticated statistical criteria would
outperform simple counts of co-occurrence frequencies. We here explicitly test
this assumption. By way of four qualitative criteria, we show that purely
statistics-based measures reveal virtually no difference compared with
frequency of occurrence counts, while linguistically more informed metrics do
reveal such a marked difference.</p>

<p class=AbstractTitle><a name=b12B2></a>Ontologizing Semantic Relations</p>

<p class=AbstractAuthor>Marco Pennacchiotti<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pennacchiotti, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Patrick Pantel<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pantel, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Many algorithms have
been developed to harvest lexical semantic resources, however few have linked
the mined knowledge into formal knowledge repositories. In this paper, we
propose two algorithms for automatically ontologizing (attaching) semantic
relations into WordNet. We present an empirical evaluation on the task of
attaching partof and causation relations, showing an improvement on F-score
over a baseline model.</span><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12B3></a>Semantic Taxonomy Induction from
Heterogenous Evidence </p>

<p class=AbstractAuthor>Rion Snow<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Snow, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Daniel Jurafsky<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Jurafsky, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Andrew Y. Ng<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ng, A.Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We propose a novel
algorithm for inducing semantic taxonomies. Previous algorithms for taxonomy
induction have typically focused on independent classifiers for discovering new
single relationships based on hand-constructed or automatically discovered
textual patterns. By contrast, our algorithm flexibly incorporates evidence
from multiple classifiers over heterogenous relationships to optimize the
entire structure of the taxonomy, using knowledge of a word¡¦s coordinate terms
to help in determining its hypernyms, and vice versa. We apply our algorithm on
the problem of sense-disambiguated noun hyponym acquisition, where we combine
the predictions of hypernym and coordinate term classifiers with the knowledge
in a preexisting semantic taxonomy (WordNet 2.1). We add 10; 000 novel synsets
to WordNet 2.1 at 84% precision, a relative error reduction of 70% over a
non-joint algorithm using the same component classifiers. Finally, we show that
a taxonomy built using our algorithm shows a 23% relative F-score improvement
over WordNet 2.1 on an independent testset of hypernym pairs.</span><span
style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span
style='mso-tab-count:4'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>12C: Information
Extraction </span><st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:
 13.0pt'>III</span></st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:
13.0pt'><span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Yorick Wilks<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12C1></a>Names and Similarities on the Web:
Fact Extraction in the Fast Lane</p>

<p class=AbstractAuthor>Marius Pa&#351;ca<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pa&#351;ca, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Dekang Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jeffrey Bigham<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bigham, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Andrei Lifchits<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lifchits, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Alpa Jain<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Jain, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>In a new approach to
large-scale extraction of facts from unstructured text, distributional
similarities become an integral part of both the iterative acquisition of
high-coverage contextual extraction patterns, and the validation and ranking of
candidate facts. The evaluation measures the quality and coverage of facts
extracted from one hundred million Web documents, starting from ten seed facts
and using no additional knowledge, lexicons or complex tools.</span><span
style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12C2></a>Weakly Supervised Named Entity
Transliteration and Discovery from Multilingual Comparable Corpora</p>

<p class=AbstractAuthor>Alexandre Klementiev<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Klementiev, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dan Roth<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Roth, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Named Entity
recognition (</span><st1:stockticker><span style='mso-font-kerning:0pt'>NER</span></st1:stockticker><span
style='mso-font-kerning:0pt'>) is an important part of many natural language
processing tasks. Current approaches often employ machine-learning techniques
and require supervised data. However, many languages lack such resources. This
paper presents an (almost) unsupervised learning algorithm for automatic
discovery of Named Entities (NEs) in a resource free language, given a
bilingual corpora in which it is weakly temporally aligned with a resource rich
language. NEs have similar time distributions across such corpora, and often
some of the tokens in a multi-word NE are transliterated. We develop an
algorithm that exploits both observations iteratively. The algorithm makes use
of a new, frequency based, metric for time distributions and a resource free
discriminative approach to transliteration. Seeded with a small number of
transliteration pairs, our algorithm discovers multi-word NEs, and takes
advantage of a dictionary (if one exists) to account for translated or
partially translated NEs. We evaluate the algorithm on an English-Russian
corpus, and show high level of NEs discovery in Russian.</span><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span
style='mso-tab-count:5'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12C3></a>A Composite Kernel to Extract
Relations between Entities with both Flat and Structured Features</p>

<p class=AbstractAuthor>Min Zhang<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Zhang, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jie Zhang<!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span></span>
XE &quot;Zhang, J.(1)&quot; <![endif]--><!--[if supportFields]><span lang=FR
style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]-->,
Jian Su<!--[if supportFields]><span style='mso-element:field-begin'></span> XE
&quot;Su, J.&quot; <![endif]--><!--[if supportFields]><span style='mso-element:
field-end'></span><![endif]--><span style='mso-spacerun:yes'>&nbsp;</span>and
Guodong Zhou<!--[if supportFields]><span style='mso-element:field-begin'></span>
XE &quot;Zhou, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper proposes a
novel composite kernel for relation extraction. The composite kernel consists
of two individual kernels: an entity kernel that allows for entity-related
features and a convolution parse tree kernel that models syntactic information
of relation examples. The motivation of our method is to fully utilize the nice
properties of kernel methods to explore diverse knowledge for relation
extraction. Our study illustrates that the composite kernel can effectively
capture both flat and structured features without the need for extensive
feature engineering, and can also easily scale to include more features.
Evaluation on the ACE corpus shows that our method outperforms the previous
best-reported methods and significantly outperforms previous two dependency
tree kernels for relation extraction.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>SRW</span></st1:stockticker><span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'> 3: Parsing<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Stephen Wan<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12D1></a>S6<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Extraction
of Tree Adjoining Grammars from a Treebank for Korean</p>

<p class=AbstractAuthor>Jungyeul Park</p>

<p class=MsoBodyText>We present the implementation of a system which extracts
not only lexicalized grammars but also feature-based lexicalized grammars from
Korean Sejong Treebank. We report on some practical experiments where we
extract <st1:stockticker>TAG</st1:stockticker> grammars and tree schemata.
Above all, full-scale syntactic tags and well-formed morphological analysis in
Sejong Treebank allow us to extract syntactic features. In addition, we modify
Treebank for extracting lexicalized grammars and convert lexicalized grammars
into tree schemata to resolve limited lexical coverage problem of extracted
lexicalized grammars.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12D2></a>S7<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Parsing
and Subcategorization Data</p>

<p class=AbstractAuthor>Jianguo Li<span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=MsoBodyText>In this paper, we compare the performance of a
state-of-the-art statistical parser (Bikel, 2004) in parsing written and spoken
language and in generating subcategorization cues from written and spoken
language. Although Bikel¡¦s parser achieves a higher accuracy for parsing
written language, it achieves a higher accuracy when extracting
subcategorization cues from spoken language. Additionally, we explore the
utility of punctuation in helping parsing and extraction of subcategorization
cues. Our experiments show that punctuation is of little help in parsing spoken
language and extracting subcategorization cues from spoken language. This
indicates that there is no need to add punctuation in transcribing spoken
corpora simply in order to help parsers.<span style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b12D3></a>S8<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Clavius:
Bi-Directional Parsing for Generic Multimodal Interaction</p>

<p class=AbstractAuthor>Frank Rudzicz</p>

<p class=MsoBodyText>We introduce a new multi-threaded parsing algorithm on
unification grammars designed specifically for multimodal interaction and noisy
environments. By lifting some traditional constraints, namely those related to
the ordering of constituents, we overcome several difficulties of other systems
in this domain. We also present several criteria used in this model to
constrain the search process using dynamically loadable scoring functions. Some
early analyses of our implementation are discussed.</p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><span style='font-size:10.0pt;mso-bidi-font-size:14.0pt'>Friday</span> 21st
July 1000am¡V1030am</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>13A: Parsing VI<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Srinivas Bangalore<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b13A1></a>Japanese Dependency Parsing Using
Co-occurrence Information and a Combination of Case Elements</p>

<p class=AbstractAuthor>Takeshi Abekawa<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Abekawa, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Manabu Okumura<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Okumura, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>In this paper, we
present a method that improves Japanese dependency parsing by using large-scale
statistical information. It takes into account two kinds of information not
considered in previous statistical (machine learning based) parsing methods:
information about dependency relations among the case elements of a verb, and
information about co-occurrence relations between a verb and its case element.
This information can be collected from the results of automatic dependency
parsing of large-scale corpora. The results of an experiment in which our
method was used to rerank the results obtained using an existing machine
learning based parsing method showed that our method can improve the accuracy
of the results obtained using the existing method.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>13B: Question
Answering I<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Dan Moldovan<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b13B1></a>Answer Extraction, Semantic
Clustering, and Extractive Summarization for Clinical Question Answering</p>

<p class=AbstractAuthor>Dina Demner-Fushman<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Demner-Fushman, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jimmy Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper presents a
hybrid approach</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'>
</span><span style='mso-font-kerning:0pt'>to question answering in the clinical</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>domain that combines techniques from</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>summarization and information retrieval.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>We tackle a frequently-occurring class of</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>questions that takes the form ¡§What is</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>the best drug treatment for X?¡¨ Starting</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>from an initial set of MEDLINE citations,</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>our system first identifies the drugs under</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>study. Abstracts are then clustered using</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>semantic classes from the UMLS ontology.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>Finally, a short extractive summary</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>is generated for each abstract to populate</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>the clusters. Two evaluations¡Xa</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>manual one focused on short answers and</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>an automatic one focused on the supporting</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>abstracts¡Xdemonstrate that our system</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>compares favorably to PubMed, the</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>search system most widely used by physicians</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>today.</span><span style='mso-tab-count:1'>&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>13C: Semantics </span><st1:stockticker><span
 style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>III</span></st1:stockticker><span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'><span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Alexander Koller<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b13C1></a>Discovering asymmetric entailment
relations between verbs using selectional preferences</p>

<p class=AbstractAuthor>Fabio Massimo Zanzotto<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zanzotto, F.M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Marco Pennacchiotti<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pennacchiotti, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Maria Teresa Pazienza<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pazienza, M.T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In this
paper we investigate a novel method to detect asymmetric entailment relations
between verbs. Our starting point is the idea that some point-wise verb
selectional preferences carry relevant semantic information. Experiments using
WordNet as a gold standard show promising results. Where applicable, our
method, used in combination with other approaches, significantly increases the
performance of entailment detection. A combined approach including our model
improves the AROC of 5% with respect to standard models.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>13D: Applications </span><st1:stockticker><span
 style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>III</span></st1:stockticker><span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'><span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair:<span style='mso-spacerun:yes'>&nbsp;
</span>Eva Haji&#269;ov&aacute;<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b13D1></a>Event Extraction in a Plot Advice
Agent </p>

<p class=AbstractAuthor>Harry Halpin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Halpin, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Johanna D. Moore<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Moore, J.D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>In this paper we
present how the automatic extraction of events from text can be used to both
classify narrative texts according to plot quality and produce advice in an
interactive learning environment intended to help students with story writing.
We focus on the story-rewriting task, in which an exemplar story is read to the
students and the students rewrite the story in their own words. The system
automatically extracts events from the raw text, formalized as a sequence of
temporally ordered predicate-arguments. These events are given to a
machine-learner that produces a coarse-grained rating of the story. The results
of the machine-learner and the extracted events are then used to generate fine-grained
advice for the students.<o:p></o:p></span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Friday 21st July <span style='font-size:10.0pt;mso-bidi-font-size:14.0pt'>1100am</span>¡V1230pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>14A: Parsing </span><st1:stockticker><span
 style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>VII</span></st1:stockticker><span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'><span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Srinivas Bangalore<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b14A1></a>An All-Subtrees Approach to
Unsupervised Parsing</p>

<p class=AbstractAuthor>Rens Bod<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Bod, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We investigate generalizations of the all-subtrees &quot;DOP&quot;
approach to unsupervised parsing. Unsupervised DOP models assign all possible
binary trees to a set of sentences<span style='mso-ansi-language:EN-GB'> </span>and
next use (a large random subset of) all subtrees from these binary trees to
compute the most probable parse trees. We will test both a relative frequency
estimator for unsupervised DOP and a maximum likelihood estimator which is
known to be statistically consistent. We report state-of-the-art results on
English (WSJ), German (NEGRA) and Chinese (<st1:stockticker>CTB</st1:stockticker>)
data. To the best of our knowledge this is the first paper which tests a
maximum likelihood estimator for DOP on the Wall Street Journal, leading to the
surprising result that an unsupervised parsing model beats a widely used
supervised model (a treebank PCFG).</p>

<p class=AbstractTitle><a name=b14A2></a>Advances in Discriminative Parsing</p>

<p class=AbstractAuthor>Joseph Turian<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Turian, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and I. Dan Melamed<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Melamed, I.D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>The present work
advances the accuracy and training speed of discriminative parsing. Our
discriminative parsing method has no generative component, yet surpasses a
generative baseline on constituent parsing, and does so with minimal linguistic
cleverness. Our model can incorporate arbitrary features of the input and parse
state, and performs feature selection incrementally over an exponential feature
space during training. We demonstrate the flexibility of our approach by
testing it with several parsing strategies and various feature sets. Our
implementation is freely available at: http://nlp.cs.nyu.edu/parser/.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b14A3></a>Prototype-Driven Grammar Induction</p>

<p class=AbstractAuthor>Aria Haghighi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Haghighi, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dan Klein<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Klein, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We investigate
prototype-driven learning for primarily unsupervised grammar induction. Prior
knowledge is specified declaratively, by providing a few canonical examples of
each target phrase type. This sparse prototype information is then propagated
across a corpus using distributional similarity features, which augment an
otherwise standard PCFG model. We show that distributional features are
effective at distinguishing bracket labels, but not determining bracket
locations. To improve the quality of the induced trees, we combine our PCFG
induction with the CCM model of Klein and Manning (2002), which has
complementary strengths: it identifies brackets but does not label them. Using
only a handful of prototypes, we show substantial improvements over naive PCFG
induction for English and Chinese grammar induction.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>14B: Question
Answering II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Dan Moldovan<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b14B1></a>Exploring Correlation of Dependency
Relation Paths for Answer Extraction</p>

<p class=AbstractAuthor>Dan Shen<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Shen, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dietrich Klakow<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Klakow, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>In this paper, we explore correlation of dependency
relation paths to rank candidate answers in answer extraction. Using the
correlation measure, we compare dependency relations of a candidate answer and
mapped question phrases in sentence with the corresponding relations in
question. Different from previous studies, we propose an approximate
phrase-mapping algorithm and incorporate the mapping score into the correlation
measure. The correlations are further incorporated into a Maximum Entropy-based
ranking model which estimates path weights from training. Experimental results
show that our method significantly outperforms state-of-the-art syntactic
relation-based methods by up to 20% in <st1:stockticker>MRR</st1:stockticker>.</p>

<p class=AbstractTitle><a name=b14B2></a>Question Answering with Lexical Chains
Propagating Verb Arguments</p>

<p class=AbstractAuthor>Adrian Novischi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Novischi, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dan Moldovan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Moldovan, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper describes an algorithm for propagating verb
arguments along lexical chains consisting of WordNet relations. The algorithm
creates verb argument structures using VerbNet syntactic patterns. In order to
increase the coverage, a larger set of verb senses were automatically
associated with the existing patterns from VerbNet. The algorithm is used in an
in-house Question Answering system for re-ranking the set of candidate answers.
Tests on factoid questions from TREC 2004 indicate that the algorithm improved
the system performance by 2.4%.</p>

<p class=AbstractTitle><a name=b14B3></a>Methods for Using Textual Entailment
in Open-Domain Question Answering</p>

<p class=AbstractAuthor>Sanda Harabagiu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Harabagiu, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Andrew Hickl<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hickl, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Work on the semantics
of questions has argued that the relation between a question and its answer(s)
can be cast in terms of logical entailment. In this paper, we demonstrate how
computational systems designed to recognize textual entailment can be used to
enhance the accuracy of current open-domain automatic question answering (Q/A)
systems. In our experiments, we show that when textual entailment information
is used to either filter or rank answers returned by a Q/A system, accuracy can
be increased by as much as 20% overall.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>14C: Semantics IV<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Alexander Koller<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b14C1></a>Using String-Kernels for Learning
Semantic Parsers</p>

<p class=AbstractAuthor>Rohit J. Kate<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kate, R.J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Raymond J. Mooney<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mooney, R.J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
present a new approach for mapping natural language sentences to their formal
meaning representations using string-kernel-based classifiers. Our system
learns these classifiers for every production in the formal language grammar.
Meaning representations for novel natural language sentences are obtained by
finding the most probable semantic parse using these string classifiers. Our
experiments on two real-world data sets show that this approach compares
favorably to other existing systems and is particularly robust to noise.</span><span
style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b14C2></a>A Bootstrapping Approach to
Unsupervised Detection of Cue Phrase Variants</p>

<p class=AbstractAuthor>Rashid M. Abdalla<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Abdalla, R.M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Simone Teufel<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Teufel, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We investigate the unsupervised
detection of semi-fixed cue phrases such as ¡§This paper proposes a novel
approach ¡K¡¨ from unseen text, on the basis of only a handful of seed cue
phrases with the desired semantics. The problem, in contrast to bootstrapping
approaches for Question Answering and Information Extraction, is that it is
hard to find a constraining context for occurrences of semi-fixed cue phrases.
Our method uses components of the cue phrase itself, rather than external
context, to bootstrap. It successfully excludes phrases which are different
from the target semantics, but which look superficially similar. The method
achieves 88% accuracy, outperforming standard bootstrapping approaches.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b14C3></a>Semantic Role Labeling via FrameNet,
VerbNet and PropBank </p>

<p class=AbstractAuthor>Ana-Maria Giuglea<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Giuglea, A-M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Alessandro Moschitti<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Moschitti, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This article describes
a robust semantic parser that uses a broad knowledge base created by
interconnecting three major resources: FrameNet, VerbNet and PropBank. The
FrameNet corpus contains the examples annotated with semantic roles whereas the
VerbNet lexicon provides the knowledge about the syntactic behavior of the
verbs. We connect VerbNet and FrameNet by mapping the FrameNet frames to the
VerbNet Intersective Levin classes. The PropBank corpus, which is tightly
connected to the VerbNet lexicon, is used to increase the verb coverage and
also to test the effectiveness of our approach. The results indicate that our
model is an interesting step towards the design of more robust semantic parsers.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>14D: Resources II<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair:<span style='mso-spacerun:yes'>&nbsp;
</span>Eva Haji&#269;ov&aacute;<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b14D1></a>Multilingual Legal Terminology on the
Jibiki Platform: The LexALP Project</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Gilles
S&eacute;rasset</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;S&eacute;rasset, G.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'>, Francis Brunet-Manquat</span><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span>
XE &quot;Brunet-Manquat, F.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><span
style='mso-spacerun:yes'>&nbsp;</span>and Elena Chiocchetti</span><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span>
XE &quot;Chiocchetti, E.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper presents the
particular use of</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>¡§Jibiki¡¨ (Papillon¡¦s web
server development</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>platform) for the LexALP1
project.</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>LexALP¡¦s goal is to harmonise the terminology</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>on spatial planning and sustainable</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>development used within the Alpine</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>Convention2, so that the member states</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>are able to cooperate and communicate</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>efficiently in the four official languages</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>(French, German, Italian and Slovene). To</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>this purpose, LexALP uses the Jibiki platform</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>to build a term bank for the contrastive</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>analysis of the specialised terminology</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>used in six different national legal</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>systems and four different languages. In</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>this paper we present how a generic platform</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>like Jibiki can cope with a new kind of
dictionary.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b14D2></a>Leveraging Reusability: Cost-effective
Lexical Acquisition for Large-scale Ontology Translation</p>

<p class=AbstractAuthor>G. Craig Murray<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Murray, G.C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Bonnie Dorr<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Dorr, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jimmy Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jan Haji&#269;<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Haji&#269;, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Pavel Pecina<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pecina, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Thesauri and ontologies
provide important value in facilitating access to digital archives by
representing underlying principles of organization. Translation of such
resources into multiple languages is an important component for providing
multilingual access.<span style='mso-spacerun:yes'>&nbsp; </span>However, the
specificity of vocabulary terms in most ontologies precludes fully-automated
machine translation using general-domain lexical resources. In this paper, we
present an efficient process for leveraging human translations when
constructing domain-specific lexical resources. We evaluate the effectiveness
of this process by producing a probabilistic phrase dictionary and translating
a thesaurus of 56,000 concepts used to catalogue a large archive of oral
histories. Our experiments demonstrate a cost-effective technique for accurate machine
translation of large ontologies.</span><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b14D3></a>Accurate Collocation Extraction Using
a Multilingual Parser</p>

<p class=AbstractAuthor>Violeta Seretan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Seretan, V.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Eric Wehrli<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wehrli, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper focuses on the use of advanced techniques of
text analysis as support for collocation extraction. A hybrid system is
presented that combines statistical methods and multilingual parsing for
detecting accurate collocational information from English, French, Spanish and
Italian corpora. The advantage of relying on full parsing over using a
traditional window method (which ignores the syntactic information) is first
theoretically motivated, then empirically validated by a comparative evaluation
experiment.</p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Friday 21st July <span style='font-size:10.0pt;mso-bidi-font-size:14.0pt'>200pm</span>¡V330pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>15A: Machine
Translation VI<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Dekai Wu<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b15A1></a>Scalable Inference and Training of
Context-rich Syntactic Translation Models</p>

<p class=AbstractAuthor>Michel Galley<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Galley, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jonathan Graehl<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Graehl, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Kevin Knight<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Knight, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Daniel Marcu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Marcu, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Steve DeNeefe<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;DeNeefe, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Wei Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Ignacio Thayer<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Thayer, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Statistical MT has made great progress in the last few
years, but current translation models are weak on re-ordering and target
language fluency. Syntactic approaches seek to remedy these problems.<span
style='mso-spacerun:yes'>&nbsp; </span>In this paper, we take the framework for
acquiring multi-level syntactic translation rules of (Galley et al., 2004) from
aligned tree-string pairs, and present two main extensions of their approach:
first, instead of merely computing a single derivation that minimally explains
a sentence pair, we construct a large number of derivations that include
contextually richer rules, and account for multiple interpretations of
unaligned words.<span style='mso-spacerun:yes'>&nbsp; </span>Second, we propose
probability estimates and a training procedure for weighting these rules.<span
style='mso-spacerun:yes'>&nbsp; </span>We contrast different approaches on real
examples, show that our estimates based on multiple derivations favor phrasal
re-orderings that are linguistically better motivated, and establish that our
larger rules provide a 3.63 BLEU point increase over minimal rules.</p>

<p class=AbstractTitle><a name=b15A2></a>Modelling lexical redundancy for
machine translation</p>

<p class=AbstractAuthor>David Talbot<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Talbot, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Miles Osborne<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Osborne, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Certain distinctions made in the lexicon of one language
may be redundant when translating into another language. We quantify redundancy
among source types by the similarity of their distributions over target types.
We propose a language-independent framework for minimising lexical redundancy
that can be optimised directly from parallel text. Optimisation of the source
lexicon for a given target language is viewed as model selection over a set of
cluster-based translation models.</p>

<p class=MsoBodyText>Redundant distinctions between types may exhibit
monolingual regularities, for example, inflexion patterns. We define a prior
over model structure using a Markov random field and learn features over sets
of monolingual types that are predictive of bilingual redundancy. The prior
makes model selection more robust without the need for language-specific
assumptions regarding redundancy. Using these models in a phrase-based <st1:stockticker>SMT</st1:stockticker>
system, we show significant improvements in translation quality for certain
language pairs.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b15A3></a>Empirical Lower Bounds on the
Complexity of Translational Equivalence</p>

<p class=AbstractAuthor>Benjamin Wellington<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wellington, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Sonjia Waxmonsky<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Waxmonsky, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and <span style='mso-bidi-font-weight:
bold'>I. Dan Melamed</span><!--[if supportFields]><span style='mso-bidi-font-weight:
bold'><span style='mso-element:field-begin'></span></span> XE &quot;Melamed,
I.D.&quot; <![endif]--><!--[if supportFields]><span style='mso-bidi-font-weight:
bold'><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper describes a
study of the patterns of translational equivalence exhibited by a variety of
bitexts. The study found that the complexity of these patterns in every bitext
was higher than suggested in the literature. These findings shed new light on
why ¡§syntactic¡¨ constraints have not helped to improve statistical translation
models, including finite state phrase-based models, tree-to-string models, and
tree-to-tree models. The paper also presents evidence that inversion
transduction grammars cannot generate some translational equivalence relations,
even in relatively simple real bitexts in syntactically similar languages with
rigid word order. Instructions for replicating our experiments are at
http://nlp.cs.nyu.edu/GenPar/</span><st1:stockticker><span style='mso-font-kerning:
 0pt'>ACL</span></st1:stockticker><span style='mso-font-kerning:0pt'>06<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>15B: Language
Modelling<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Jianfeng Gao<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b15B1></a>A Hierarchical Bayesian Language Model
Based On Pitman-Yor Processes</p>

<p class=AbstractAuthor>Yee Whye Teh<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Teh, Y.W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>We propose a new hierarchical
Bayesian n-gram model of natural languages. Our model makes use of a
generalization of the commonly used Dirichlet distributions called Pitman-Yor
processes which produce power-law distributions more closely resembling those
in natural languages. We show that an approximation to the hierarchical
Pitman-Yor language model recovers the exact formulation of interpolated
Kneser-Ney, one of the best smoothing methods for n-gram language models.
Experiments verify that our model gives cross entropy results superior to
interpolated Kneser-Ney and comparable to modified Kneser-Ney.</span><span
style='mso-tab-count:1'>&nbsp;&nbsp; </span><span style='mso-tab-count:5'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b15B2></a>A Phonetic-Based Approach to Chinese
Chat Text Normalization</p>

<p class=AbstractAuthor>Yunqing Xia<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Xia, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Kam-Fai Wong<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wong, K-F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Wenjie Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Li, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Chatting is a popular communication media on the Internet
via ICQ, chat rooms, etc. Chat language is different from natural language due
to its anomalous and dynamic natures, which renders conventional NLP tools
inapplicable. The dynamic problem is enormously troublesome because it makes
static chat language corpus outdated quickly in representing contemporary chat
language. To address the dynamic problem, we propose the phonetic mapping
models to present mappings between chat terms and standard words via phonetic
transcription, i.e. Chinese Pinyin in our case. Different from character
mappings, the phonetic mappings can be constructed from available standard
Chinese corpus. To perform the task of dynamic chat language term
normalization, we extend the source channel model by incorporating the phonetic
mapping models. Experimental results show that this method is effective and
stable in normalizing dynamic chat language terms.<span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b15B3></a>Discriminative Pruning of Language
Models for Chinese Word Segmentation</p>

<p class=AbstractAuthor>Jianfeng Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Li, J.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Haifeng Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Dengjun Ren<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ren, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Guohua Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Li, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper presents a discriminative pruning method of n-gram language model for
Chinese word segmentation. To reduce the size of the language model that is
used in a Chinese word segmentation system, importance of each bigram is
computed in terms of discriminative pruning criterion that is related to the
performance loss caused by pruning the bigram. Then we propose a step-by-step
growing algorithm to build the language model of desired size. Experimental
results show that the discriminative pruning method leads to a much smaller
model compared with the model pruned using the state-of-the-art method. At the
same Chinese word segmentation F-measure, the number of bigrams in the model
can be reduced by up to 90%. Correlation between language model perplexity and
word segmentation performance is also discussed.</span><span style='mso-tab-count:
5'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>15C: Information
Retrieval II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Rosie Jones<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b15C1></a>Novel Association Measures Using Web
Search with Double Checking</p>

<p class=AbstractAuthor>Hsin-Hsi Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, H-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ming-Shun Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, M-S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Yu-Chuan Wei<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wei, Y-C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>A web search with double checking model is proposed to
explore the web as a live corpus.<span style='mso-spacerun:yes'>&nbsp;
</span>Five association measures including variants of Dice, Overlap Ratio,
Jaccard, and Cosine, as well as Co-Occurrence Double Check (CODC), are
presented. In the experiments on Rubenstein-Goodenough¡¦s benchmark data set,
the CODC measure achieves correlation coefficient 0.8492, which competes with
the performance (0.8914) of the model using WordNet. The experiments on link
detection of named entities using the strategies of direct association,
association matrix and scalar association matrix verify that the double-check
frequencies are reliable. Further study on named entity clustering shows that
the five measures are quite useful. In particular, CODC measure is very stable
on word-word and name-name experiments. The application of CODC measure to
expand community chains for personal name disambiguation achieves 9.65% and
14.22% increase compared to the system without community expansion. All the
experiments illustrate that the novel model of web search with double-checking
is feasible for mining associations from the web.</p>

<p class=AbstractTitle><a name=b15C2></a>Semantic Retrieval for the Accurate
Identification of Relational Concepts in Massive Textbases </p>

<p class=AbstractAuthor>Yusuke Miyao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Miyao, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Tomoko Ohta<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ohta, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Katsuya Masuda<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Masuda, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yoshimasa Tsuruoka<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsuruoka, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Kazuhiro Yoshida<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yoshida, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Takashi Ninomiya<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ninomiya, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jun'ichi Tsujii<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsujii, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper introduces a novel framework for the accurate
retrieval of relational concepts from huge texts.<span
style='mso-spacerun:yes'>&nbsp; </span>Prior to retrieval, all sentences are
annotated with predicate argument structures and ontological identifiers by
applying a deep parser and a term recognizer.<span
style='mso-spacerun:yes'>&nbsp; </span>During the run time, user requests are
converted into queries of region algebra on these annotations.<span
style='mso-spacerun:yes'>&nbsp; </span>Structural matching with pre-computed
semantic annotations establishes the accurate and efficient retrieval of
relational concepts.<span style='mso-spacerun:yes'>&nbsp; </span>This framework
was applied to a text retrieval system for MEDLINE.<span
style='mso-spacerun:yes'>&nbsp; </span>Experiments on the retrieval of biomedical
correlations revealed that the cost is sufficiently small for real-time
applications and that the retrieval precision is significantly improved.</p>

<p class=AbstractTitle><a name=b15C3></a>Exploring Distributional Similarity
Based Models for Query Spelling Correction</p>

<p class=AbstractAuthor>Mu Li<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Li, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Muhua Zhu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhu, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yang Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, Y.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Ming Zhou<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhou, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>A query speller is crucial to search engine in improving
web search relevance. This paper describes novel methods for use of
distributional similarity estimated from query logs in learning improved query
spelling correction models. The key to our methods is the property of
distributional similarity between two terms: it is high between a frequently
occurring misspelling and its correction, and low between two irrelevant terms
only with similar spellings. We present two models that are able to take
advantage of this property. Experimental results demonstrate that the
distributional similarity based models can significantly outperform their
baseline systems in the web query spelling correction task.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>15D: Generation I<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Donia Scott<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b15D1></a>Robust PCFG-Based Generation using
Automatically Acquired <st1:stockticker>LFG</st1:stockticker> Approximations </p>

<p class=AbstractAuthor>Aoife Cahill<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Cahill, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Josef van Genabith<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;van Genabith, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We present a novel PCFG-based architecture for robust
probabilistic generation based on wide-coverage <st1:stockticker>LFG</st1:stockticker>
approximations (Cahill et al., 2004) automatically extracted from treebanks,
maximising the probability of a tree given an f-structure. We evaluate our
approach using string-based evaluation. We currently achieve coverage of
95.26%, a BLEU score of 0.7227 and string accuracy of 0.7476 on the Penn-II WSJ
Section 23 sentences of length &#8804;20.</p>

<p class=AbstractTitle><a name=b15D2></a>Incremental generation of spatial
referring expressions in situated dialog</p>

<p class=AbstractAuthor>John D. Kelleher<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kelleher, J.D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Geert-Jan M. Kruijff<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kruijff, G-J. M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper presents an approach to incrementally
generating locative expressions. It addresses the issue of combinatorial
explosion inherent in the construction of relational context models by: (a)
contextually defining the set of objects in the context that may function as a
landmark, and (b) sequencing the order in which spatial relations are
considered using a cognitively motivated hierarchy of relations, and visual and
discourse salience.<span style='mso-tab-count:5'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b15D3></a>Learning to Predict Case Markers in
Japanese</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Hisami
Suzuki</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Suzuki, H.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><span style='mso-spacerun:yes'>&nbsp;</span>and
Kristina Toutanova</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Toutanova, K.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=MsoBodyText>Japanese case markers, which indicate the grammatical
relation of the complement NP to the predicate, often pose challenges to the
generation of Japanese text, be it done by a foreign language learner, or by a
machine translation (MT) system. In this paper, we describe the task of
predicting Japanese case markers and propose machine learning methods for
solving it in two settings: (i) monolingual, when given information only from
the Japanese sentence; and (ii) bilingual, when also given information from a
corresponding English source sentence in an MT context. We formulate the task
after the well-studied task of English semantic role labelling, and explore
features from a syntactic dependency structure of the sentence. For the
monolingual task, we evaluated our models on the Kyoto Corpus and achieved over
84% accuracy in assigning correct case markers for each phrase. For the
bilingual task, we achieved an accuracy of 92% per phrase using a bilingual
dataset from a technical domain. We show that in both settings, features that
exploit dependency information, whether derived from gold-standard annotations
or automatically assigned, contribute significantly to the prediction of case
markers.</p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2>Friday 21st July 400pm¡V500pm</h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>16A: Text
Classification II<span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Peter Turney<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b16A1></a>Are These Documents Written from
Different Perspectives? A Test of Different Perspectives Based On Statistical
Distribution Divergence</p>

<p class=AbstractAuthor>Wei-Hao Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, W-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Alexander Hauptmann<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hauptmann, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>In this paper we investigate how to automatically
determine if two document collections are written from different
perspectives.<span style='mso-spacerun:yes'>&nbsp; </span>By perspectives we
mean a point of view, for example, from the perspective of Democrats or
Republicans.<span style='mso-spacerun:yes'>&nbsp; </span>We propose a test of
different perspectives based on distribution divergence between the statistical
models of two collections.<span style='mso-spacerun:yes'>&nbsp;
</span>Experimental results show that the test can successfully distinguish
document collections of different perspectives from other types of collections.</p>

<p class=AbstractTitle><a name=b16A2></a>Word Sense and Subjectivity </p>

<p class=AbstractAuthor>Janyce Wiebe<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wiebe, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Rada Mihalcea<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mihalcea, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Subjectivity and
meaning are both important properties of language. This paper explores their
interaction, and brings empirical evidence in support of the hypotheses that
(1) subjectivity is a property that can be associated with word senses, and (2)
word sense disambiguation can directly benefit from subjectivity annotations.<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>16B: Question
Answering </span><st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:
 13.0pt'>III</span></st1:stockticker><span style='font-size:10.0pt;mso-bidi-font-size:
13.0pt'><span style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: John Prange<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b16B1></a>Improving QA Accuracy by Question
Inversion</p>

<p class=AbstractAuthor>John Prager<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Prager, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Pablo Duboue<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Duboue, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jennifer Chu-Carroll<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chu-Carroll, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper demonstrates a conceptually simple but effective method of increasing the
accuracy of QA systems on factoid-style questions.<span
style='mso-spacerun:yes'>&nbsp; </span>We define the notion of an inverted
question, and show that by requiring that the answers to the original and
inverted questions be mutually consistent, incorrect answers get demoted in
confidence and correct ones promoted.<span style='mso-spacerun:yes'>&nbsp;
</span>Additionally, we show that lack of validation can be used to assert
no-answer (nil) conditions.<span style='mso-spacerun:yes'>&nbsp; </span>We
demonstrate increases of performance on TREC and other question-sets, and
discuss the kinds of future activities that can be particularly beneficial to
approaches such as ours.</span><span style='mso-tab-count:6'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b16B2></a>Reranking Answers for Definitional QA
Using Language Modeling</p>

<p class=AbstractAuthor>Yi Chen<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Chen, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ming Zhou<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhou, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Shilong Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, S.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>Statistical ranking methods based on centroid vector
(profile) extracted from ex-ternal knowledge have become widely adopted in the
top definitional QA systems in TREC 2003 and 2004. In these approaches, terms
in the centroid vector are treated as a bag of words based on the independent
assumption. To relax this assumption, this paper proposes a novel language
model-based answer reranking method to improve the existing bag-of-words model
approach by considering the dependence of the words in the centroid vector.
Experiments have been conducted to evaluate the different dependence models.
The results on the TREC 2003 test set show that the reranking approach with
biterm language model, significantly outperforms the one with the bag-of-words
model and unigram language model by 14.9% and 12.5% respectively in
F-Measure(5).</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>16C: Grammars </span><st1:stockticker><span
 style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>III</span></st1:stockticker><span
style='font-size:10.0pt;mso-bidi-font-size:13.0pt'><span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Gerald Penn<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b16C1></a>Highly constrained unification
grammars</p>

<p class=AbstractAuthor>Daniel Feinstein<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Feinstein, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Shuly Wintner<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wintner, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Unification grammars
are widely accepted as an expressive means for describing the structure of
natural languages. In general, the recognition problem is undecidable for
unification grammars. Even with restricted variants of the formalism, offline
parsable grammars, the problem is computationally hard. We present two natural
constraints on unification grammars which limit their expressivity. We first
show that non-reentrant unification grammars generate exactly the class of
context-free languages. We then relax the constraint and show that
one-reentrant unification grammars generate exactly the class of tree-adjoining
languages. We thus relate the commonly used and linguistically motivated
formalism of unification grammars to more restricted, computationally tractable
classes of languages.<o:p></o:p></span></p>

<p class=AbstractTitle><a name=b16C2></a>A polynomial parsing algorithm for the
topological model Synchronizing Constituent and Dependency Grammars,
Illustrated by German Word Order Phenomena</p>

<p class=AbstractAuthor>Kim Gerdes<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gerdes, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Sylvain Kahane<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kahane, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper describes a minimal topology driven parsing
algorithm for topological grammars that synchronizes a rewriting grammar and a
dependency grammar, obtaining two linguistically motivated syntactic
structures. The use of non-local slash and visitor features can be restricted
to obtain a CKY type analysis in polynomial time. German long distance
phenomena illustrate the algorithm, bringing to the fore the procedural needs
of the analyses of syntax-topology mismatches in constraint based approaches
like for example HPSG.</p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span style='font-size:10.0pt;mso-bidi-font-size:13.0pt'>16D: Generation II<span
style='mso-tab-count:7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></h3>

</div>

<p class=SessionChair>Session Chair: Donia Scott<span style='mso-tab-count:
7'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=AbstractTitle><a name=b16D1></a>Stochastic Language Generation Using
WIDL-expressions and its Application in Machine Translation and Summarization</p>

<p class=AbstractAuthor>Radu Soricut<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Soricut, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Daniel Marcu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Marcu, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>We propose WIDL-expressions as a flexible formalism that
facilitates the integration of a generic sentence realization system within
end-to-end language processing applications. WIDL-expressions represent
compactly probability distributions over finite sets of candidate realizations,
and have optimal algorithms for realization via interpolation with language
model probability distributions. We show the effectiveness of a WIDL-based NLG
system in two sentence realization tasks: automatic translation and headline
generation.</p>

<p class=AbstractTitle><a name=b16D2></a>Learning to Say It Well: Reranking
Realizations by Predicted Synthesis Quality</p>

<p class=AbstractAuthor>Crystal Nakatsu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nakatsu, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Michael White<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;White, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>This paper presents a
method for adapting a language generator to the strengths and weaknesses of a
synthetic voice, thereby improving the naturalness of synthetic speech in a
spoken language dialogue system. The method trains a discriminative reranker to
select paraphrases that are predicted to sound natural when synthesized. The
ranker is trained on realizer and synthesizer features in supervised fashion,
using human judgments of synthetic voice quality on a sample of the paraphrases
representative of the generator¡¦s capability. Results from a cross-validation
study indicate that discriminative paraphrase reranking can achieve substantial
improvements in naturalness on average, ameliorating the problem of highly
variable synthesis quality typically encountered with today¡¦s unit selection
synthesizers.<o:p></o:p></span></p>

<h1><span lang=EN-GB style='mso-ansi-language:EN-GB'>Poster Sessions<o:p></o:p></span></h1>

<p class=MsoBodyText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Posters
are assigned to either Monday 17th July or Tuesday 18th July.<span
style='mso-spacerun:yes'>&nbsp; </span>Each poster will be on display all day
on the day to which it has been assigned, but is also allocated a one hour time
slot in the early evening of that day during which the presenter of that poster
will be available for discussion.<span style='mso-spacerun:yes'>&nbsp;
</span>This schedule is organised by day, then by topic area, with each poster
abstract indicating its time slot and the numbered spot at which it can be
found in the poster display area.<o:p></o:p></span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><span lang=EN-GB style='mso-ansi-language:EN-GB'>Monday 17th July<o:p></o:p></span></h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Asian Languages<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>An account for compound prepositions in Farsi</p>

<p class=AbstractAuthor>Zahra Abolhassani Chime<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chime, Z.A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>There are some sorts of ¡¥Preposition +<span
style='mso-ansi-language:EN-GB'> </span>Noun¡¦ combinations in Farsi that<span
style='mso-ansi-language:EN-GB'> </span>apparently a Prepositional Phrase
almost<span style='mso-ansi-language:EN-GB'> </span>behaves as Compound
Prepositions. As<span style='mso-ansi-language:EN-GB'> </span>they are not
completely behaving as<span style='mso-ansi-language:EN-GB'> </span>compounds,
it is doubtful that the process<span style='mso-ansi-language:EN-GB'> </span>of
word formation is a morphological<span style='mso-ansi-language:EN-GB'> </span>one.</p>

<p class=PosterAbstractText>The analysis put forward by this paper<span
style='mso-ansi-language:EN-GB'> </span>proposes ¡¥incorporation¡¦ by which a No<span
style='mso-ansi-language:EN-GB'> </span>is incorporated to a Po constructing a<span
style='mso-ansi-language:EN-GB'> </span>compound preposition. In this way<span
style='mso-ansi-language:EN-GB'> </span>tagging prepositions and parsing texts
in<span style='mso-ansi-language:EN-GB'> </span>Natural Language Processing is
defined<span style='mso-ansi-language:EN-GB'> </span>in a proper manner.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
1</span></p>

<p class=AbstractTitle>Chinese-English Term Translation Mining Based on
Semantic Prediction</p>

<p class=AbstractAuthor>Gaolin Fang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Fang, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hao Yu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yu, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Fumihito Nishino<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nishino, F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Using
abundant Web resource to mine Chinese term translations can be applied in many
fields such as reading/writing assistant, machine translation and
cross-language information retrieval. In mining English translations of Chinese
terms, how to obtain effective Web pages and evaluate translation candidates
are two challenging issues. In this paper, the approach based on semantic
prediction is first proposed to obtain effective Web pages. The proposed method
predicts possible English meanings according to each constituent unit of
Chinese term, and expands these English items using semantically relevant
knowledge for searching. The refined related terms are extracted from top
retrieved documents through feedback learning to construct a new query expansion
for acquiring more effective Web pages. For obtaining a correct translation
list, a translation evaluation method in the weighted sum of multi-features is
presented to rank these candidates estimated from effective Web pages.
Experimental results demonstrate that the proposed method has good performance
in Chinese-English term translation acquisition, and achieves 82.9% accuracy.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
5</span></p>

<p class=AbstractTitle>A Collaborative Framework for Collecting Thai Unknown
Words from the Web</p>

<p class=AbstractAuthor>Choochart Haruechaiyasak<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Haruechaiyasak, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chatchawal Sangkeettrakarn<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sangkeettrakarn, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Pornpimon Palingoon<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Palingoon, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Sarawoot Kongyoung<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kongyoung, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Chaianun Damrongrat<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Damrongrat, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
propose a collaborative framework for collecting Thai unknown words found on
Web pages over the Internet. Our main goal is to design and construct a
Web-based system which allows a group of interested users to participate in
constructing a Thai unknown-word open dictionary. The proposed framework
provides supporting algorithms and tools for automatically identifying and
extracting unknown words from Web pages of given URLs. The system yields the
result of unknown-word candidates which are presented to the users for
verification. The approved unknown words could be combined with the set of
existing words in the lexicon to improve the performance of many NLP tasks such
as word segmentation, information retrieval and machine translation. Our
framework includes word segmentation and morphological analysis modules for
handling the non-segmenting characteristic of Thai written language. To take
advantage of large available text resource on the Web, our unknown-word
boundary identification approach is based on the statistical string
pattern-matching algorithm.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
7</span></p>

<p class=AbstractTitle>Machine-Learning-Based Transformation of Passive
Japanese Sentences into Active by Separating Training Data into Each Input
Particle</p>

<p class=AbstractAuthor>Masaki Murata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Murata, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Toshiyuki Kanamaru<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kanamaru, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Tamotsu Shirado<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shirado, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hitoshi Isahara<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Isahara, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We developed a new method of transforming<span
style='mso-ansi-language:EN-GB'> </span>Japanese case particles when
transforming<span style='mso-ansi-language:EN-GB'> </span>Japanese passive
sentences into<span style='mso-ansi-language:EN-GB'> </span>active sentences.
It separates training data<span style='mso-ansi-language:EN-GB'> </span>into
each input particle and uses machine<span style='mso-ansi-language:EN-GB'> </span>learning
for each particle. We also used<span style='mso-ansi-language:EN-GB'> </span>numerous
rich features for learning. Our<span style='mso-ansi-language:EN-GB'> </span>method
obtained a high rate of accuracy<span style='mso-ansi-language:EN-GB'> </span>(94.30%).
In contrast, a method that did<span style='mso-ansi-language:EN-GB'> </span>not
separate training data for any input<span style='mso-ansi-language:EN-GB'> </span>particles
obtained a lower rate of accuracy<span style='mso-ansi-language:EN-GB'> </span>(92.00%).
In addition, a method<span style='mso-ansi-language:EN-GB'> </span>that did not
have many rich features for<span style='mso-ansi-language:EN-GB'> </span>learning
used in a previous study (Murata<span style='mso-ansi-language:EN-GB'> </span>and
Isahara, 2003) obtained a much<span style='mso-ansi-language:EN-GB'> </span>lower
accuracy rate (89.77%). We confirmed that these improvements were significant<span
style='mso-ansi-language:EN-GB'> </span>through a statistical test. We<span
style='mso-ansi-language:EN-GB'> </span>also conducted experiments utilizing
traditional<span style='mso-ansi-language:EN-GB'> </span>methods using verb
dictionaries<span style='mso-ansi-language:EN-GB'> </span>and manually prepared
heuristic rules<span style='mso-ansi-language:EN-GB'> </span>and confirmed that
our method obtained<span style='mso-ansi-language:EN-GB'> </span>much higher
accuracy rates than traditional<span style='mso-ansi-language:EN-GB'> </span>methods.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
13</span></p>

<p class=AbstractTitle>Infrastructure for standardization of Asian language
resources</p>

<p class=AbstractAuthor>Tokunaga Takenobu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tokunaga, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Virach Sornlertlamvanich<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sornlertlamvanich, V.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Thatsanee Charoenporn<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Charoenporn, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Nicoletta Calzolari<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Calzolari, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Monica Monachini<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Monachini, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Claudia Soria<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Soria, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chu-Ren Huang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Huang, C-R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Xia YingJu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Xia, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yu Hao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yu, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Laurent Prevot<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Prevot, L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Shirai Kiyoaki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shirai, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>As
an area of great linguistic and cultural diversity, Asian language resources
have received much less attention than their western counterparts. Creating a
common standard for Asian language resources that is compatible with an
international standard has at least three strong advantages: to increase the
competitive edge of Asian countries, to bring Asian countries to closer to
their western counterparts, and to bring more cohesion among Asian countries.
To achieve this goal, we have launched a two year project to create a common
standard for Asian language resources. The project is comprised of four
research items, (1) building a description framework of lexical entries, (2)
building sample lexicons, (3) building an upper-layer ontology and (4)
evaluating the proposed framework through an application. This paper outlines
the project in terms of its aim and approach.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
17</span></p>

<p class=AbstractTitle>Aligning Features with Sense Distinction Dimensions</p>

<p class=AbstractAuthor>Nianwen Xue<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Xue, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jinying Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, J.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Martha Palmer<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Palmer, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>In this paper we present word sense disambiguation
(WSD) experiments on ten highly polysemous verbs in Chinese, where significant
performance improvements are achieved using rich linguistic features. Our
system performs significantly better, and in some cases substantially better,
than the baseline on all ten verbs.<span style='mso-spacerun:yes'>&nbsp;
</span>Our results also demonstrate that features extracted from the output of
an automatic Chinese semantic role labeling system in general benefited the WSD
system, even though the amount of improvement was not consistent across the
verbs. For a few verbs, semantic role information actually hurt WSD
performance. The inconsistency of feature performance is a general
characteristic of the WSD task, as has been observed by others. We argue that
this result can be explained by the fact that word senses are partitioned along
different dimensions for different verbs and the features therefore need to be
tailored to particular verbs in order to achieve adequate accuracy on verb
sense disambiguation.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
19</span></p>

<p class=AbstractTitle>A Modified Joint Source-Channel Model for
Transliteration</p>

<p class=AbstractAuthor>Asif Ekbal<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ekbal, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Sudip Kumar Naskar<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Naskar, S.K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Sivaji Bandyopadhyay<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bandyopadhyay, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Most machine transliteration systems transliterate
out of vocabulary (OOV) words through intermediate phonemic mapping. A
framework has been presented that allows direct orthographical mapping between
two languages that are of different origins employing different alphabet sets.
A modified joint source-channel model along with a number of alternatives have
been proposed. Aligned transliteration units along with their con-text are
automatically derived from a bi-lingual training corpus to generate the
collocational statistics. The transliteration units in Bengali words take the
pattern C+M where C represents a vowel or a consonant or a conjunct and M
represents the vowel modifier or matra. The English transliteration units are
of the form C*V* where C represents a consonant and V represents a vowel. A
Bengali-English machine transliteration system has been developed based on the
proposed models. The system has been trained to transliterate person names from
Bengali to English. It uses the linguistic knowledge of possible conjuncts and
diphthongs in Bengali and their equivalents in English. The system has been
evaluated and it has been observed that the modified joint source-channel model
performs best with a Word Agreement Ratio of 69.3% and a Transliteration Unit
Agreement Ratio of 89.8%.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
3</span></p>

<p class=AbstractTitle>Detection of Quotations and Inserted Clauses and its
Application to Dependency Structure Analysis in Spontaneous Japanese</p>

<p class=AbstractAuthor>Ryoji Hamabe<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hamabe, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Kiyotaka Uchimoto<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Uchimoto, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Tatsuya Kawahara<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kawahara, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hitoshi Isahara<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Isahara, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Japanese dependency structure is usually
represented by relationships between<span style='mso-ansi-language:EN-GB'> </span>phrasal
units called 'bunsetsu's.<span style='mso-ansi-language:EN-GB'> </span>One of
the biggest problems with dependency structure analysis in spontaneous<span
style='mso-ansi-language:EN-GB'> </span>speech is that clause boundaries are
ambiguous.<span style='mso-ansi-language:EN-GB'> </span>This paper describes a
method for detecting the boundaries of quotations and<span style='mso-ansi-language:
EN-GB'> </span>inserted clauses and that for improving the dependency accuracy
by applying the<span style='mso-ansi-language:EN-GB'> </span>detected
boundaries to dependency structure analysis.<span style='mso-ansi-language:
EN-GB'> </span>The quotations and inserted clauses are determined by using an <st1:stockticker>SVM</st1:stockticker>-based
text<span style='mso-ansi-language:EN-GB'> </span>chunking method that
considers information on morphemes, pauses, fillers, etc. The information on
automatically analyzed dependency structure is also used to<span
style='mso-ansi-language:EN-GB'> </span>detect the beginning of the clauses.
Our evaluation experiment using 'Corpus of Spontaneous Japanese (CSJ)' showed<span
style='mso-ansi-language:EN-GB'> </span>that the automatically estimated
boundaries of quotations and inserted clauses<span style='mso-ansi-language:
EN-GB'> </span>helped to improve the accuracy of dependency structure analysis.</p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="18"><span lang=EN-GB>6-7pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
9</span></p>

<p class=AbstractTitle>Japanese Idiom Recognition: Drawing a Line between
Literal and Idiomatic Meanings</p>

<p class=AbstractAuthor>Chikara Hashimoto<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hashimoto, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Satoshi Sato<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sato, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Takehito Utsuro<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Utsuro, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Recognizing idioms in a sentence is important to
sentence<span style='mso-ansi-language:EN-GB'> </span>understanding. This paper
discusses the lexical knowledge of idioms<span style='mso-ansi-language:EN-GB'>
</span>for idiom recognition. The challenges are that idioms can be ambiguous<span
style='mso-ansi-language:EN-GB'> </span>between literal and idiomatic meanings,
and that they can be<span style='mso-ansi-language:EN-GB'> </span>&quot;transformed''
when expressed in a sentence. However, there has been<span style='mso-ansi-language:
EN-GB'> </span>little research on Japanese idiom recognition with its ambiguity
and<span style='mso-ansi-language:EN-GB'> </span>transformations taken into
account. We propose a set of lexical<span style='mso-ansi-language:EN-GB'> </span>knowledge
for idiom recognition. We evaluated the knowledge by<span style='mso-ansi-language:
EN-GB'> </span>measuring the performance of an idiom recognizer that exploits
the<span style='mso-ansi-language:EN-GB'> </span>knowledge. As a result, more
than 90% of the idioms in a corpus are<span style='mso-ansi-language:EN-GB'> </span>recognized
with 90% accuracy.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
11</span></p>

<p class=AbstractTitle>When Conset meets Synset: A Preliminary Survey of an
Ontological Lexical Resource based on Chinese Characters</p>

<p class=AbstractAuthor>Shu-Kai Hsieh<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hsieh, S-K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Chu-Ren Huang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Huang, C-R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper describes an on-going project concerning
with an<span style='mso-ansi-language:EN-GB'> </span>ontological lexical
resource based on the abundant conceptual<span style='mso-ansi-language:EN-GB'>
</span>information grounded on Chinese characters. The ultimate goal of<span
style='mso-ansi-language:EN-GB'> </span>this project is set to construct a
cognitively sound and<span style='mso-ansi-language:EN-GB'> </span>computationally
effective character-grounded machine-understandable<span style='mso-ansi-language:
EN-GB'> </span>resource.</p>

<p class=PosterAbstractText>Philosophically, Chinese ideogram has its
ontological status, but<span style='mso-ansi-language:EN-GB'> </span>its
applicability to the NLP task has not been expressed explicitly in terms of<span
style='mso-ansi-language:EN-GB'> </span>language resource. We thus propose the
first attempt to locate Chinese<span style='mso-ansi-language:EN-GB'> </span>characters
within the context of ontology. Having the primary success in<span
style='mso-ansi-language:EN-GB'> </span>applying it to some NLP tasks, we
believe that the construction of this<span style='mso-ansi-language:EN-GB'> </span>knowledge
resource will shed new light on theoretical setting as well as the<span
style='mso-ansi-language:EN-GB'> </span>construction of Chinese lexical
semantic resources.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
15</span></p>

<p class=AbstractTitle>Sinhala Grapheme-to-Phoneme Conversion and Rules for
Schwa Epenthesis</p>

<p class=AbstractAuthor>Asanka Wasala<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wasala, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ruvan Weerasinghe<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Weerasinghe, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kumudu Gamage<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gamage, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper describes an architecture to convert
Sinhala Unicode text into phonemic specification of pronunciation. The study
was mainly focused on disambiguating schwa-/<span style='font-family:"Times New Roman"'>&#601;</span>/
and /a/ vowel epenthesis for consonants, which is one of the significant
problems found in Sinhala. This problem has been addressed by formulating a set
of rules. The proposed set of rules was tested using 30,000 distinct words
obtained from a corpus and compared with the same words manually transcribed to
phonemes by an expert. The Grapheme-to-Phoneme (G2P) conversion model achieves
98 % accuracy.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
21</span></p>

<p class=AbstractTitle>An HMM-Based Approach to Automatic Phrasing for Mandarin
Text-to-Speech Synthesis</p>

<p class=AbstractAuthor>Jing Zhu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Zhu, J.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jian-Hua Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Li, J-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Automatic phrasing is essential to Mandarin
text-to-speech synthesis. We select<span style='mso-ansi-language:EN-GB'> </span>word
format as target linguistic feature and propose an HMM-based approach to<span
style='mso-ansi-language:EN-GB'> </span>this issue. Then we define four states
of prosodic positions for each word when<span style='mso-ansi-language:EN-GB'> </span>employing
a discrete hidden Markov model. The approach achieves high accuracy<span
style='mso-ansi-language:EN-GB'> </span>of roughly 82%, which is very close to
that from manual labeling. Our<span style='mso-ansi-language:EN-GB'> </span>experimental
results also demonstrate that this approach has advantages over<span
style='mso-ansi-language:EN-GB'> </span>those part-of-speech-based ones.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
23<b><o:p></o:p></b></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Chunking<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>An Empirical Study of Chinese Chunking</p>

<p class=AbstractAuthor>Wenliang Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, W.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yujie Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, Y.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hitoshi Isahara<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Isahara, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>In this paper, we describe an empirical study of
Chinese chunking on<span style='mso-ansi-language:EN-GB'> </span>a corpus,
which is extracted from UPENN Chinese Treebank-4 (<st1:stockticker>CTB</st1:stockticker>4).<span
style='mso-ansi-language:EN-GB'> </span>First, we compare the performance of
the state-of-the-art machine<span style='mso-ansi-language:EN-GB'> </span>learning
models. Then we propose two approaches in order to improve<span
style='mso-ansi-language:EN-GB'> </span>the performance of Chinese chunking. 1)
We propose an approach to<span style='mso-ansi-language:EN-GB'> </span>resolve
the special problems of Chinese chunking. This approach<span style='mso-ansi-language:
EN-GB'> </span>extends the chunk tags for every problem by a tag-extension<span
style='mso-ansi-language:EN-GB'> </span>function. 2) We propose two novel
voting methods based on the<span style='mso-ansi-language:EN-GB'> </span>characteristics
of chunking task. Compared with traditional voting<span style='mso-ansi-language:
EN-GB'> </span>methods, the proposed voting methods consider long distance<span
style='mso-ansi-language:EN-GB'> </span>information. The experimental results
show that the SVMs model<span style='mso-ansi-language:EN-GB'> </span>outperforms
the other models and that our proposed approaches can<span style='mso-ansi-language:
EN-GB'> </span>improve performance significantly.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'> </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
25</span></p>

<p class=AbstractTitle>Exact Decoding for Jointly Labeling and Chunking
Sequences</p>

<p class=AbstractAuthor>Nobuyuki Shimizu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shimizu, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Andrew Haas<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Haas, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>There
are two decoding algorithms essential to the area of natural language
processing. One is Viterbi algorithm for linear-chain models, often constructed
as HMMs or CRFs. The other is CKY algorithm for probabilistic context free
grammars. However, tasks such as noun phrase chunking or relation extraction
seem to fall between the two, neither of them being the best fit. Ideally we
would like to model entities and relations, with two layers of labels. We
present a tractable algorithm for exact inference over two layers of labels and
chunks with time complexity O(n<sup>2</sup>), and provide empirical results
comparing our model with linear-chain models.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
27</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Corpus Annotation<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Towards A Modular Data Model For Multi-Layer Annotated
Corpora</p>

<p class=AbstractAuthor>Richard Eckart<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Eckart, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In
this paper we discuss the current methods in the representation of corpora
annotated at multiple levels of linguistic organization (so-called multi-level
or multi-layer corpora). Taking five approaches which are representative of the
current practice in this area, we discuss the commonalities and differences
between them focusing on the underlying data models. The goal of the paper is
to identify the common concerns in multi-layer corpus representation and
processing so as to lay a foundation for a unifying, modular data model.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
29</span></p>

<p class=AbstractTitle>Towards the Orwellian Nightmare: Separation of Business
and Personal Emails</p>

<p class=AbstractAuthor>Sanaz Jabbari<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Jabbari, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ben Allison<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Allison, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, David Guthrie<!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span></span>
XE &quot;Guthrie, D.&quot; <![endif]--><!--[if supportFields]><span lang=FR
style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Louise Guthrie<!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span></span>
XE &quot;Guthrie, L.&quot; <![endif]--><!--[if supportFields]><span lang=FR
style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=PosterAbstractText>This paper describes the largest scale annotation
project involving the Enron email corpus to date. Over 12,500 emails were
classified, by humans, into the categories &quot;business&quot; and
&quot;Personal&quot; and then sub-categorised by type within these categories.
The paper quantifies how well humans perform on this task (evaluated by
inter-annotator agreement). It presents the problems experienced with the
separation of these language types. As a final section, the paper presents
preliminary results using a machine to perform this classification task.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
31</span></p>

<p class=AbstractTitle>Parsing Aligned Parallel Corpus by Projecting Syntactic
Relations from Annotated Source Corpus</p>

<p class=AbstractAuthor>Shailly Goyal<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Goyal, S.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Niladri Chatterjee<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chatterjee, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Example-based
parsing has already been proposed in literature. In particular, attempts are
being made to develop techniques for language pairs where the source and target
languages are different, e.g. Direct Projection Algorithm (Hwa et al., 2005).
This enables one to develop parsed corpus for target languages having fewer
linguistic tools with the help of a resource-rich source language. The DPA
algorithm works on the assumption of Direct Correspondence which simply means
that the relation between two words of the source language sentence can be
projected directly between the corresponding words of the parallel target
language sentence. However, we find that this assumption does not hold good all
the time. This leads to wrong parsed structure of the target language sentence.
As a solution we propose an algorithm called pseudo DPA (pDPA) that can work
even if Direct Correspondence assumption is not guaranteed. The proposed
algorithm works in a recursive manner by considering the embedded phrase
structures from outermost level to the innermost.<span
style='mso-spacerun:yes'>&nbsp; </span>The present work discusses the pDPA
algorithm, and illustrates it with respect to English-Hindi language pair. Link
Grammar based parsing has been considered as the underlying parsing scheme for
this work.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
33</span></p>

<p class=AbstractTitle>Analysis of Selective Strategies to Build a
Dependency-Analyzed Corpus</p>

<p class=AbstractAuthor>Kiyonori Ohtake<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ohtake, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper discusses sampling strategies for building a dependency-analyzed corpus
and analyzes them with different kinds of corpora. We used the Kyoto Text
Corpus, a dependency-analyzed corpus of newspaper articles, and prepared the
IPAL corpus, a dependency-analyzed corpus of example sentences in dictionaries,
as a new and different kind of corpus. The experimental results revealed that
the length of the test set controlled the accuracy and that the longest-first
strategy was good for an expanding corpus, but this was not the case when
constructing a corpus from scratch.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
35</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Dialog Systems<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Towards Conversational QA: Automatic Identification of
Problematic Situations and User Intent</p>

<p class=AbstractAuthor>Joyce Chai<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chai, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chen Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Tyler Baldwin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Baldwin, T. (2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>To enable conversational QA, it is important to
examine key issues addressed in conversational systems in the context of question
answering. In conversational systems, understanding user intent is critical to
the success of interaction. Recent studies have also shown that the capability
to automatically identify problematic situations during interaction can
significantly improve the<span style='mso-spacerun:yes'>&nbsp;&nbsp;
</span>system performance. Therefore, this paper investigates the new
implications of user intent and<span style='mso-spacerun:yes'>&nbsp;&nbsp;
</span>problematic situations in the context of question answering. Our studies
indicate that, in basic interactive QA, there are different types of user
intent that are tied to different kinds of system performance (e.g.,
problematic/error free situations). Once users are motivated to find specific
information related to their information goals, the interaction context can
provide useful cues for the system to automatically identify problematic
situations and user intent.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
37</span></p>

<p class=AbstractTitle>Using Machine Learning to Explore Human Multimodal
Clarification Strategies</p>

<p class=AbstractAuthor>Verena Rieser<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Rieser, V.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Oliver Lemon<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lemon, O.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We investigate the use of machine learning in
combination with feature engineering techniques to explore human multimodal
clarification strategies and the use of those strategies for dialogue systems.
We learn from data collected in a Wizard-of-Oz study where different wizards
could decide whether to ask a clarification request in a multimodal manner or
else use speech alone. We show that there is a uniform strategy across wizards
which is based on multiple features in the context. These are generic runtime
features which can be implemented in dialogue systems. Our prediction models
achieve a weighted f-score of 85.3% (which is a 25.5% improvement over a
one-rule baseline). To assess the effects of models, feature discretisation,
and selection, we also conduct a regression analysis. We then interpret and
discuss the use of the learnt strategy for dialogue systems. Throughout the
investigation we discuss the issues arising from using small initial
Wizard-of-Oz data sets, and we show that feature engineering is an essential
step when learning from such limited data.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
41</span></p>

<p class=AbstractTitle>Segmented and unsegmented dialogue-act annotation with
statistical dialogue models</p>

<p class=AbstractAuthor>Carlos D. Mart&iacute;nez-Hinarejos<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mart&iacute;nez-Hinarejos, C.D.&quot;
<![endif]--><!--[if supportFields]><span style='mso-element:field-end'></span><![endif]-->,
Ram&oacute;n Granell<!--[if supportFields]><span style='mso-element:field-begin'></span>
XE &quot;Granell, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jos&eacute; Miguel Bened&iacute;<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bened&iacute;, J.M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Dialogue systems are one of the most challenging
applications of Natural Language Processing. In recent years, some statistical
dialogue models have been proposed to cope with the dialogue problem. The
evaluation of these models is usually performed by using them as annotation
models. Many of the works on annotation use information such as the complete
sequence of dialogue turns or the correct segmentation of the dialogue. This
information is not usually available for dialogue systems. In this work, we propose
a statistical model that uses only the information that is usually available
and performs the segmentation and annotation at the same time. The results of
this model reveal the great influence that the availability of a correct
segmentation has in obtaining an accurate annotation of the dialogues.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
39</span></p>

<p class=AbstractTitle>Stochastic Discourse Modeling in Spoken Dialogue Systems
Using Semantic Dependency Graphs</p>

<p class=AbstractAuthor>Jui-Feng Yeh<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yeh, J-F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chung-Hsien Wu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wu, C-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mao-Zhu Yang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yang, M-Z.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This investigation proposes an approach to modeling
the discourse of spoken<span style='mso-ansi-language:EN-GB'> </span>dialogue
using semantic dependency graphs. By characterizing the discourse as a<span
style='mso-ansi-language:EN-GB'> </span>sequence of speech acts, discourse
modeling becomes the identification of the<span style='mso-ansi-language:EN-GB'>
</span>speech act sequence. A statistical approach is adopted to model the
relations<span style='mso-ansi-language:EN-GB'> </span>between words in the
users utterance using the semantic dependency graphs.<span style='mso-ansi-language:
EN-GB'> </span>Dependency relation between the headword and other words in a
sentence is<span style='mso-ansi-language:EN-GB'> </span>detected using the
semantic dependency grammar. In order to evaluate the<span style='mso-ansi-language:
EN-GB'> </span>proposed method, a dialogue system for medical service is
developed.<span style='mso-ansi-language:EN-GB'> </span>Experimental results
show that the rates for speech act detection and task<span style='mso-ansi-language:
EN-GB'> </span>completion are 95.6% and 85.24%, respectively, and the average
number of turns<span style='mso-ansi-language:EN-GB'> </span>of each dialogue
is 8.3. Compared with the Bayes' classifier and the<span style='mso-ansi-language:
EN-GB'> </span>PartialPattern Tree based approaches, we obtain 14.9% and 12.47%
improvements<span style='mso-ansi-language:EN-GB'> </span>in accuracy for
speech act identification, respectively.<span lang=EN-GB style='mso-ansi-language:
EN-GB'><span style='mso-tab-count:1'> </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
45<b><o:p></o:p></b></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Discourse<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Discourse Generation Using Utility-Trained Coherence
Models</p>

<p class=AbstractAuthor>Radu Soricut<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Soricut, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Daniel Marcu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Marcu, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We describe a generic framework for integrating
various stochastic models of discourse coherence in a manner that takes
advantage of their individual strengths. An integral part of this framework are
algorithms for searching and training these stochastic coherence models. We
evaluate the performance of our models and algorithms and show empirically that
utility-trained log-linear coherence models outperform each of the individual
coherence models considered.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
43</span></p>

<p class=AbstractTitle>A Grammatical Approach to Understanding Textual Tables
using Two-Dimensional SCFGs</p>

<p class=AbstractAuthor>Dekai Wu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Wu, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Ken Wing Kuen Lee<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lee, K.W.K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We present an elegant and extensible model that is
capable of providing semantic interpretations for an unusually wide range of
textual tables in documents. Unlike the few existing table analysis models,
which largely rely on relatively ad hoc heuristics, our linguistically-oriented
approach is systematic and grammar based, which allows our model (1) to be
concise and yet (2) recognize a wider range of data models than others, and (3)
disambiguate to a significantly finer extent the underlying semantic interpretation
of the table in terms of data models drawn from relation database theory. To
accomplish this, the model introduces Viterbi parsing under two-dimensional
stochastic CFGs. The cleaner grammatical approach facilitates not only greater
coverage, but also grammar extension and maintenance, as well as a more direct
and declarative link to semantic interpretation, for which we also introduce a
new, cleaner data model. In disambiguation experiments on recognizing relevant
data models of unseen web tables from different domains, a blind evaluation of
the model showed 60% precision and 80% recall.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
47</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Formal Grammars<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Coreference handling in XMG</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Claire
Gardent</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;</span><span lang=FR
style='mso-fareast-font-family:SimSun;mso-ansi-language:FR;mso-fareast-language:
ZH-CN'>Gardent, C.</span><span lang=FR style='mso-ansi-language:FR'>&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><span style='mso-spacerun:yes'>&nbsp;</span>and
Yannick Parmentier</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Parmentier</span><span lang=FR
style='mso-fareast-font-family:SimSun;mso-ansi-language:FR;mso-fareast-language:
ZH-CN'>, Y.</span><span lang=FR style='mso-ansi-language:FR'>&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=PosterAbstractText>We claim that existing specification languages for
tree based grammars<span style='mso-ansi-language:EN-GB'> </span>fail to
adequately support identifier management. We then show that<span
style='mso-ansi-language:EN-GB'> </span>XMG (eXtensible MetaGrammar) provides a
sophisticated<span style='mso-ansi-language:EN-GB'> </span>treatment of
identifiers which is effective in supporting a<span style='mso-ansi-language:
EN-GB'> </span>linguist-friendly grammar design.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
49</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Generation<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Adding Syntax to Dynamic Programming for Aligning
Comparable Texts for the Generation of Paraphrases</p>

<p class=AbstractAuthor>Siwei Shen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shen, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Dragomir R. Radev<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Radev, D.R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Agam Patel<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Patel, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and G&uuml;ne&ccedil; Erkan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Erkan, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Multiple sequence alignment techniques have
recently gained popularity<span style='mso-ansi-language:EN-GB'> </span>in the
Natural Language community, especially for tasks such as<span style='mso-ansi-language:
EN-GB'> </span>machine translation, text generation, and paraphrase<span
style='mso-ansi-language:EN-GB'> </span>identification. Prior work falls into
two categories, depending on the<span style='mso-ansi-language:EN-GB'> </span>type
of input used: (a) parallel corpora (e.g., multiple translations<span
style='mso-ansi-language:EN-GB'> </span>of the same text) or (b) comparable
texts (non-parallel but on the<span style='mso-ansi-language:EN-GB'> </span>same
topic). So far, only techniques based on parallel texts have<span
style='mso-ansi-language:EN-GB'> </span>successfully used syntactic information
to guide alignments. In this paper, we describe an algorithm for incorporating
syntactic features<span style='mso-ansi-language:EN-GB'> </span>in the
alignment process for non-parallel texts with the goal of<span
style='mso-ansi-language:EN-GB'> </span>generating novel paraphrases of
existing texts. Our method uses<span style='mso-ansi-language:EN-GB'> </span>dynamic
programming with alignment decision based on the local syntactic similarity
between two sentences. Our results show that<span style='mso-ansi-language:
EN-GB'> </span>syntactic alignment outrivals syntax-free methods by 20% in both<span
style='mso-ansi-language:EN-GB'> </span>grammaticality and fidelity when
computed over the novel sentences<span style='mso-ansi-language:EN-GB'> </span>generated
by alignment-induced finite state automata.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
53</span></p>

<p class=AbstractTitle>Conceptual Coherence in the Generation of Referring
Expressions</p>

<p class=AbstractAuthor>Albert Gatt<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gatt, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kees van Deemter<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;van Deemter, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>One of the challenges in the automatic generation
of referring<span style='mso-ansi-language:EN-GB'> </span>expressions is to
identify a set of domain entities coherently, that is, from the same conceptual
perspective. We describe and evaluate an algorithm that generates a
conceptually coherent description of a target<span style='mso-ansi-language:
EN-GB'> </span>set. The design of the algorithm is motivated by the results of<span
style='mso-ansi-language:EN-GB'> </span>psycholinguistic experiments.<span
lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
51</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Information Extraction<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Automatically Extracting Nominal Mentions of Events with
a Bootstrapped Probabilistic Classifier</p>

<p class=AbstractAuthor>Cassandre Creswell<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Creswell, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Matthew J. Beal<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Beal, M.J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, John Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, J.(3)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Thomas L. Cornell<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Cornell, T.L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Lars Nilsson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nilsson, L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Rohini K. Srihari<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Srihari, R.K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Most approaches to event extraction focus on
mentions anchored in verbs. However, many mentions of events surface as noun
phrases. Detecting them can increase the recall of event extraction and provide
the foundation for detecting relations between events. This paper describes a
weakly supervised method for detecting nominal event mentions that combines
techniques from word sense disambiguation (WSD) and lexical acquisition to
create a classifier that labels noun phrases as denoting events or non-events.
The classifier uses bootstrapped probabilistic generative models of the
contexts of events and non-events. The contexts are the lexically-anchored
semantic dependency relations that the NPs appear in. Our method dramatically
improves with bootstrapping, and comfortably outperforms lexical lookup methods
which are based on very much larger handcrafted resources.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
55</span></p>

<p class=AbstractTitle>URES : an Unsupervised Web Relation Extraction System </p>

<p class=AbstractAuthor>Benjamin Rosenfeld<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Rosenfeld, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Ronen Feldman<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Feldman, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Most information extraction systems either use hand
written extraction patterns or use a machine learning algorithm that is trained
on a manually annotated corpus. Both of these approaches require massive human
effort and hence prevent information extraction from becoming more widely
applicable. In this paper we present URES (Unsupervised Relation Extraction
System), which extracts relations from the Web in a totally unsupervised way.
It takes as input the descriptions of the target relations, which include the
names of the predicates, the types of their attributes, and several seed
instances of the relations. Then the system downloads from the Web a large
collection of pages that are likely to contain instances of the target
relations. From those pages, utilizing the known seed instances, the system
learns the relation patterns, which are then used for extraction. We present
several experiments in which we learn patterns and extract instances of a set
of several common IE relations, comparing several pattern learning and
filtering setups. We demonstrate that using simple noun phrase tagger is
sufficient as a base for accurate patterns. However, having a named entity
recognizer, which is able to recognize the types of the relation attributes
significantly, enhances the extraction performance. We also compare our approach
with KnowItAll's fixed generic patterns.<span lang=EN-GB style='mso-ansi-language:
EN-GB'><span style='mso-tab-count:1'>&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
61</span></p>

<p class=AbstractTitle>Automatic Creation of Domain Templates</p>

<p class=AbstractAuthor>Elena Filatova<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Filatova, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Vasileios Hatzivassiloglou<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hatzivassiloglou, V.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kathleen McKeown<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;McKeown, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Recently, many Natural Language Processing (NLP)
applications have improved the quality of their output by using various machine
learning techniques to mine Information Extraction (IE) patterns for capturing
information from the input text. Currently, to mine IE patterns one should know
in advance the type of the information that should be captured by these
patterns. In this work we propose a novel methodology for corpus analysis based
on cross-examination of several document collections representing different
instances of the same domain. We show that this methodology can be used for
automatic domain template creation. As the problem of automatic domain template
creation is rather new, there is no well-defined procedure for the evaluation
of the domain template quality. Thus, we propose a methodology for identifying
what information should be present in the template. Using this information we
evaluate the automatically created domain templates through the text snippets
retrieved according to the created templates.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
65</span></p>

<p class=AbstractTitle>Unsupervised Relation Disambiguation Using Spectral
Clustering</p>

<p class=AbstractAuthor>Jinxiu Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, J.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Donghong Ji<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ji, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chew Lim Tan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tan, C.L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Zhengyu Niu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Niu, Z.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper presents an unsupervised learning approach
to<span style='mso-ansi-language:EN-GB'> </span>disambiguate various relations
between name entities by use of<span style='mso-ansi-language:EN-GB'> </span>various
lexical and syntactic features from the contexts. It works<span
style='mso-ansi-language:EN-GB'> </span>by calculating eigenvectors of an
adjacency graph's Laplacian to<span style='mso-ansi-language:EN-GB'> </span>recover
a submanifold of data from a high dimensionality space and<span
style='mso-ansi-language:EN-GB'> </span>then performing cluster number
estimation on the eigenvectors.<span style='mso-ansi-language:EN-GB'> </span>Experiment
results on ACE corpora show that this spectral<span style='mso-ansi-language:
EN-GB'> </span>clustering based approach outperforms the other clustering<span
style='mso-ansi-language:EN-GB'> </span>methods.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
67</span></p>

<p class=AbstractTitle><st1:stockticker>ARE</st1:stockticker>: Instance
Splitting Strategies for Dependency Relation-based Information Extraction</p>

<p class=AbstractAuthor>Mstislav Maslennikov<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Maslennikov, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hai-Kiat Goh<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Goh, H-K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Tat-Seng Chua<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chua, T-S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Information Extraction (IE) is a fundamental
technology for NLP. Previous methods for IE were relying on co-occurrence
relations, soft patterns and properties of the target (for example, syntactic
role), which result in problems of handling paraphrasing and alignment of
instances. Our system <st1:stockticker>ARE</st1:stockticker> (Anchor and
Relation) is based on the dependency relation model and tackles these problems
by unifying entities according to their dependency relations, which we found to
provide more invariant relations between entities in many cases. In order to
exploit the complexity and characteristics of relation paths, we further
classify the relation paths into the categories of 'easy', 'average' and
'hard', and utilize different extraction strategies based on the
characteristics of those categories. Our extraction method leads to improvement
in performance by 3% and 6% for MUC4 and MUC6 respectively as compared to the
state-of-art IE systems.</p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
73</span></p>

<p class=AbstractTitle>Automatic Identification of Pro and Con Reasons in
Online Reviews</p>

<p class=AbstractAuthor>Soo-Min Kim<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kim, S-M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Eduard Hovy<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hovy, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>In this paper, we present a system that
automatically extracts the pros and cons from online reviews. Although many
approaches have been developed for ex-tracting opinions from text, our focus
here is on extracting the reasons of the opinions, which may themselves be in
the form of either fact or opinion. Leveraging online review sites with
author-generated pros and cons, we propose a system for aligning the pros and
cons to their sentences in review texts. A maximum en-tropy model is then
trained on the resulting labeled set to subsequently extract pros and cons from
online review sites that do not explicitly provide them. Our experimental
results show that our resulting system identifies pros and cons with 66%
precision and 76% recall.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
125</span><span lang=EN-GB style='mso-bidi-font-family:Arial;mso-font-kerning:
0pt'><o:p></o:p></span></p>

<p class=AbstractTitle>A Rote Extractor with Edit Distance-based Generalisation
and Multi-corpora Precision Calculation</p>

<p class=AbstractAuthor>Enrique Alfonseca<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Alfonseca, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Pablo Castells<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Castells, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Manabu Okumura<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Okumura, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Maria Ruiz-Casado<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ruiz-Casado, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>In this paper, we describe a rote extractor that
learns patterns for finding semantic relationships in unrestricted text, with
new procedures for pattern generalization and scoring. These include the use of
part of speech tags to guide the generalization, Named Entity categories inside
the patterns, an edit-distance-based pattern generalization algorithm, and a
pattern accuracy calculation procedure based on evaluating the patterns on
several test corpora. In an evaluation with 14 entities, the system attains a
precision higher than 50% for half of the relationships considered.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
57</span></p>

<p class=AbstractTitle>A Bio-inspired Approach for Multi-Word Expression
Extraction</p>

<p class=AbstractAuthor>Jianyong Duan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Duan, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ruzhan Lu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lu, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Weilin Wu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wu, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yi Hu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hu, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Yan Tian<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tian, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper proposes a new approach for Multi-word
Expression (MWE) extraction<span style='mso-ansi-language:EN-GB'> </span>on the
motivation of gene sequence alignment because textual sequence is<span
style='mso-ansi-language:EN-GB'> </span>similar to gene sequence in pattern
analysis. Theory of Longest Common<span style='mso-ansi-language:EN-GB'> </span>Subsequence
(LCS) originates from computer science and has been established as<span
style='mso-ansi-language:EN-GB'> </span>affine gap model in Bioinformatics. We
perform this developed LCS technique<span style='mso-ansi-language:EN-GB'> </span>combined
with linguistic criteria in MWE extraction. In comparison with<span
style='mso-ansi-language:EN-GB'> </span>traditional n-gram method, which is the
major technique for MWE extraction, LCS<span style='mso-ansi-language:EN-GB'> </span>approach
is applied with great efficiency and performance guarantee. Experimental
results show<span style='mso-ansi-language:EN-GB'> </span>that LCS-based
approach achieves better results than n-gram.<span lang=EN-GB style='mso-ansi-language:
EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
59</span></p>

<p class=AbstractTitle>Exploiting Non-local Features for Spoken Language
Understanding</p>

<p class=AbstractAuthor>Minwoo Jeong<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Jeong, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Gary Geunbae Lee<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lee, G.G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In
this paper, we exploit non-local features as an estimate of long-distance
dependencies to improve performance on the statistical spoken language
understanding (SLU) problem. The statistical natural language parsers trained
on text perform unreliably to encode non-local information on spoken language.
An alternative method we propose is to use trigger pairs that are automatically
extracted by a feature induction algorithm. We describe a light version of the
inducer in which a simple modification is efficient and successful. We evaluate
our method on an SLU task and show an error reduction of up to 27% over the
base local model.<span style='mso-tab-count:1'>&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
63</span></p>

<p class=AbstractTitle>Minority Vote: At-Least-N Voting Improves Recall for
Extracting Relations</p>

<p class=AbstractAuthor>Nanda Kambhatla<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kambhatla, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Several
NLP tasks are characterized by asymmetric data where one class label NONE,
signifying the absence of any structure (named entity, coreference, relation,
etc.) dominates all other classes. Classifiers built on such data typically
have a higher precision and a lower recall and tend to overproduce the NONE
class. We present a novel scheme for voting among a committee of classifiers
that can significantly boost the recall in such situations. We demonstrate
results showing up to a 16% relative improvement in ACE value for the 2004 ACE
relation extraction task for English, Arabic and Chinese.<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
69</span></p>

<p class=AbstractTitle>Interpreting Semantic Relations in Noun Compounds via
Verb Semantics</p>

<p class=AbstractAuthor>Su Nam Kim<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kim, S.N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Timothy Baldwin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Baldwin, T.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We propose a novel method for automatically
interpreting compound nouns based on a predefined set of semantic relations.
First we map verb tokens in sentential contexts to a fixed set of seed verbs
using WordNet: Similarity and Moby's Thesaurus. We then match the sentences
with semantic relations based on the semantics of the seed verbs and
grammatical roles of the head noun and modifier. Based on the semantics of the
matched sentences, we then build a classifier using TiMBL.<span
style='mso-spacerun:yes'>&nbsp; </span>The performance of our final system at
interpreting NCs is 52.6%.<span lang=EN-GB style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
71</span></p>

<p class=AbstractTitle>On-Demand Information Extraction </p>

<p class=AbstractAuthor>Satoshi Sekine<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sekine, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>At present, adapting an Information Extraction
system to new topics is an expensive and slow process, requiring some knowledge
engineering for each new topic. We propose a new paradigm of Information
Extraction which operates 'on demand' in response to a user's query. On-demand
Information Ex-traction (ODIE) aims to completely eliminate the customization
effort. Given a user query, the system will automatically create patterns to
extract salient relations in the text of the topic, and build tables from the
extracted information using paraphrase discovery technology. It relies on
recent advances in pattern discovery, paraphrase discovery, and extended named
entity tagging. We re-port on experimental results in which the system created
useful tables for many topics, demonstrating the feasibility of this approach.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
75</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Information Retrieval<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Using Bilingual Comparable Corpora and Semi-supervised
Clustering for Topic Tracking</p>

<p class=AbstractAuthor>Fumiyo Fukumoto<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Fukumoto, F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Yoshimi Suzuki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Suzuki, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
address the problem dealing with skewed data, and propose a method for
estimating effective training stories for the topic tracking task. For a small
number of labelled positive stories, we extract story pairs which consist of
positive and its associated stories from bilingual comparable corpora. To
overcome the problem of a large number of labelled negative stories, we
classify them into some clusters. This is done by using k-means with EM. The
results on the TDT corpora show the effectiveness of the method.<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
77</span></p>

<p class=AbstractTitle>Argumentative Feedback: A Linguistically-motivated Term
Expansion for Information Retrieval</p>

<p class=AbstractAuthor>Patrick Ruch<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ruch, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Imad Tbahriti<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tbahriti, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Julien Gobeill<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gobeill, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Alan R. Aronson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Aronson, A.R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We report on the development of a new automatic
feedback model to improve information retrieval in digital libraries. Our
hypothesis is that some particular sentences, selected based on argumentative
criteria, can be more useful than others to perform well-known feedback
information retrieval tasks. The argumentative model we explore is based on
four disjunct classes, which has been very regularly observed in scientific
reports: PURPOSE, METHODS, RESULTS, CONCLUSION. To test this hypothesis, we use
the Rocchio algorithm as baseline. While Rocchio selects the features to be
added to the original query based on statistical evidence, we propose to base
our feature selection also on argumentative criteria. Thus, we restrict the
expansion on features appearing only in sentences classified into one of our
argumentative categories. Our results, obtained on the OHSUMED collection, show
a significant improvement when expansion is based on PURPOSE (mean average
precision = +23%) and CONCLUSION (mean average precision = +41%) contents
rather than on other argumentative contents. These results suggest that
argumentation is an important linguistic dimension that could benefit
information retrieval.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
79</span></p>

<p class=AbstractTitle>Examining the Content Load of Part of Speech Blocks for
Information Retrieval</p>

<p class=AbstractAuthor>Christina Lioma<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lioma, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Iadh Ounis<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ounis, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We investigate the connection between part of
speech (<st1:stockticker>POS</st1:stockticker>) distribution and content in
language. We define <st1:stockticker>POS</st1:stockticker> blocks to be groups
of parts of speech. We hypothesise that there exists a directly proportional
relation between the frequency of <st1:stockticker>POS</st1:stockticker> blocks
and their content salience. We also hypothesise that the class membership of
the parts of speech within such blocks reflects the content load of the blocks,
on the basis that open class parts of speech are more content-bearing than
closed class parts of speech. We test these hypotheses in the context of
Information Retrieval, by syntactically representing queries, and removing from
them content-poor blocks, in line with the aforementioned hypotheses. For our
first hypothesis, we induce <st1:stockticker>POS</st1:stockticker> distribution
information from a corpus, and approximate the probability of occurrence of <st1:stockticker>POS</st1:stockticker>
blocks as per two statistical estimators separately. For our second hypothesis,
we use simple heuristics to estimate the content load within <st1:stockticker>POS</st1:stockticker>
blocks. We use the Text REtrieval Conference (TREC) queries of 1999 and 2000 to
retrieve documents from the WT2G and WT10G test collections, with five
different retrieval strategies. Experimental outcomes confirm that our
hypotheses hold in the context of Information Retrieval.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="18"><span lang=EN-GB>6-7pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
81</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Language Acquisition<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Finding Synonyms Using Automatic Word Alignment and
Measures of Distributional Similarity</p>

<p class=AbstractAuthor>Lonneke van der Plas<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;van der Plas, L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and J&ouml;rg Tiedemann<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tiedemann, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>There have been many proposals to extract
semantically related words using measures of distributional similarity, but
these typically are not able to distinguish between synonyms and other types of
semantically related words such as antonyms, (co)hyponyms and hypernyms. We
present a method based on automatic word alignment of parallel corpora
consisting of documents translated into multiple languages and compare our
method with a monolingual syntax-based method. </p>

<p class=PosterAbstractText>The approach that uses aligned multilingual data to
extract synonyms shows much higher precision and recall scores for the task of
synonym extraction than the monolingual syntax-based approach.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
83</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Language Modeling<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Techniques to incorporate the benefits of a Hierarchy in
a modified hidden Markov model</p>

<p class=AbstractAuthor>Lin-Yi Chou<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chou, L-Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper explores techniques to take advantage of the fundamental difference in
structure between hidden Markov models (HMM) and hierarchical hidden Markov
models (HHMM). The HHMM structure allows repeated parts of the model to be
merged together. A merged model takes advantage of the recurring patterns
within the hierarchy, and the clusters that exist in some sequences of
observations, in order to increase the extraction accuracy. This paper also
presents a new technique for reconstructing grammar rules automatically. This
work builds on the idea of combining a phrase extraction method with HHMM to
expose patterns within English text. The reconstruction is then used to
simplify the complex structure of an HHMM.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
85</span></p>

<p class=AbstractTitle>Using Word Support Model to Improve Chinese Input System</p>

<p class=AbstractAuthor>Jia-Lin Tsai<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsai, J-L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper presents a word support model (</span><st1:stockticker><span lang=EN-GB
 style='mso-ansi-language:EN-GB'>WSM</span></st1:stockticker><span lang=EN-GB
style='mso-ansi-language:EN-GB'>). The </span><st1:stockticker><span
 lang=EN-GB style='mso-ansi-language:EN-GB'>WSM</span></st1:stockticker><span
lang=EN-GB style='mso-ansi-language:EN-GB'> can effectively perform homophone
selection and syllable-word segmentation to improve Chinese input systems. The
experimental results show that: (1) the </span><st1:stockticker><span
 lang=EN-GB style='mso-ansi-language:EN-GB'>WSM</span></st1:stockticker><span
lang=EN-GB style='mso-ansi-language:EN-GB'> is able to achieve tonal (syllables
input with four tones) and toneless (syllables input without four tones)
syllable-to-word (</span><st1:stockticker><span lang=EN-GB style='mso-ansi-language:
 EN-GB'>STW</span></st1:stockticker><span lang=EN-GB style='mso-ansi-language:
EN-GB'>) accuracies of 99% and 92%, respectively, among the converted words;
and (2) while applying the </span><st1:stockticker><span lang=EN-GB
 style='mso-ansi-language:EN-GB'>WSM</span></st1:stockticker><span lang=EN-GB
style='mso-ansi-language:EN-GB'> as an adaptation processing, together with the
Microsoft Input Method Editor 2003 (MSIME) and an optimized bigram model, the
average tonal and toneless </span><st1:stockticker><span lang=EN-GB
 style='mso-ansi-language:EN-GB'>STW</span></st1:stockticker><span lang=EN-GB
style='mso-ansi-language:EN-GB'> improvements are 37% and 35%, respectively.<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
89</span></p>

<p class=AbstractTitle>Reduced n-gram models for English and Chinese corpora</p>

<p class=AbstractAuthor>Le Q Ha<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Ha, L.Q.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, P Hanna<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hanna, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, D W Stewart<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Stewart, D.W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and F J Smith<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Smith, F.J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Statistical
language models should improve as the size of the n-grams increases from 3 to 5
or higher. However, the number of parameters and calculations, and the storage
requirement increase very rapidly if we attempt to store all possible
combinations of n-grams. To avoid these problems, the reduced n-grams' approach
previously developed by O'Boyle (1993) can be applied. A reduced n-gram
language model can store an entire corpus's phrase-history length within
feasible storage limits. Another theoretical advantage of reduced n-grams is
that they are closer to being semantically complete than traditional models,
which include all n-grams. In our experiments, the reduced n-gram Zipf curves
are first presented, and compared with previously obtained conventional n-grams
for both English and Chinese. The reduced n-gram model is then applied to large
English and Chinese corpora. For English, we can reduce the model sizes,
compared to 7-gram traditional model sizes, with factors of 14.6 for a
40-million-word corpus and 11.0 for a 500-million-word corpus while obtaining
5.8% and 4.2% improvements in perplexities. For Chinese, we gain a 16.9%
perplexity reductions and we reduce the model size by a factor larger than
11.2. This paper is a step towards the modeling of English and Chinese using
semantically complete phrases in an n-gram model.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
87</span></p>

<p class=AbstractTitle>Word Vectors and Two Kinds of Similarity</p>

<p class=AbstractAuthor>Akira Utsumi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Utsumi, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Daisuke Suzuki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Suzuki, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper examines what kind of similarity between words can be represented by what
kind of word vectors in the vector space model. Through two experiments, three
methods for constructing word vectors, i.e., LSA-based, cooccurrence-based and
dictionary-based methods, were compared in terms of the ability to represent
two kinds of similarity, i.e., taxonomic similarity and associative similarity.
The result of the comparison was that the dictionary-based word vectors better
reflect taxonomic similarity, while the LSA-based and the cooccurrence-based
word vectors better reflect associative similarity.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
93</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Language Resources<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Efficient sentence retrieval based on syntactic
structure</p>

<p class=AbstractAuthor>Ichikawa Hiroshi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ichikawa, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hakoda Keita<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hakoda, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hashimoto Taiichi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hashimoto, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Tokunaga Takenobu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tokunaga, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper proposes an efficient method<span
style='mso-ansi-language:EN-GB'> </span>of sentence retrieval based on
syntactic<span style='mso-ansi-language:EN-GB'> </span>structure. Collins
proposed Tree Kernel<span style='mso-ansi-language:EN-GB'> </span>to calculate
structural similarity. However,<span style='mso-ansi-language:EN-GB'> </span>structural
retrieval based on Tree Kernel<span style='mso-ansi-language:EN-GB'> </span>is
not practicable because the size of the<span style='mso-ansi-language:EN-GB'> </span>index
table by Tree Kernel becomes impractical.<span style='mso-ansi-language:EN-GB'>
</span>We propose more efficient algorithms<span style='mso-ansi-language:EN-GB'>
</span>approximating Tree Kernel: Tree<span style='mso-ansi-language:EN-GB'> </span>Overlapping
and Subpath Set. These algorithms<span style='mso-ansi-language:EN-GB'> </span>are
more efficient than Tree Kernel<span style='mso-ansi-language:EN-GB'> </span>because
indexing is possible with practical<span style='mso-ansi-language:EN-GB'> </span>computation
resources. The results of the<span style='mso-ansi-language:EN-GB'> </span>experiments
comparing these three algorithms<span style='mso-ansi-language:EN-GB'> </span>showed
that structural retrieval with<span style='mso-ansi-language:EN-GB'> </span>Tree
Overlapping and Subpath Set were<span style='mso-ansi-language:EN-GB'> </span>faster
than that with Tree Kernel by 100<span style='mso-ansi-language:EN-GB'> </span>times
and 1,000 times respectively.<span lang=EN-GB style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
91</span></p>

<p class=AbstractTitle>From Prosodic Trees to Syntactic Trees</p>

<p class=AbstractAuthor>Andi Wu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Wu, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kirk Lowery<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lowery, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper describes an ongoing effort to parse the Hebrew Bible. The parser
consults the bracketing information extracted from the cantillation marks of
the Masoetic text. We first constructed a cantillation treebank which encodes
the prosodic structures of the text.<span style='mso-spacerun:yes'>&nbsp;
</span>It was found that many of the prosodic boundaries in the cantillation
trees correspond, directly or indirectly, to the phrase boundaries of the
syntactic trees we are trying to build.<span
style='mso-spacerun:yes'>&nbsp;&nbsp; </span>All the useful boundary
information was then extracted to help the parser make syntactic decisions,
either serving as hard constraints in rule application or used
probabilistically in tree ranking. This has greatly improved the accuracy and
efficiency of the parser and reduced the amount of manual work in building a
Hebrew treebank.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
95</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Lexical Semantics<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>N Semantic Classes are Harder than Two</p>

<p class=AbstractAuthor>Ben Carterette<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Carterette, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Rosie Jones<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Jones, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Wiley Greiner<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Greiner, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Cory Barr<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Barr, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We show that we can automatically classify
semantically related phrases into 10 classes. Classification robustness is
improve by training with multiple sources of evidence, including
within-document cooccurrence, HTML markup, syntactic relationships in
sentences, substitutability in query logs, and string similarity. Our work
provides a benchmark for automatic n-way classification into WordNet¡¦s semantic
classes, both on a TREC news corpus and on a corpus of substitutable search
query phrases.<span lang=EN-GB style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
97</span></p>

<p class=AbstractTitle>Modeling Adjectives in Computational Relational Lexica</p>

<p class=AbstractAuthor>Palmira Marrafa<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Marrafa, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Sara Mendes<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mendes, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In
this paper we propose a small set of lexical conceptual relations which allow
to encode adjectives in computational relational lexica in a principled and
integrated way. Our main motivation comes from the fact that adjectives and
certain classes of verbs, related in a way or another with adjectives, do not
have a satisfactory representation in this kind of lexica. This is due to a
great extent to the heterogeneity of their semantic and syntactic properties.
We sustain that such properties are mostly derived from the relations holding
between adjectives and other </span><st1:stockticker><span lang=EN-GB
 style='mso-ansi-language:EN-GB'>POS</span></st1:stockticker><span lang=EN-GB
style='mso-ansi-language:EN-GB'>. Accordingly, our proposal is mainly concerned
with the specification of appropriate cross-</span><st1:stockticker><span
 lang=EN-GB style='mso-ansi-language:EN-GB'>POS</span></st1:stockticker><span
lang=EN-GB style='mso-ansi-language:EN-GB'> relations to encode adjectives in
lexica of the type considered here.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
101</span></p>

<p class=AbstractTitle>Unsupervised Induction of Modern Standard Arabic Verb
Classes Using Syntactic Frames and LSA</p>

<p class=AbstractAuthor>Neal Snider<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Snider, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mona Diab<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Diab, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We exploit the resources in the Arabic Treebank
(ATB) and Arabic Gigaword (AG) to determine the best features for the novel
task of automatically creating lexical semantic verb classes for Modern
Standard Arabic (<st1:stockticker>MSA</st1:stockticker>). The verbs are
classified into groups that share semantic elements of meaning as they exhibit
similar syntactic behavior. The results of the clustering experiments are
compared with a gold standard set of classes, which is approximated by using
the noisy English translations provided in the ATB to create Levin-like classes
for <st1:stockticker>MSA</st1:stockticker>. The quality of the clusters is
found to be sensitive to the inclusion of syntactic frames, LSA vectors,
morphological pattern, and subject animacy. The best set of parameters yields
an F<sub>£]=1</sub> score of 0.456, compared to a random baseline of an F<sub>£]=1</sub>
score of 0.205.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
103</span></p>

<p class=AbstractTitle>Robust Word Sense Translation by EM Learning of Frame
Semantics </p>

<p class=AbstractAuthor>Pascale Fung<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Fung, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Benfeng Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We propose a robust method of automatically
constructing a bilingual word sense dictionary from readily available
monolingual ontologies by using estimation- maximization, without any annotated
training data or manual tuning. We demonstrate our method on the English
FrameNet and Chinese HowNet structures. Owing to the robustness of EM
iterations in improving translation likelihoods, our word sense translation
accuracies are very high, at 82% on average, for the 11 most ambiguous words in
the English FrameNet with 5 senses or more. We also carried<span
style='mso-spacerun:yes'>&nbsp;&nbsp; </span>out a pilot study on using this
automatically generated bilingual word sense dictionary to choose the best
translation candidates and show the first significant evidence that frame
semantics are useful for translation disambiguation. Translation disambiguation
accuracy using frame semantics is 75%, compared to 15% by using dictionary
glossing only. These results demonstrate the great potential for future
application of bilingual frame semantics to machine translation tasks.<span
lang=EN-GB style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
99</span></p>

<p class=AbstractTitle>Integrating Pattern-based and Distributional Similarity
Methods for Lexical Entailment Acquisition</p>

<p class=AbstractAuthor>Shachar Mirkin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mirkin, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ido Dagan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Dagan, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Maayan Geffet<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Geffet, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper addresses the problem of acquiring
lexical semantic relationships, applied to the lexical entailment relation. Our
main contribution is a novel conceptual integration between the two distinct
acquisition paradigms for lexical relations ¡V the pattern-based and the
distributional similarity approaches. The integrated method exploits mutual
complementary information of the two approaches to obtain candidate relations
and informative characterizing features. Then, a small size training set is
used to construct a more accurate supervised classifier, showing significant increase
in both recall and precision over the original approaches.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
105</span></p>

<p class=AbstractTitle>Transformation-based Interpretation of Implicit Parallel
Structures: Reconstructing the meaning of vice versa and similar linguistic
operators</p>

<p class=AbstractAuthor>Helmut Horacek<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Horacek, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Magdalena Wolska<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wolska, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Successful
participation in dialogue as well as understanding written text requires, among
others, interpretation of specifications implicitly conveyed through parallel
structures. While those whose reconstruction requires insertion of a missing
element, such as gapping and ellipsis, have been addressed to a certain extent
by computational approaches, there is virtually no work addressing parallel
structures headed by vice versa-like operators, whose reconstruction requires
transformation. In this paper, we address the meaning reconstruction of such
constructs by an informed reasoning process. The applied techniques include
building deep semantic representations, application of categories of patterns
underlying a formal reconstruction, and using pragmatically-motivated and
empirically justified preferences. We present an evaluation of our algorithm
conducted on a uniform collection of texts containing the phrases in question.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
107</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>The Lexicon<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Improving English Subcategorization Acquisition with
Diathesis Alternations as Heuristic Information</p>

<p class=AbstractAuthor>Xiwu Han<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Han, X.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Tiejun Zhao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhao, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Xingshang Fu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Fu, X.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Automatically
acquired lexicons with subcategorization information have al-ready proved
accurate and useful enough for some purposes but their accuracy still shows
room for improvement. By means of diathesis alternation, this paper pro-poses a
new filtering method, which im-proved the performance of Korhonen acquisition
system remarkably, with the precision increased to 91.18% and recall unchanged,
making the acquired lexicon much more practical for further manual proofreading
and other NLP uses.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
109</span></p>

<p class=AbstractTitle>A Term Recognition Approach to Acronym Recognition</p>

<p class=AbstractAuthor>Naoaki Okazaki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Okazaki, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Sophia Ananiadou<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ananiadou, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
present a term recognition approach to extract acronyms and their definitions from
a large text collection. Parenthetical expressions appearing in a text
collection are identified as potential acronyms. Assuming terms appearing
frequently in the proximity of an acronym to be the expanded forms
(definitions) of the acronyms, we apply a term recognition method to enumerate
such candidates and to measure the likelihood scores of the expanded forms.
Based on the list of the expanded forms and their likelihood scores, the
proposed algorithm determines the final acronym-definition pairs. The proposed
method combined with a letter matching algorithm achieved 78% precision and 85%
recall on an evaluation corpus with 4,212 acronym-definition pairs.<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
113</span></p>

<p class=AbstractTitle>Learning Transliteration Lexicons from the Web</p>

<p class=AbstractAuthor>Jin-Shea Kuo<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kuo, J-S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Haizhou Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Li, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Ying-Kuei Yang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yang, Y-K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper presents an adaptive learning framework for Phonetic Similarity Modeling
(PSM) that supports the automatic construction of transliteration lexicons. The
learning algorithm starts with minimum prior knowledge about machine
transliteration, and acquires knowledge iteratively from the Web. We study the
active learning and the unsupervised learning strategies that minimize human
supervision in terms of data labeling. The learning process refines the PSM and
constructs a transliteration lexicon at the same time. We evaluate the proposed
PSM and its learning algorithm through a series of systematic experiments,
which show that the proposed framework is reliably effective on two independent
databases.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
111</span></p>

<p class=AbstractTitle>Compiling a Lexicon of Cooking Actions for Animation
Generation</p>

<p class=AbstractAuthor>Kiyoaki Shirai<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shirai, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hiroshi Ookawa<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ookawa, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper describes a system which generates animations for cooking actions in
recipes, to help people understand recipes written in Japanese. The major goal
of this research is to increase the scalability of the system, i.e., to develop
a system which can handle various kinds of cooking actions. We designed and
compiled the lexicon of cooking actions required for the animation generation
system. The lexicon includes the action plan used for animation generation, and
the information about ingredients upon which the cooking action is taken.
Preliminary evaluation shows that our lexicon contains most of the cooking
actions that appear in Japanese recipes. We also discuss how to handle
linguistic expressions in recipes, which are not included in the lexicon, in
order to generate animations for them.<span style='mso-tab-count:1'>&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
117</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Machine Learning Methods<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Semantic parsing with Structured <st1:stockticker>SVM</st1:stockticker>
Ensemble Classification Models</p>

<p class=AbstractAuthor>Le-Minh Nguyen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nguyen, L-M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Akira Shimazu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shimazu, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Xuan-Hieu Phan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Phan, X-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We present a learning framework for structured
support vector models<span style='mso-ansi-language:EN-GB'> </span>in which
boosting and bagging methods are used to construct ensemble<span
style='mso-ansi-language:EN-GB'> </span>models. We also propose a selection
method which is based on a<span style='mso-ansi-language:EN-GB'> </span>switching
model among a set of outputs of individual classifiers<span style='mso-ansi-language:
EN-GB'> </span>when dealing with natural language parsing problems. The
switching<span style='mso-ansi-language:EN-GB'> </span>model uses subtrees
mined from the corpus and a boosting-based<span style='mso-ansi-language:EN-GB'>
</span>algorithm to select the most appropriate output. The application of<span
style='mso-ansi-language:EN-GB'> </span>the proposed framework on the domain of
semantic parsing shows<span style='mso-ansi-language:EN-GB'> </span>advantages
in comparison with the original large margin methods.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
115</span></p>

<p class=AbstractTitle>Combining Statistical and Knowledge-based Spoken
Language Understanding in Conditional Models</p>

<p class=AbstractAuthor>Ye-Yi Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, Y-Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Alex Acero<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Acero, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Milind Mahajan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mahajan, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and John Lee<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lee, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Spoken Language Understanding (SLU) addresses the
problem of extracting semantic meaning conveyed in an utterance. The
traditional knowledge-based approach to this problem is very expensive ¡V it
requires joint expertise in natural language processing and speech recognition,
and best practices in language engineering for every new domain. On the other
hand, a statistical learning approach needs a large amount of annotated data
for model training, which is seldom available in practical applications outside
of large research labs. A generative HMM/CFG composite model, which integrates
easy-to-obtain domain knowledge into a data-driven statistical learning
framework, has previously been introduced to reduce data requirement. The major
contribution of this paper is the investigation of integrating prior knowledge
and statistical learning in a conditional model framework. We also study and
compare conditional random fields (CRFs) with perceptron learning for SLU.
Experimental results show that the conditional models achieve more than 20%
relative reduction in slot error rate over the HMM/CFG model, which had already
achieved an SLU accuracy at the same level as the best results reported on the <st1:stockticker>ATIS</st1:stockticker>
data.</p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
121</span></p>

<p class=AbstractTitle>Combining Association Measures for Collocation
Extraction</p>

<p class=AbstractAuthor>Pavel Pecina<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pecina, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Pavel Schlesinger<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Schlesinger, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
introduce the possibility of combining lexical association measures and present
empirical results of several methods employed in automatic collocation
extraction. First, we present a comprehensive summary overview of association
measures and their performance on manually annotated data evaluated by
precision-recall graphs and mean average precision. Second, we describe several
classification methods for combining association measures, followed by their
evaluation and comparison with individual measures. Finally, we propose a
feature selection algorithm significantly reducing the number of combined
measures with only a small performance degradation.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
119</span></p>

<p class=AbstractTitle>Boosting Statistical Word Alignment Using Labeled and
Unlabeled Data</p>

<p class=AbstractAuthor>Hua Wu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Wu, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Haifeng Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Zhanyi Liu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Liu, Z.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper proposes a semi-supervised boosting
approach to improve statistical word alignment with limited labeled data and
large amounts of unlabeled data. The proposed approach modifies the supervised
boosting algorithm to a semi-supervised learning algorithm by incorporating the
unlabeled data. In this algorithm, we build a word aligner by using both the
labeled data and the unlabeled data. Then we build a pseudo reference set for
the unlabeled data, and calculate the error rate of each word aligner using
only the labeled data. Based on this semi-supervised boosting algorithm, we
investigate two boosting methods for word alignment. In addition, we improve
the word alignment results by combining the results of the two semi-supervised
boosting methods. Experimental results on word alignment indicate that
semi-supervised boosting achieves relative error reductions of 28.29% and
19.52% as compared with supervised boosting and unsupervised boosting,
respectively.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
123</span></p>

<div style='border:solid windowtext 1.0pt;mso-border-alt:solid windowtext .5pt;
padding:1.0pt 4.0pt 1.0pt 4.0pt'>

<h2><span lang=EN-GB style='mso-ansi-language:EN-GB'>Tuesday 18th July<o:p></o:p></span></h2>

</div>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Machine Translation<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Soft Syntactic Constraints for Word Alignment through
Discriminative Training</p>

<p class=AbstractAuthor>Colin Cherry<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Cherry, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dekang Lin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lin, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Word alignment methods can gain valuable guidance
by ensuring that their alignments maintain cohesion with respect to the phrases
specified by a monolingual dependency tree. However, this hard constraint can
also rule out correct alignments, and its utility decreases as alignment models
become more complex. We use a publicly available structured output <st1:stockticker>SVM</st1:stockticker>
to create a max-margin syntactic aligner with a soft cohesion constraint. The
resulting aligner is the first, to our knowledge, to use a discriminative
learning method to train an <st1:stockticker>ITG</st1:stockticker> bitext
parser.</p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
2</span></p>

<p class=AbstractTitle>MT Evaluation: Human-like vs. Human Acceptable</p>

<p class=AbstractAuthor>Enrique Amig&oacute;<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Amig&oacute;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>, E.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Jes&uacute;s Gim&eacute;nez<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gim&eacute;nez, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Julio Gonzalo<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gonzalo, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Llu&iacute;s M&agrave;rquez<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;M&agrave;rquez, L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We present a comparative study on Machine
Translation Evaluation according to two different criteria: human likeness and
human acceptability.<span style='mso-spacerun:yes'>&nbsp; </span>We provide
empirical evidence that there is a relationship between these two kinds of
evaluation: human likeness implies human acceptability but the reverse is not
true. From the point of view of automatic evaluation this implies that metrics
based on human likeness are more reliable for system tuning.</p>

<p class=PosterAbstractText>Our results also show that current evaluation
metrics are not always able to distinguish between automatic and human
translations. In order to improve the descriptive power of current metrics we
propose the use of additional syntax-based metrics, and metric combinations
inside the QARLA Framework.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
4</span></p>

<p class=AbstractTitle>Low-cost Enrichment of Spanish WordNet with
Automatically Translated Glosses: Combining General and Specialized Models</p>

<p class=AbstractAuthor>Jes&uacute;s Gim&eacute;nez<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gim&eacute;nez, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Llu&iacute;s M&agrave;rquez<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;M&agrave;rquez, L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper studies the enrichment of Spanish
WordNet with synset glosses automatically obtained from the English WordNet
glosses using a phrase-based Statistical Machine Translation system. We
construct the English-Spanish translation system from a parallel corpus of
proceedings of the European Parliament, and study how to adapt statistical
models to the domain of dictionary definitions. We build specialized language
and translation models from a small set of parallel definitions and experiment
with robust manners to combine them. A statistically significant increase in
performance is obtained. The best system is finally used to generate a
definition for all Spanish synsets, which are currently ready for a manual
revision. As a complementary issue, we analyze the impact of the amount of
in-domain data needed to improve a system trained entirely on out-of-domain
data.<span lang=EN-GB style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
10</span></p>

<p class=AbstractTitle>ATLAS ¡V a new text alignment architecture</p>

<p class=AbstractAuthor>Bettina Schrader<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Schrader, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
are presenting a new, hybrid alignment architecture for aligning bilingual,
linguistically annotated parallel corpora. It is able to align simultaneously
at paragraph, sentence, phrase and word level, using statistical and heuristic
cues, along with linguistics-based rules. The system currently aligns English
and German texts, and the linguistic annotation used covers </span><st1:stockticker><span
 lang=EN-GB style='mso-ansi-language:EN-GB'>POS</span></st1:stockticker><span
lang=EN-GB style='mso-ansi-language:EN-GB'>-tags, lemmas and syntactic
constituents. However, as the system is highly modular, we can easily adapt it
to new language pairs and other types of annotation. <o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>The
hybrid nature of the system allows experiments with a variety of alignment cues
to find solutions to word alignment problems like the correct alignment of rare
words and multiwords, or how to align despite syntactic differences between two
languages.<o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>First
performance tests are promising, and we are setting up a gold standard for a
thorough evaluation of the system.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
14</span></p>

<p class=AbstractTitle>Minimum Risk Annealing for Training Log-Linear Models</p>

<p class=AbstractAuthor>David A. Smith<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Smith, D.A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jason Eisner<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Eisner, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>When training the parameters for a natural language
system, one would prefer to minimize 1-best loss (error) on an evaluation set.
Since the error surface for many natural language problems is piecewise
constant and riddled with local minima, many systems instead optimize
log-likelihood, which is conveniently differentiable and convex. We propose
training instead to minimize the expected loss, or risk. We define this
expectation using a probability distribution over hypotheses that we gradually
sharpen (anneal) to focus on the 1-best hypothesis. Besides the linear loss functions
used in previous work, we also describe techniques for optimizing nonlinear
functions such as precision or the BLEU metric. We present experiments training
log-linear combinations of models for dependency parsing and for machine
translation. In machine translation, annealed minimum risk training achieves
significant improvements in BLEU over standard minimum error training. We also
show improvements in labeled dependency parsing.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
16</span></p>

<p class=AbstractTitle>Word Alignment for Languages with Scarce Resources Using
Bilingual Corpora of Other Language Pairs</p>

<p class=AbstractAuthor>Haifeng Wang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wang, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hua Wu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wu, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Zhanyi Liu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Liu, Z.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper proposes an approach to improve word
alignment for languages with scarce resources using bilingual corpora of other
language pairs. To perform word alignment between languages L1 and L2, we
introduce a third language L3. Although only small amounts of bilingual data
are available for the desired language pair L1-L2, large-scale bilingual
corpora in L1-L3 and L2-L3 are available. Based on these two additional corpora
and with L3 as the pivot language, we build a word alignment model for L1 and
L2. This approach can build a word alignment model for two languages even if no
bilingual corpus is available in this language pair. In addition, we build
another word alignment model for L1 and L2 using the small L1-L2 bilingual
corpus. Then we interpolate the above two models to further improve word
alignment between L1 and L2. Experimental results indicate a relative error
rate reduction of 21.30% as compared with the method only using the small
bilingual corpus in L1 and L2.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
22</span></p>

<p class=AbstractTitle>BiTAM: Bilingual Topic AdMixture Models for Word
Alignment</p>

<p class=AbstractAuthor>Bing Zhao<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Zhao, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Eric P. Xing<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Xing, E.P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We propose a novel bilingual topical admixture
(BiTAM) formalism for word alignment in statistical machine translation. Under
this formalism, the parallel sentence-pairs within a document-pair are assumed
to constitute a mixture of hidden topics; each word-pair follows a
topic-specific bilingual translation model. Three BiTAM models are proposed to
capture topic sharing at different levels of linguistic granularity (i.e., at
the sentence or word levels). These models enable word alignment process to
leverage topical contents of document-pairs. Efficient variational
approximation algorithms are designed for inference and parameter estimation.
With the inferred latent topics, BiTAM models facilitate coherent pairing of
bilingual linguistic entities that share common topical aspects. Our
preliminary experiments show that the proposed models improve word alignment
accuracy, and lead to better translation quality.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
26</span></p>

<p class=AbstractTitle>A High-Accurate Chinese-English Backward NE Translation
System Combining Both Lexical Information and Web Statistics</p>

<p class=AbstractAuthor>Conrad Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hsin-Hsi Chen<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chen, H-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Named entity translation is indispensable in cross
language information retrieval nowadays. We propose an approach of combining
lexical information, web statistics, and inverse search based on Google to
backward translate a Chinese named entity (NE) into English. Our system
achieves a high Top-1 accuracy of 87.6%, which is a relatively good performance
reported in this area until present<span lang=EN-GB style='mso-ansi-language:
EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
6</span></p>

<p class=AbstractTitle>Factoring Synchronous Grammars by Sorting </p>

<p class=AbstractAuthor>Daniel Gildea<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gildea, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Giorgio Satta<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Satta, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hao Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Synchronous Context-Free Grammars (SCFGs) have been
successfully exploited as translation models in machine translation
applications. When parsing with an SCFG, computational complexity grows
exponentially with the length of the rules, in the worst case. In this paper we
examine the problem of factorizing each rule of an input SCFG to a generatively
equivalent set of rules, each having the smallest possible length. Our
algorithm works in time O(n log n), for each rule of length n. This improves
upon previous results and solves an open problem about recognizing permutations
that can be factored.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
8</span></p>

<p class=AbstractTitle>Stochastic Iterative Alignment for Machine Translation
Evaluation</p>

<p class=AbstractAuthor>Ding Liu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Liu, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Daniel Gildea<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gildea, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>A number of metrics for automatic evaluation of
machine translation have been proposed in recent years, with some metrics
focusing on measuring the adequacy of MT output, and other metrics focusing on
fluency. Adequacy-oriented metrics such as<span
style='mso-spacerun:yes'>&nbsp;&nbsp; </span>BLEU measure n-gram overlap of MT
outputs and their references, but do not represent sentence-level information.
In contrast, fluency-oriented metrics such as ROUGE-W compute longest common
subsequences, but ignore words not aligned by the LCS. We propose a metric
based on stochastic iterative string alignment (SIA), which aims to combine the
strengths of both approaches. We compare SIA with existing metrics, and find
that it outperforms them in overall evaluation, and works specially well in
fluency evaluation.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
12</span></p>

<p class=AbstractTitle>Simultaneous English-Japanese Spoken Language
Translation Based on Incremental Dependency Parsing and Transfer</p>

<p class=AbstractAuthor>Koichiro Ryu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ryu, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Shigeki Matsubara<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Matsubara, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Yasuyoshi Inagaki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Inagaki, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper proposes a method for incrementally
translating English spoken language into Japanese. To realize simultaneous
translation between languages with different word order, such as English and
Japanese, our method utilizes the feature that the word order of a target
language is flexible. To resolve the problem of generating a grammatically
incorrect sentence, our method uses dependency structures and Japanese
dependency constraints to determine the word order of a translation. Moreover,
by considering the fact that the inversion of predicate expressions occurs more
frequently in Japanese spoken language, our method takes advantage of a predicate
inversion to resolve the problem that Japanese has the predicate at the end of
a sentence. Furthermore, our method includes the function of canceling an
inversion by restating a predicate when the translation is incomprehensible due
to the inversion. We implement a prototype translation system and conduct an
experiment with all 578 sentences in the <st1:stockticker>ATIS</st1:stockticker>
corpus. The results indicate improvements in comparison to two other methods.<span
lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="18"><span lang=EN-GB>6-7pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
18</span></p>

<p class=AbstractTitle>Continuous Space Language Models for Statistical Machine
Translation</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Holger
Schwenk</span><!--[if supportFields]><span lang=FR style='mso-ansi-language:
FR'><span style='mso-element:field-begin'></span> XE &quot;Schwenk, H.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'>, Daniel Dchelotte</span><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span>
XE &quot;Dchelotte, D.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><span
style='mso-spacerun:yes'>&nbsp;</span>and Jean-Luc Gauvain</span><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span>
XE &quot;Gauvain, J-L.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=PosterAbstractText>Statistical machine translation systems are based
on one or more translation models and a language model of the target language.
While many different translation models and phrase extraction algorithms have
been proposed, a standard word n-gram back-off language model is used in most
systems.</p>

<p class=PosterAbstractText>In this work, we propose to use a new statistical language
model that is based on a continuous representation of the words in the
vocabulary. A neural network is used to perform the projection and the
probability estimation.<span style='mso-spacerun:yes'>&nbsp; </span>We consider
the translation of European Parliament Speeches.<span
style='mso-spacerun:yes'>&nbsp; </span>This task is part of an international
evaluation organized by the Tc-Star project in 2006. The proposed method
achieves consistent improvements in the BLEU score on the development and test
data.</p>

<p class=PosterAbstractText>We also present algorithms to improve the
estimation of the language model probabilities when splitting long sentences
into shorter chunks.<span lang=EN-GB style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
20</span></p>

<p class=AbstractTitle>Statistical phrase-based models for interactive
computer-assisted translation</p>

<p class=AbstractAuthor>Jes&uacute;s Tom&aacute;s<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tom&aacute;s, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Francisco Casacuberta<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Casacuberta, F.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Obtaining high-quality machine translations<span
style='mso-ansi-language:EN-GB'> </span>is still a long way off. A post-editing<span
style='mso-ansi-language:EN-GB'> </span>phase is required to improve the<span
style='mso-ansi-language:EN-GB'> </span>output of a machine translation system.<span
style='mso-ansi-language:EN-GB'> </span>An alternative is the so called
computer-assisted<span style='mso-ansi-language:EN-GB'> </span>translation. In
this framework, a<span style='mso-ansi-language:EN-GB'> </span>human translator
interacts with the system<span style='mso-ansi-language:EN-GB'> </span>in order
to obtain high-quality translations.<span style='mso-ansi-language:EN-GB'> </span>A
statistical phrase-based approach<span style='mso-ansi-language:EN-GB'> </span>to
computer-assisted translation is<span style='mso-ansi-language:EN-GB'> </span>described
in this article. A new decoder algorithm<span style='mso-ansi-language:EN-GB'> </span>for
interactive search is also presented,<span style='mso-ansi-language:EN-GB'> </span>that
combines monotone and non-monotone<span style='mso-ansi-language:EN-GB'> </span>search.
The system has been<span style='mso-ansi-language:EN-GB'> </span>assessed in
the TransType-2 project for<span style='mso-ansi-language:EN-GB'> </span>the
translation of several printer manuals,<span style='mso-ansi-language:EN-GB'> </span>from
(to) English to (from) Spanish, German<span style='mso-ansi-language:EN-GB'> </span>and
French.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
24</span></p>

<p class=AbstractTitle>Inducing Word Alignments with Bilexical Synchronous
Trees</p>

<p class=AbstractAuthor>Hao Zhang<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Zhang, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Daniel Gildea<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gildea, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper compares different bilexical tree-based
models for bilingual alignment. EM training for the new model benefits from the
dynamic programming &quot;hook trick&quot;. The model produces improved
dependency structure for both languages.<span lang=EN-GB style='mso-ansi-language:
EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
30</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Multilinguality<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>GF Parallel Resource Grammars and Russian</p>

<p class=AbstractAuthor>Janna Khegai<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Khegai, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>A
resource grammar is a standard library for the GF grammar formalism. It raises the
abstraction level of writing domain-specific grammars by taking care of the
general grammatical rules of a language. GF resource grammars have been built
in parallel for eleven languages and share a common interface, which simplifies
multilingual applications. We reflect on our experience with the Russian
resource grammar trying to answer the questions: how well Russian fits into the
common interface and where the line between language-independent and
language-specific should be drawn.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
28</span></p>

<p class=AbstractTitle>Multilingual Lexical Database Generation from parallel
texts in 20 European languages with endogenous resources</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Emmanuel
Giguet</span><!--[if supportFields]><span style='mso-element:field-begin'></span><span
lang=FR style='mso-ansi-language:FR'> XE &quot;Giguet, E.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><span style='mso-spacerun:yes'>&nbsp;</span>and
Pierre-Sylvain Luquet</span><!--[if supportFields]><span lang=FR
style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span> XE
&quot;Luquet, P-S.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=PosterAbstractText>This paper deals with multilingual database
generation from parallel corpora.<span style='mso-ansi-language:EN-GB'> </span>The
idea is to contribute to the enrichment of lexical databases for languages<span
style='mso-ansi-language:EN-GB'> </span>with few linguistic resources. Our
approach is endogenous: it relies on the raw<span style='mso-ansi-language:
EN-GB'> </span>texts only, it does not require external linguistic resources
such as stemmers<span style='mso-ansi-language:EN-GB'> </span>or taggers. The
system produces alignments for the 20 European languages of the <span
lang=EN-GB style='mso-ansi-language:EN-GB'>'A</span>cquis Communautaire'
Corpus.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
32</span></p>

<p class=AbstractTitle>Using comparable corpora to solve problems difficult for
human translators</p>

<p class=AbstractAuthor>Serge Sharoff<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sharoff, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Bogdan Babych<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Babych, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Anthony Hartley<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hartley, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>In this paper we present a tool that uses
comparable corpora to find<span style='mso-ansi-language:EN-GB'> </span>appropriate
translation equivalents for expressions that are<span style='mso-ansi-language:
EN-GB'> </span>considered by translators as difficult. For a phrase in the
source<span style='mso-ansi-language:EN-GB'> </span>language the tool
identifies a range of possible expressions used in<span style='mso-ansi-language:
EN-GB'> </span>similar contexts in target language corpora and presents them to
the<span style='mso-ansi-language:EN-GB'> </span>translator as a list of
suggestions. In the paper we discuss the<span style='mso-ansi-language:EN-GB'> </span>method
and present results of human evaluation of the performance of<span
style='mso-ansi-language:EN-GB'> </span>the tool, which highlight its
usefulness when dictionary solutions are lacking.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
36</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Multi-modality<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Discriminating image senses by clustering with
multimodal features</p>

<p class=AbstractAuthor>Nicolas Loeff<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Loeff, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Cecilia Ovesdotter Alm<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Alm, C.O.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and David Forsyth<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Forsyth, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We discuss Image Sense Discrimination (ISD), and
apply a method based on spectral clustering, using multimodal features from the
image and text of the embedding web page. We evaluate our method on a new data
set of annotated web images, retrieved with ambiguous query terms. Experiments
investigate different levels of sense granularity, as well as the impact of
text and image features, and global versus local text features.<span
lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
34</span></p>

<p class=AbstractTitle>Unsupervised Topic Identification by Integrating
Linguistic and Visual Information Based on Hidden Markov Models</p>

<p class=AbstractAuthor>Tomohide Shibata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shibata, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Sadao Kurohashi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kurohashi, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper presents an unsupervised topic
identification method integrating linguistic and visual information based on
Hidden Markov Models (HMMs). We employ HMMs for topic identification, wherein a
state corresponds to a topic and various features including linguistic, visual
and audio information are observed. Our experiments on two kinds of cooking TV
programs show the effectiveness of our proposed method.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
42</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Named Entity Detection<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Analysis and Repair of Name Tagger Errors</p>

<p class=AbstractAuthor>Heng Ji<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Ji, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Ralph Grishman<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Grishman, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Name tagging is a critical early stage in many
natural language processing pipe-lines. In this paper we analyze the types of
errors produced by a tagger, distinguishing name classification and various
types of name identification errors.<span style='mso-spacerun:yes'>&nbsp;
</span>We present a joint inference model to improve Chinese name tagging by
incorporating feedback from subsequent stages in an information extraction
pipeline: name structure parsing, cross-document co reference, semantic
relation extraction and event extraction. We show through examples and performance
measurement how different stages can correct different types of errors.<span
style='mso-spacerun:yes'>&nbsp; </span>The resulting accuracy approaches that
of individual human annotators.<span style='mso-spacerun:yes'>&nbsp; </span><span
lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
38</span></p>

<p class=AbstractTitle>An Effective Two-Stage Model for Exploiting Non-Local
Dependencies in Named Entity Recognition </p>

<p class=AbstractAuthor>Vijay Krishnan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Krishnan, V.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Christopher D. Manning<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Manning, C.D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper shows that a simple two-stage approach
to handle non-local dependencies in Named Entity Recognition (<st1:stockticker>NER</st1:stockticker>)
can outperform existing approaches that handle non-local dependencies, while
being much more computationally efficient.<span style='mso-spacerun:yes'>&nbsp;
</span><st1:stockticker>NER</st1:stockticker> systems typically use sequence
models for tractable inference, but this makes them unable to capture the long
distance structure present in text. We use a Conditional Random Field (CRF)
based <st1:stockticker>NER</st1:stockticker> system using local features to
make predictions and then train another CRF which uses both local information
and features extracted from the output of the first CRF.<span
style='mso-spacerun:yes'>&nbsp; </span>Using features capturing non-local
dependencies from the same document, our approach yields a 12.6% relative error
reduction on the F1 score, over state-of-threat <st1:stockticker>NER</st1:stockticker>
systems using local-information alone, when compared to the 9.3% relative error
reduction offered by the best systems that exploit non-local information. Our approach
also makes it easy to incorporate non-local information from other documents in
the test corpus, and this gives us a 13.3% error reduction over <st1:stockticker>NER</st1:stockticker>
systems using local-information alone. Additionally, our running time for
inference is just the inference time of two sequential CRFs, which is much less
than that of other more complicated approaches that directly model the
dependencies and do approximate inference.</p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="18"><span lang=EN-GB>6-7pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
44</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>NLP Applications<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>A Phrase-based Statistical Model for SMS Text
Normalization</p>

<p class=AbstractAuthor>AiTi Aw<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Aw, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Min Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Juan Xiao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Xiao, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jian Su<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Su, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Short Messaging Service (SMS) texts behave quite
differently from normal written texts and have some very special phenomena. To
translate SMS texts, traditional approaches model such irregularities directly
in Machine Translation (MT). However, such approaches suffer from customization
problem as tremendous effort is required to adapt the language model of the
existing translation system to handle SMS text style. We offer an alternative
approach to resolve such irregularities by normalizing SMS texts before MT. In
this paper, we view the task of SMS normalization as a translation problem from
the SMS language to the English language and we propose to adapt a phrase-based
statistical MT model for the task. Evaluation by 5-fold cross validation on a
parallel SMS normalized corpus of 5000 sentences shows that our method can
achieve 0.80702 in BLEU score against the baseline BLEU score 0.6958. Another experiment
of translating SMS texts from English to Chinese on a separate SMS text corpus
shows that, using SMS normalization as MT preprocessing can largely boost SMS
translation performance from 0.1926 to 0.3770 in BLEU score.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
40</span></p>

<p class=AbstractTitle><st1:stockticker>HAL</st1:stockticker>-based Cascaded
Model for Variable-Length Semantic Pattern Induction from Psychiatry Web
Resources</p>

<p class=AbstractAuthor>Liang-Chih Yu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yu, L-C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Chung-Hsien Wu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wu, C-H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Fong-Lin Jang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Jang, F-L.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Negative life events play an important role in triggering
depressive episodes.<span style='mso-ansi-language:EN-GB'> </span>Developing
psychiatric services that can automatically identify such events is<span
style='mso-ansi-language:EN-GB'> </span>beneficial for mental health care and
prevention. Before these services can be<span style='mso-ansi-language:EN-GB'> </span>provided,
some meaningful semantic pat-terns, such as &lt;lost, parents&gt;, have to<span
style='mso-ansi-language:EN-GB'> </span>be extracted. In this work, we present
a text mining framework capable of<span style='mso-ansi-language:EN-GB'> </span>inducing
variable-length semantic patterns from unannotated psychiatry web<span
style='mso-ansi-language:EN-GB'> </span>resources. This framework integrates a
cognitive motivated model, Hyperspace<span style='mso-ansi-language:EN-GB'> </span>Analog
to Language (<st1:stockticker>HAL</st1:stockticker>), to represent words as
well as combinations of words.<span style='mso-ansi-language:EN-GB'> </span>Then,
a cascaded induction process (CIP) boot-straps with a small set of seed<span
style='mso-ansi-language:EN-GB'> </span>patterns and incorporates relevance
feedback to iteratively induce more<span style='mso-ansi-language:EN-GB'> </span>relevant
patterns. The experimental results show that by combining the <st1:stockticker>HAL</st1:stockticker><span
style='mso-ansi-language:EN-GB'> </span>model and relevance feedback, the CIP
can induce semantic patterns from the<span style='mso-ansi-language:EN-GB'> </span>unannotated
web corpora so as to reduce the reliance on annotated corpora.</p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
46</span></p>

<p class=AbstractTitle>Reinforcing English Countability Prediction with One
Countability per Discourse Property</p>

<p class=AbstractAuthor>Ryo Nagata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nagata, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Atsuo Kawai<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kawai, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Koichiro Morihiro<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Morihiro, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Naoki Isu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Isu, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Countability of English nouns is important in
various natural language processing tasks. It especially plays an important
role in machine translation since it determines the range of possible
determiners. This paper proposes a method for reinforcing countability
prediction by introducing a novel concept called one countability per
discourse. It claims that when a noun appears more than once in a discourse,
they will all share the same countability in the discourse. The basic idea of
the proposed method is that mispredictions can be correctly overridden using
efficiently the one countability per discourse property. Experiments show that
the proposed method successfully reinforces countability prediction and
outperforms other methods used for comparison.</p>

<p class=MsoNormal><span lang=EN-GB style='mso-ansi-language:EN-GB'>6-7pm<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
48<o:p></o:p></span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>NLP Tools<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Using Machine Learning Techniques to Build a Comma
Checker for Basque</p>

<p class=AbstractAuthor>I&ntilde;aki Alegria<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Alegria, I.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Bertol Arrieta<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Arrieta, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Arantza Diaz de Ilarraza<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;de Ilarraza, A.D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Eli Izagirre<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Izagirre, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Montse Maritxalar<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Maritxalar, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>In this paper, we describe the research using
machine learning techniques to build a comma checker to be integrated in a
grammar checker for Basque. After several experiments, and trained with a
little corpus of 100,000 words, the system guesses correctly not placing commas
with a precision of 96% and a recall of 98%. It also gets a precision of 70%
and a recall of 49% in the task of placing commas. Finally, we have shown that
these results can be improved using a bigger and a more homogeneous corpus to
train, that is, a bigger corpus written by one unique author.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
54</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Parsing<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Evaluating the Accuracy of an Unlexicalized Statistical
Parser on the PARC DepBank</p>

<p class=AbstractAuthor>Ted Briscoe<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Briscoe, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and John Carroll<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Carroll, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We evaluate the accuracy of an unlexicalized
statistical parser, trained on 4K treebanked sentences from balanced data and
tested on the PARC DepBank. We demonstrate that a parser which is competitive
in accuracy (without sacrificing processing speed) can be quickly tuned without
reliance on large in-domain manually-constructed treebanks. This makes it more
practical to use statistical parsers in applications that need access to
aspects of predicate-argument structure. The comparison of systems using
DepBank is not straightforward, so we extend and validate DepBank and highlight
a number of representation and scoring issues for relational evaluation
schemes.<span lang=EN-GB style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
50</span></p>

<p class=AbstractTitle>Speeding up full syntactic parsing by leveraging partial
parsing decisions</p>

<p class=AbstractAuthor>Elliot Glaysher<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Glaysher, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dan Moldovan<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Moldovan, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Parsing is a computationally intensive task due to
the combinatorial explosion seen in chart parsing algorithms that explore
possible parse trees. In this paper, we propose a method to limit the
combinatorial explosion by restricting the CYK chart parsing algorithm based on
the output of a chunk parser. When tested on the three parsers presented in
(Collins, 1999), we observed an approximate three--fold speedup with only an
average decrease of 0.17% in both precision and recall.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
52</span></p>

<p class=AbstractTitle>Exploring the Potential of Intractable Parsers</p>

<p class=AbstractAuthor>Mark Hopkins<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hopkins, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jonas Kuhn<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kuhn, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
revisit the idea of history-based parsing and present a history-based parsing
framework that strives to be simple, general, and flexible. We also provide a
decoder for this probability model that is linear-space, optimal, and anytime.
A parser based on this framework, when evaluated on Section 23 of the Penn
Treebank, compares favorably with other state-of-the-art approaches, in terms
of both accuracy and speed.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
58</span></p>

<p class=AbstractTitle>Parsing and Subcategorization Data</p>

<p class=AbstractAuthor>Jianguo Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Li, J.(2)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Chris Brew<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Brew, C.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>In this paper, we compare the performance of a
state-of-the-art statistical parser (Bikel, 2004) in parsing written and spoken
language and in generating subcategorization cues from written and spoken
language. Although Bikel's parser achieves a higher accuracy for parsing
written language, it achieves a higher accuracy when extracting
subcategorization cues from spoken language. Our experiments also show that
current technology for extracting subcategorization frames initially designed
for written texts works equally well for spoken language. Additionally, we
explore the utility of punctuation in helping parsing and extraction of
subcategorization cues. Our experiments show that punctuation is of little help
in parsing spoken language and extracting subcategorization cues from spoken
language. This indicates that there is no need to add punctuation in
transcribing spoken corpora simply in order to help parsers.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
62</span></p>

<p class=AbstractTitle>Discriminative Classifiers for Deterministic Dependency
Parsing</p>

<p class=AbstractAuthor>Johan Hall<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hall, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Joakim Nivre<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nivre, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jens Nilsson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nilsson, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Deterministic parsing guided by treebank-induced
classifiers has emerged as a<span style='mso-ansi-language:EN-GB'> </span>simple
and efficient alternative to more complex models for data-driven<span
style='mso-ansi-language:EN-GB'> </span>parsing. We present a systematic
comparison of memory-based learning (MBL) and<span style='mso-ansi-language:
EN-GB'> </span>support vector machines (<st1:stockticker>SVM</st1:stockticker>)
for inducing classifiers for deterministic<span style='mso-ansi-language:EN-GB'>
</span>dependency parsing, using data from Chinese, English and Swedish,
together with<span style='mso-ansi-language:EN-GB'> </span>a variety of
different feature models. The comparison shows that <st1:stockticker>SVM</st1:stockticker>
gives<span style='mso-ansi-language:EN-GB'> </span>higher accuracy for richly
articulated feature models across all languages,<span style='mso-ansi-language:
EN-GB'> </span>albeit with considerably longer training times. The results also
confirm that<span style='mso-ansi-language:EN-GB'> </span>classifier-based
deterministic parsing can achieve parsing accuracy very close<span
style='mso-ansi-language:EN-GB'> </span>to the best results reported for more
complex parsing models.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
64</span></p>

<p class=AbstractTitle>The effect of corpus size in combining supervised and
unsupervised training for disambiguation</p>

<p class=AbstractAuthor>Michaela Atterer<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Atterer, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hinrich Sch&uuml;tze<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sch&uuml;tze, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We investigate the effect of corpus size in
combining supervised and unsupervised learning for two types of attachment decisions:
relative clause attachment and prepositional phrase attachment.<span
style='mso-spacerun:yes'>&nbsp; </span>The supervised component is Collins'
parser, trained on the Wall Street Journal. The unsupervised component gathers
lexical statistics from an unannotated corpus of newswire text. We find that
the combined system only improves the performance of the parser for small
training sets. Surprisingly, the size of the unannotated corpus has little
effect due to the noisiness of the lexical statistics acquired by unsupervised
learning.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
70</span></p>

<p class=AbstractTitle>A Pipeline Framework for Dependency Parsing</p>

<p class=AbstractAuthor>Ming-Wei Chang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chang, M-W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Quang Do<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Do, Q.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dan Roth<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Roth, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Pipeline computation, in which a task is decomposed
into several stages that are solved sequentially, is a common computational
strategy in natural language processing. The key problem of this model is that
it results in error accumulation and suffers from its inability to correct
mistakes in previous stages. We develop a framework for decisions made via in
pipeline models, which addresses these difficulties, and presents and evaluates
it in the context of bottom up dependency parsing for English. We show
improvements in the accuracy of the inferred trees relative to existing models.
Interestingly, the proposed algorithm shines especially when evaluated
globally, at a sentence level, where our results are significantly better than
those of existing approaches.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
56</span></p>

<p class=AbstractTitle>Graph Branch Algorithm: An Optimum Tree Search Method
for Scored Dependency Graph with Arc Co-occurrence Constraints</p>

<p class=AbstractAuthor>Hideki Hirakawa<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hirakawa, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Various kinds of scored dependency graphs are
proposed as packed shared data structures in combination with optimum
dependency tree search algorithms. This paper classifies the scored dependency
graphs and discusses the specific features of the ¡§<st1:place><st1:PlaceName>Dependency</st1:PlaceName>
 <st1:PlaceType>Forest</st1:PlaceType></st1:place>¡¨ (DF) which is the packed
shared data structure adopted in the ¡§Preference Dependency Grammar¡¨ (<st1:stockticker>PDG</st1:stockticker>),
and proposes the ¡§Graph Branch Algorithm¡¨ for computing the optimum dependency
tree from a DF. This paper also reports the experiment showing the
computational amount and behavior of the graph branch algorithm.</p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="18"><span lang=EN-GB>6-7pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
60</span></p>

<p class=AbstractTitle>Mildly Non-Projective Dependency Structures</p>

<p class=AbstractAuthor>Marco Kuhlmann<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kuhlmann, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Joakim Nivre<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nivre, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Syntactic parsing requires a fine balance between
expressivity and complexity,<span style='mso-ansi-language:EN-GB'> </span>so
that naturally occurring structures can be accurately parsed without<span
style='mso-ansi-language:EN-GB'> </span>compromising efficiency. In
dependency-based parsing, several constraints have<span style='mso-ansi-language:
EN-GB'> </span>been proposed that restrict the class of permissible structures,
such as projectivity, planarity, multi-planarity, well-nestedness, gap degree,<span
style='mso-ansi-language:EN-GB'> </span>and edge degree. While projectivity is
generally taken to be too restrictive<span style='mso-ansi-language:EN-GB'> </span>for
natural language syntax, it is not clear which of the other proposals strikes
the best balance between expressivity and complexity. In this paper, we<span
style='mso-ansi-language:EN-GB'> </span>review and compare the different
constraints theoretically, and provide an<span style='mso-ansi-language:EN-GB'>
</span>experimental evaluation using data from two treebanks, investigating how
large<span style='mso-ansi-language:EN-GB'> </span>a proportion of the
structures found in the treebanks are permitted under<span style='mso-ansi-language:
EN-GB'> </span>different constraints. The results indicate that a combination
of the<span style='mso-ansi-language:EN-GB'> </span>well-nestedness constraint
and a parametric constraint on discontinuity gives a<span style='mso-ansi-language:
EN-GB'> </span>very good fit with the linguistic data.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
66</span></p>

<p class=AbstractTitle>The Benefit of Stochastic PP Attachment to a Rule-Based
Parser</p>

<p class=AbstractAuthor>Kilian A. Foth<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Foth, K.A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Wolfgang Menzel<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Menzel, W.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>To study PP attachment disambiguation as a
benchmark for empirical methods in<span style='mso-ansi-language:EN-GB'> </span>natural
language processing it has often been reduced to a binary decision<span
style='mso-ansi-language:EN-GB'> </span>problem (between verb or noun
attachment) in a particular syntactic<span style='mso-ansi-language:EN-GB'> </span>configuration.
A parser, however, must solve the more general task of deciding<span
style='mso-ansi-language:EN-GB'> </span>between more than two alternatives in
many different contexts. We combine the<span style='mso-ansi-language:EN-GB'> </span>attachment
predictions made by a simple model of lexical attraction with a<span
style='mso-ansi-language:EN-GB'> </span>full-fledged parser of German to
determine the actual benefit of the subtask to<span style='mso-ansi-language:
EN-GB'> </span>parsing. We show that the combination of data-driven and
rule-based components<span style='mso-ansi-language:EN-GB'> </span>can reduce
the number of all parsing errors by 14% and raise the attachment<span
style='mso-ansi-language:EN-GB'> </span>accuracy for dependency parsing of
German to an unprecedented 92%.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
68</span></p>

<p class=AbstractTitle>A Best-First Probabilistic Shift-Reduce Parser</p>

<p class=AbstractAuthor>Kenji Sagae<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sagae, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and <span style='mso-bidi-font-weight:
bold'>Alon Lavie</span><!--[if supportFields]><span style='mso-bidi-font-weight:
bold'><span style='mso-element:field-begin'></span></span> XE &quot;<span
style='mso-bidi-font-weight:bold'>Lavie, A.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-bidi-font-weight:bold'><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=PosterAbstractText>Recently proposed deterministic classifier- based
parsers (Nivre and Scholz, 2004; Sagae and Lavie, 2005; Yamada and Matsumoto,
2003) offer attractive alternatives to generative statistical parsers.
Deterministic parsers are fast, efficient, and simple to implement, but
generally less accurate than optimal (or nearly optimal) statistical parsers.
We present a statistical shift-reduce parser that bridges the gap between
deterministic and probabilistic parsers. The parsing model is essentially the
same as one previously used for deterministic parsing, but the parser performs
a best-first search instead of a greedy search. Using the standard sections of
the WSJ corpus of the Penn Treebank for training and testing, our parser has
88.1% precision and 87.8% recall (using automatically assigned part-of-speech
tags). Perhaps more interestingly, the parsing model is significantly different
from the generative models used by other well-known accurate parsers, allowing
for a simple combination that produces precision and recall of 90.9% and 90.7%,
respectively.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
72</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Part-of-Speech Tagging<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Using Lexical Dependency and Ontological Knowledge to
Improve a Detailed Syntactic and Semantic Tagger of English</p>

<p class=AbstractAuthor>Andrew Finch<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Finch, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ezra Black<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Black, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Young-Sook Hwang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hwang, Y-S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Eiichiro Sumita<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sumita, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper presents a detailed study of the
integration of knowledge from both<span style='mso-ansi-language:EN-GB'> </span>dependency
parses and hierarchical word ontologies into a maximum-entropy-based<span
style='mso-ansi-language:EN-GB'> </span>tagging model that simultaneously
labels words with both syntax and semantics.<span style='mso-ansi-language:
EN-GB'> </span>Our findings show that information from both these sources can
lead to strong<span style='mso-ansi-language:EN-GB'> </span>improvements in
overall system accuracy: dependency knowledge improved<span style='mso-ansi-language:
EN-GB'> </span>performance over all classes of word, and knowledge of the
position of a word<span style='mso-ansi-language:EN-GB'> </span>in<span
style='mso-ansi-language:EN-GB'> </span>an ontological hierarchy increased
accuracy for words not seen in the training<span style='mso-ansi-language:EN-GB'>
</span>data. The resulting tagger offers the highest reported tagging accuracy
on this<span style='mso-ansi-language:EN-GB'> </span>tagset to date.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
74</span></p>

<p class=AbstractTitle>Morphological Richness Offsets Resource Demand-
Experiences in Constructing a <st1:stockticker>POS</st1:stockticker> Tagger for
Hindi</p>

<p class=AbstractAuthor>Smriti Singh<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Singh, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Kuhoo Gupta<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gupta, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Manish Shrivastava<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Shrivastava, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Pushpak Bhattacharyya<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bhattacharyya, P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>In this paper we report our work on building a <st1:stockticker>POS</st1:stockticker>
tagger for a morphologically rich language- Hindi. The theme of the research is
to vindicate the stand that- if morphology is strong and harnessable, then lack
of training corpora is not debilitating. We establish a methodology of <st1:stockticker>POS</st1:stockticker>
tagging which the resource disadvantaged (lacking annotated corpora) languages
can make use of. The methodology makes use of locally annotated modestly-sized
corpora (15,562 words), exhaustive morpohological analysis backed by
high-coverage lexicon and a decision tree based learning algorithm (CN2). The
evaluation of the system was done with 4-fold cross validation of the corpora
in the news domain (www.bbc.co.uk/hindi). The current accuracy of <st1:stockticker>POS</st1:stockticker>
tagging is 93.45% and can be further improved.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="18"><span lang=EN-GB>6-7pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
78</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Phonetics<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Unsupervised Analysis for Decipherment Problems</p>

<p class=AbstractAuthor>Kevin Knight<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Knight, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Anish Nair<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nair, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Nishit Rathod<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Rathod, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kenji Yamada<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yamada, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We study a number of natural language decipherment
problems using unsupervised<span style='mso-ansi-language:EN-GB'> </span>learning.
These include letter substitution ciphers, character code conversion, phonetic
decipherment, and word-based ciphers with relevance to<span style='mso-ansi-language:
EN-GB'> </span>machine translation.<span style='mso-spacerun:yes'>&nbsp;
</span>Straightforward unsupervised learning techniques most<span
style='mso-ansi-language:EN-GB'> </span>often fail on the first try, so we
describe techniques for understanding errors<span style='mso-ansi-language:
EN-GB'> </span>and significantly increasing performance.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
80</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Phonology<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Analysis and Synthesis of the Distribution of Consonants
over Languages: A Complex Network Approach</p>

<p class=AbstractAuthor>Monojit Choudhury<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Choudhury, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Animesh Mukherjee<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mukherjee, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Anupam Basu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Basu, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Niloy Ganguly<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ganguly, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Cross-linguistic similarities are reflected by the
speech sound systems of<span style='mso-ansi-language:EN-GB'> </span>languages
all over the world. In this work we try to model such similarities<span
style='mso-ansi-language:EN-GB'> </span>observed in the consonant inventories,
through a complex bipartite network. We<span style='mso-ansi-language:EN-GB'> </span>present
a systematic study of some of the appealing features of these<span
style='mso-ansi-language:EN-GB'> </span>inventories with the help of the
bipartite network. An important observation<span style='mso-ansi-language:EN-GB'>
</span>is that the occurrence of consonants follows a two regime power law<span
style='mso-ansi-language:EN-GB'> </span>distribution. We find that the
consonant inventory size distribution together<span style='mso-ansi-language:
EN-GB'> </span>with the principle of preferential attachment are the main
reasons behind the<span style='mso-ansi-language:EN-GB'> </span>emergence of
such a two regime behavior. In order to further support our<span
style='mso-ansi-language:EN-GB'> </span>explanation we present a synthesis
model for this network based on the general<span style='mso-ansi-language:EN-GB'>
</span>theory of preferential attachment.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
76</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Question Answering<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>The Role of Information Retrieval in Answering Complex
Questions</p>

<p class=AbstractAuthor>Jimmy Lin<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Lin, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper explores the role of information<span
style='mso-ansi-language:EN-GB'> </span>retrieval in answering ¡§relationship¡¨<span
style='mso-ansi-language:EN-GB'> </span>questions, a new class complex
information<span style='mso-ansi-language:EN-GB'> </span>needs formally
introduced in TREC 2005. Since information retrieval is often<span
style='mso-ansi-language:EN-GB'> </span>an integral component of many question<span
style='mso-ansi-language:EN-GB'> </span>answering strategies, it is important<span
style='mso-ansi-language:EN-GB'> </span>to understand the impact of different
term-based<span style='mso-ansi-language:EN-GB'> </span>techniques. Within a
framework of<span style='mso-ansi-language:EN-GB'> </span>sentence retrieval,
we examine three factors<span style='mso-ansi-language:EN-GB'> </span>that
contribute to question answering<span style='mso-ansi-language:EN-GB'> </span>performance:
the use of different retrieval<span style='mso-ansi-language:EN-GB'> </span>engines,
relevance (both at the document<span style='mso-ansi-language:EN-GB'> </span>and
sentence level), and redundancy.<span style='mso-ansi-language:EN-GB'> </span>Results
point out the limitations<span style='mso-ansi-language:EN-GB'> </span>of
purely term-based methods to this challenging<span style='mso-ansi-language:
EN-GB'> </span>task. Nevertheless, IR-based techniques<span style='mso-ansi-language:
EN-GB'> </span>provide a strong baseline on top<span style='mso-ansi-language:
EN-GB'> </span>of which more sophisticated language processing<span
style='mso-ansi-language:EN-GB'> </span>techniques can be deployed.<span
lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
84</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Semantic Role Labeling<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>A Hybrid Convolution Tree Kernel for Semantic Role
Labeling</p>

<p class=AbstractAuthor>Wanxiang Che<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Che, W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Min Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Ting Liu<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Liu, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Sheng Li<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Li, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>A hybrid convolution tree kernel is proposed in
this paper to effectively model syntactic structures for semantic role labeling
(SRL). The hybrid kernel consists of two individual convolution kernels: a Path
kernel, which captures predicate-argument link features, and a Constituent
Structure kernel, which captures the syntactic structure features of arguments.
Evaluation on the datasets of CoNLL-2005 SRL shared task shows that the novel
hybrid convolution tree kernel outperforms the previous tree kernels. We also
combine our new hybrid tree kernel based method with the standard rich flat
feature based method. The experimental results show that the combinational
method can get better performance than each of them individually.<span
lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
82</span></p>

<p class=AbstractTitle>A Comparison of Alternative Parse Tree Paths for
Labeling Semantic Roles</p>

<p class=AbstractAuthor>Reid Swanson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Swanson, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Andrew S. Gordon<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gordon, A.S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>The
integration of sophisticated inference-based techniques into natural language
processing applications first requires a reliable method of encoding the
predicate-argument structure of the propositional content of text. Recent
statistical approaches to automated predicate-argument annotation have utilized
parse tree paths as predictive features, which encode the path between a verb
predicate and a node in the parse tree that governs its argument. In this
paper, we explore a number of alternatives for how these parse tree paths are
encoded, focusing on the difference between automatically generated
constituency parses and dependency parses. After describing five alternatives
for encoding parse tree paths, we investigate how well each can be aligned with
the argument substrings in annotated text corpora, their relative precision and
recall performance, and their comparative learning curves. Results indicate
that constituency parsers produce parse tree paths that can more easily be
aligned to argument substrings, perform better in precision and recall, and
have more favorable learning curves than those produced by a dependency parser.<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
86</span></p>

<p class=AbstractTitle>A FrameNet-based Semantic Role Labeler for Swedish</p>

<p class=AbstractAuthor>Richard Johansson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Johansson, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Pierre Nugues<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nugues. P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We present a FrameNet-based semantic<span
style='mso-ansi-language:EN-GB'> </span>role labeling system for Swedish text.
As<span style='mso-ansi-language:EN-GB'> </span>training data for the system,
we used an<span style='mso-ansi-language:EN-GB'> </span>annotated corpus that
we produced by<span style='mso-ansi-language:EN-GB'> </span>transferring
FrameNet annotation from the<span style='mso-ansi-language:EN-GB'> </span>English
side to the Swedish side in a parallel<span style='mso-ansi-language:EN-GB'> </span>corpus.
In addition, we describe two<span style='mso-ansi-language:EN-GB'> </span>frame
element bracketing algorithms that<span style='mso-ansi-language:EN-GB'> </span>are
suitable when no robust constituent<span style='mso-ansi-language:EN-GB'> </span>parsers
are available</p>

<p class=PosterAbstractText>We evaluated the system on a part of the<span
style='mso-ansi-language:EN-GB'> </span>FrameNet example corpus that we
translated<span style='mso-ansi-language:EN-GB'> </span>manually, and obtained
an accuracy<span style='mso-ansi-language:EN-GB'> </span>score of 0.75 on the
classification of presegmented<span style='mso-ansi-language:EN-GB'> </span>frame
elements, and precision<span style='mso-ansi-language:EN-GB'> </span>and recall
scores of 0.67 and 0.47 for the<span style='mso-ansi-language:EN-GB'> </span>complete
task.</p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
90</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Semantics<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Using WordNet to Automatically Deduce Relations between
Words in Noun-Noun Compounds</p>

<p class=AbstractAuthor>Fintan J. Costello<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Costello, F.J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Tony Veale<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Veale, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Simon Dunne<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Dunne, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We present an algorithm for automatically
disambiguating noun-noun compounds by deducing the correct semantic relation
between their constituent words. This algorithm uses a corpus of 2500 compounds
annotated with WordNet senses and covering 139 different semantic relations (we
make this corpus available online for researchers interested in the semantics
of noun-noun compounds). The algorithm takes as input the WordNet senses for
the nouns in a compound, finds all parent senses (hypernyms) of those senses,
and searches the corpus for other compounds containing any pair of those
senses.<span style='mso-spacerun:yes'>&nbsp;&nbsp; </span>The relation with the
highest proportional co-occurrence with any sense pair is returned as the
correct relation for the compound. This algorithm was tested using a
'leave-one-out' procedure on the corpus of compounds. The algorithm identified
the correct relations for compounds with high precision: in 92% of cases where
a relation was found with a proportional co-occurrence of 1.0, it was the
correct relation for the compound being disambiguated.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
88</span></p>

<p class=AbstractTitle>Spontaneous Speech Understanding for Robust Multi-Modal
Human-Robot Communication</p>

<p class=AbstractAuthor>Sonja H&uuml;wel<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;H&uuml;wel, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Britta Wrede<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Wrede, B.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper presents a speech understanding<span
style='mso-ansi-language:EN-GB'> </span>component for enabling robust situated<span
style='mso-ansi-language:EN-GB'> </span>human-robot communication. The aim is<span
style='mso-ansi-language:EN-GB'> </span>to gain semantic interpretations of
utterances<span style='mso-ansi-language:EN-GB'> </span>that serve as a basis
for multi-modal<span style='mso-ansi-language:EN-GB'> </span>dialog management
also in cases where<span style='mso-ansi-language:EN-GB'> </span>the recognized
word-stream is not grammatically<span style='mso-ansi-language:EN-GB'> </span>correct.
For the understanding<span style='mso-ansi-language:EN-GB'> </span>process, we
designed semantic processable<span style='mso-ansi-language:EN-GB'> </span>units,
which are adapted to the<span style='mso-ansi-language:EN-GB'> </span>domain of
situated communication. Our<span style='mso-ansi-language:EN-GB'> </span>framework
supports the specific<span style='mso-ansi-language:EN-GB'> </span>characteristics<span
style='mso-ansi-language:EN-GB'> </span>of spontaneous speech used in
combination<span style='mso-ansi-language:EN-GB'> </span>with gestures in a
real world scenario.<span style='mso-ansi-language:EN-GB'> </span>It also
provides information about<span style='mso-ansi-language:EN-GB'> </span>the
dialog acts. Finally, we present a processing<span style='mso-ansi-language:
EN-GB'> </span>mechanism using these concept<span style='mso-ansi-language:
EN-GB'> </span>structures to generate the most likely semantic<span
style='mso-ansi-language:EN-GB'> </span>interpretation of the utterances and<span
style='mso-ansi-language:EN-GB'> </span>to evaluate the interpretation with
respect<span style='mso-ansi-language:EN-GB'> </span>to semantic coherence.</p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
94</span></p>

<p class=AbstractTitle>Translating HPSG-style Outputs of a Robust Parser into
Typed Dynamic Logic</p>

<p class=AbstractAuthor>Manabu Sato<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sato, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Daisuke Bekki<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Bekki, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yusuke Miyao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Miyao, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jun'ichi Tsujii<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsujii, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>The present paper proposes a method by which to
translate outputs of a robust HPSG parser into semantic representations of
Typed Dynamic Logic (TDL), a dynamic plural semantics defined in typed lambda
calculus. With its higher-order representations of contexts, TDL analyzes and
describes the inherently inter-sentential nature of quantification and anaphora
in a strictly lexicalized and compositional manner. The present study shows
that the proposed translation method successfully combines robustness and
descriptive adequacy of contemporary semantics. The present implementation
achieves high coverage, approximately 90%, for the real text of the Penn
Treebank corpus.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
92</span></p>

<p class=AbstractTitle>Discriminative Reranking for Semantic Parsing</p>

<p class=AbstractAuthor>Ruifang Ge<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ge, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Raymond J. Mooney<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mooney, R.J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Semantic
parsing is the task of mapping natural language sentences to complete formal
meaning representations. The performance of semantic parsing can be potentially
improved by using discriminative reranking, which explores arbitrary global
features. In this paper, we investigate discriminative reranking upon a
baseline semantic parser, Scissor, where the composition of meaning
representations is guided by syntax. We examine if features used for syntactic
parsing can be adapted for semantic parsing by creating similar semantic
features based on the mapping between syntax and semantics. We report
experimental results on two real applications, an interpreter for coaching
instructions in robotic soccer and a natural-language database interface. The
results show that reranking can improve the performance on the coaching
interpreter, but not on the database interface.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
96</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Sentiment Analysis<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Whose thumb is it anyway? Classifying author personality
from weblog text</p>

<p class=AbstractAuthor>Jon Oberlander<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Oberlander, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Scott Nowson<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nowson, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
report initial results on the relatively novel task of automatic classification
of author personality. Using a corpus of personal weblogs, or
&quot;blogs&quot;, we investigate the accuracy that can be achieved when
classifying authors on four important personality traits. We explore both
binary and multiple classification, using differing sets of n-gram features.
Results are promising for all four traits examined.<span style='mso-tab-count:
1'>&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
98</span></p>

<p class=AbstractTitle>Automatic Construction of Polarity-tagged Corpus from
HTML Documents</p>

<p class=AbstractAuthor>Nobuhiro Kaji<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kaji, N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Masaru Kitsuregawa<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kitsuregawa, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper proposes a novel method<span
style='mso-ansi-language:EN-GB'> </span>of building polarity-tagged corpus from<span
style='mso-ansi-language:EN-GB'> </span>HTML documents. The characteristics of<span
style='mso-ansi-language:EN-GB'> </span>this method is that it is fully
automatic and<span style='mso-ansi-language:EN-GB'> </span>can be applied to
arbitrary HTML documents.<span style='mso-ansi-language:EN-GB'> </span>The idea
behind our method is<span style='mso-ansi-language:EN-GB'> </span>to utilize
certain layout structures and linguistic<span style='mso-ansi-language:EN-GB'> </span>pattern.
By using them, we can<span style='mso-ansi-language:EN-GB'> </span>automatically
extract such sentences that<span style='mso-ansi-language:EN-GB'> </span>express
opinion. In our experiment, the<span style='mso-ansi-language:EN-GB'> </span>method
could construct a corpus consisting<span style='mso-ansi-language:EN-GB'> </span>of
126,610 sentences.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
102</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Speech<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Integration of Speech to Computer-Assisted Translation
Using Finite-State Automata</p>

<p class=AbstractAuthor>Shahram Khadivi<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Khadivi, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Richard Zens<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zens, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Hermann Ney<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ney, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>State-of-the-art computer-assisted translation
engines are based on a statistical prediction engine, which interactively
provides completions to what a human translator types. The integration of human
speech into a computer-assisted system is also a challenging area and is the
aim of this paper. So far, only a few methods for integrating statistical
machine translation (MT) models with automatic speech recognition (<st1:stockticker>ASR</st1:stockticker>)
models have been studied. They were mainly based on Nbest rescoring approach.
N-best rescoring is not an appropriate search method for building a real-time
prediction engine. In this paper, we study the incorporation of MT models and <st1:stockticker>ASR</st1:stockticker>
models using finite-state automata. We also propose some transducers based on
MT models for rescoring the <st1:stockticker>ASR</st1:stockticker> word graphs.<span
lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="18"><span lang=EN-GB>6-7pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
104</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Summarization<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Constraint-based Sentence Compression: An Integer
Programming Approach</p>

<p class=AbstractAuthor>James Clarke<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Clarke, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mirella Lapata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lapata, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>The
ability to compress sentences while preserving their grammaticality and most of
their meaning has recently received much attention. Our work views sentence
compression as an optimisation problem. We develop an integer programming
formulation and infer globally optimal compressions in the face of
linguistically motivated constraints. We show that such a formulation allows
for relatively simple and knowledge-lean compression models that do not require
parallel corpora or large-scale resources. The proposed approach yields results
comparable and in some cases superior to state-of-the-art.<o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
100</span></p>

<p class=AbstractTitle>An Automatic Method for Summary Evaluation Using
Multiple Evaluation Results by a Manual Method </p>

<p class=AbstractAuthor>Hidetsugu Nanba<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Nanba, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Manabu Okumura<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Okumura, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>To solve a problem of how to evaluate
computer-produced summaries, a number of automatic and manual methods have been
proposed. Manual methods evaluate summaries correctly, because humans evaluate
them, but are costly. On the other hand, automatic methods, which use
evaluation tools or programs, are low cost, although these methods cannot
evaluate summaries as accurately as manual methods. In this paper, we
investigate an automatic evaluation method that can reduce the errors of
traditional automatic methods by using several evaluation results obtained
manually. We conducted some experiments using the data of the Text
Summarization Challenge 2 (<st1:stockticker>TSC</st1:stockticker>-2). A
comparison with conventional automatic methods shows that our method
outperforms other methods usually used.<span lang=EN-GB style='mso-ansi-language:
EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
106</span></p>

<p class=AbstractTitle>Topic-Focused Multi-document Summarization Using an
Approximate Oracle Score</p>

<p class=AbstractAuthor>John M. Conroy<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Conroy, J.M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Judith D. Schlesinger<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Schlesinger, J.D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Dianne P. O'Leary<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;O'Leary, D.P.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>We consider the problem of producing a
multi-document summary given a collection of documents. Since most successful
methods of multi-document summarization are still largely extractive, in this
paper, we explore just how well an extractive method can perform. We introduce
an ¡§oracle¡¨ score, based on the probability distribution of unigrams in human
summaries. We then demonstrate that with the oracle score, we can generate
extracts which score, on average, better than the human summaries, when
evaluated with ROUGE. In addition, we introduce an approximation to the oracle
score which produces a system with the best known performance for the 2005
Document Understanding Conference (DUC) evaluation.<span lang=EN-GB
style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
108</span></p>

<p class=AbstractTitle>Trimming CFG Parse Trees for Sentence Compression Using
Machine Learning Approaches</p>

<p class=AbstractAuthor>Yuya Unno<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Unno, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Takashi Ninomiya<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ninomiya, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Yusuke Miyao<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Miyao, Y.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Jun'ichi Tsujii<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tsujii, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Sentence compression is a task of creating<span
style='mso-ansi-language:EN-GB'> </span>a short grammatical sentence by
removing extraneous words or phrases<span style='mso-ansi-language:EN-GB'> </span>from
an original sentence<span style='mso-ansi-language:EN-GB'> </span>while
preserving its meaning. Existing methods learn statistics on trimming
context-free grammar (CFG) rules.<span style='mso-ansi-language:EN-GB'> </span>However,
these methods sometimes eliminate the original meaning by<span
style='mso-ansi-language:EN-GB'> </span>incorrectly removing important parts of
sentences,<span style='mso-ansi-language:EN-GB'> </span>because trimming
probabilities only depend on parents' and daughters' non-terminals in applied
CFG rules.<span style='mso-ansi-language:EN-GB'> </span>We apply a maximum
entropy model to the above method.<span style='mso-ansi-language:EN-GB'> </span>Our
method can easily include various features,<span style='mso-ansi-language:EN-GB'>
</span>for example, other parts of a parse tree or words the sentences contain.<span
style='mso-ansi-language:EN-GB'> </span>We evaluated the method using manually
compressed sentences and human judgments.<span style='mso-ansi-language:EN-GB'>
</span>We found that our method produced more grammatical and<span
style='mso-ansi-language:EN-GB'> </span>informative compressed sentences than
other methods.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'> </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
114</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Syntax<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Using Machine-Learning to Assign Function Labels to
Parser Output for Spanish</p>

<p class=AbstractAuthor>Grzegorz Chrupa&#322;a<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Chrupa&#322;a, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Josef van Genabith<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;van Genabith, J.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>Data-driven grammatical function tag assignment has
been studied for English using the Penn-II Treebank data. In this paper we
address the question of whether such methods can be applied successfully to
other languages and treebank resources. In addition to tag assignment accuracy
and f-scores we also present results of a task-based evaluation. We use three
machine-learning methods to assign Cast3LB function tags to sentences parsed
with Bikel¡¦s parser trained on the Cast3LB treebank. The best performing
method, <st1:stockticker>SVM</st1:stockticker>, achieves an f-score of 86.87%
on gold-standard trees and 66.67% on parser output - a statistically
significant improvement of 6.74% over the baseline. In a task-based evaluation
we generate <st1:stockticker>LFG</st1:stockticker> functional-structures from
the function- tag- enriched trees. On this task we achieve an f-score of
75.67%, a statistically significant 3.4% improvement over the baseline.</p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
110</span></p>

<p class=AbstractTitle>Local constraints on sentence markers and focus in
Somali</p>

<p class=AbstractAuthor>Kat Hargreaves<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Hargreaves, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Allan Ramsay<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ramsay, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
present a computationally tractable account of the interactions between
sentence markers and focus marking in Somali. Somali, as a Cushitic language,
has a basic pattern wherein a small `core' clause is preceded, and in some
cases followed by, a set of `topics', which provide scene-seting information
against which the core is interpreted. Some topics appear to carry a `focus
marker', indicating that they are particularly salient. We will outline a
computationally tractable grammar for Somali in which focus marking emerges
naturally from a consideration of the use of a range of sentence markers.<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
116</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Text Classification<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Obfuscating Document Stylometry to Preserve Author
Anonymity</p>

<p class=AbstractAuthor>Gary Kacmarcik<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kacmarcik, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Michael Gamon<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Gamon, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper explores techniques for reducing the
effectiveness of standard authorship attribution techniques so that an author A
can preserve anonymity for a particular document D. We discuss feature
selection and adjustment and show how this information can be fed back to the
author to create a new document D¡¦ for which the calculated attribution moves
away from A. Since it can be labor intensive to adjust the document in this
fashion, we attempt to quantify the amount of effort required to produce the anonymized
document and introduce two levels of anonymization: shallow and deep. In our
test set, we show that shallow anonymization can be achieved by making 14
changes per 1000 words to reduce the likelihood of identifying A as the author
by an average of more than 83%. For deep anonymization, we adapt the unmasking
work of Koppel and Schler to provide feedback that allows the author to choose
the level of anonymization.<span lang=EN-GB style='mso-ansi-language:EN-GB'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
112</span></p>

<p class=AbstractTitle>Implementing a Characterization of Genre for Automatic
Genre Identification of Web Pages</p>

<p class=AbstractAuthor>Marina Santini<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Santini, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Richard Power<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Power, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Roger Evans<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Evans, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In
this paper, we propose an implementable characterization of genre suitable for
automatic genre identification of web pages. This characterization is
implemented as an inferential model based on a modified version of Bayes'
theorem. Such a model can deal with genre hybridism and individualization, two
important forces behind genre evolution. Results show that this approach is
effective and is worth further research.<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
118</span></p>

<p class=AbstractTitle>Examining the Role of Linguistic Knowledge Sources in
the Automatic Identification and Classification of Reviews</p>

<p class=AbstractAuthor>Vincent Ng<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Ng, V.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Sajib Dasgupta<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Dasgupta, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and S. M. Niaz Arifin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Arifin, S.M.N.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText>This paper examines two problems in document-level
sentiment analysis: (1) determining whether a given document is a review or
not, and (2) classifying the polarity of a review as positive or negative. We
first demonstrate that review identification can be performed with high
accuracy using only unigrams as features. We then examine the role of four
types of simple linguistic knowledge sources in a polarity classification
system.<span lang=EN-GB style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
120</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Textual Entailment<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>A Logic-based Semantic Approach to Recognizing Textual
Entailment</p>

<p class=AbstractAuthor><span lang=FR style='mso-ansi-language:FR'>Marta Tatu</span><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-begin'></span>
XE &quot;Tatu, M.&quot; </span><![endif]--><!--[if supportFields]><span
lang=FR style='mso-ansi-language:FR'><span style='mso-element:field-end'></span></span><![endif]--><span
lang=FR style='mso-ansi-language:FR'><span
style='mso-spacerun:yes'>&nbsp;</span>and Dan Moldovan</span><!--[if supportFields]><span
style='mso-element:field-begin'></span><span lang=FR style='mso-ansi-language:
FR'> XE &quot;Moldovan, D.&quot; </span><![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=FR
style='mso-ansi-language:FR'><o:p></o:p></span></p>

<p class=PosterAbstractText>This paper proposes a knowledge representation
model and a logic proving setting with axioms on demand successfully used for recognizing
textual entailments. It also details a lexical inference system which boosts
the performance of the deep semantic oriented approach on the RTE data. The
linear combination of two slightly different logical systems with the third
lexical inference system achieves 73.75% accuracy on the RTE 2006 data.<span
lang=EN-GB style='mso-ansi-language:EN-GB'><span style='mso-tab-count:1'>&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
127</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Word Segmentation<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Unsupervised Segmentation of Chinese Text by Use of
Branching Entropy</p>

<p class=AbstractAuthor>Zhihui Jin<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Jin, Z.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Kumiko Tanaka-Ishii<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Tanaka-Ishii, K.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
propose an unsupervised segmentation method based on an assumption about
language data: that the increasing point of entropy of successive characters is
the location of a word boundary. A large-scale experiment was conducted by
using 200 MB of unsegmented training data and 1 MB of test data, and precision
of 90% was attained with recall being around 80%.<span
style='mso-spacerun:yes'>&nbsp; </span>Moreover, we found that the precision
was stable at around 90% independently of the learning data size.<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>5-6pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
122</span></p>

<p class=AbstractTitle>Subword-based Tagging for Confidence-dependent Chinese
Word Segmentation</p>

<p class=AbstractAuthor>Ruiqiang Zhang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Zhang, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Genichiro Kikui<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Kikui, G.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Eiichiro Sumita<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Sumita, E.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
proposed a subword-based tagging for Chinese word segmentation to improve the existing
character-based tagging. The subword-based tagging was implemented using the
maximum entropy (MaxEnt) and the conditional random fields (CRF) methods. We
found that the proposed subword-based tagging outperformed the character-based
tagging in all comparative experiments. In addition, we proposed a confidence
measure approach to combine the results of a dictionary-based and a
subword-tagging-based segmentation. This approach can produce an ideal tradeoff
between the in-vocabulary rate and out-of-vocabulary rate. Our techniques were
evaluated using the test data from Sighan Bakeoff 2005. We achieved higher
F-scores than the best results in three of four corpora: PKU(0.951),
CITYU(0.950) and MSR(0.971).<span style='mso-tab-count:1'> </span><o:p></o:p></span></p>

<p class=SlotAndSpot><span lang=EN-GB>6-7pm<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
126</span></p>

<div style='border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:
solid windowtext .5pt;padding:0in 0in 1.0pt 0in'>

<h3><span lang=EN-GB style='mso-ansi-language:EN-GB'>Word Sense Disambiguation<o:p></o:p></span></h3>

</div>

<p class=AbstractTitle>Word sense disambiguation using lexical cohesion in the
context</p>

<p class=AbstractAuthor>Dongqiang Yang<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Yang, D.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and David M.W. Powers<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Powers, D.M.W.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span lang=EN-GB
style='mso-ansi-language:EN-GB'><o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>This
paper designs a novel lexical hub to disambiguate word sense, using both
syntagmatic and paradigmatic relations of words. It only employs the semantic
network of WordNet to calculate word similarity, and the Edinburgh Association
Thesaurus (</span><st1:stockticker><span lang=EN-GB style='mso-ansi-language:
 EN-GB'>EAT</span></st1:stockticker><span lang=EN-GB style='mso-ansi-language:
EN-GB'>) to transform contextual space for computing syntagmatic and other
domain relations with the target word. Without any back-off policy the result
on the English lexical sample of SENSEVAL-2 shows that lexical cohesion based
on edge-counting techniques is a good way of unsupervisedly disambiguating
senses.<span style='mso-tab-count:1'>&nbsp; </span><o:p></o:p></span></p>

<p class=SlotAndSpot><st1:time Minute="0" Hour="17"><span lang=EN-GB>5-6pm</span></st1:time><span
lang=EN-GB><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Spot
124</span></p>

<h1><span lang=EN-AU>Student Posters</span></h1>

<p class=AbstractTitle><span lang=EN-GB style='mso-ansi-language:EN-GB'>Semantic
Discourse Segmentation and Labeling for Route Instructions<o:p></o:p></span></p>

<p class=AbstractAuthor><span lang=EN-GB style='mso-ansi-language:EN-GB'>Nobuyuki
Shimizu<o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In
order to build a simulated robot that accepts instructions in unconstrained
natural language, a corpus of 427 route instructions was collected from human
subjects in the office navigation domain. The instructions were segmented by
the steps in the actual route and labeled with the action taken in each step.
This flat formulation reduced the problem to an IE/Segmentation task, to which
we applied Conditional Random Fields. We compared the performance of CRFs with a
set of hand-written rules. The result showed that CRFs perform better with a
73.7% success rate.<o:p></o:p></span></p>

<p class=AbstractTitle><span lang=EN-GB style='mso-ansi-language:EN-GB'>Unsupervised
Part-of-Speech Tagging Employing Efficient Graph Clustering <o:p></o:p></span></p>

<p class=AbstractAuthor><span lang=EN-GB style='mso-ansi-language:EN-GB'>Chris
Biemann<o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>An
unsupervised part-of-speech (</span><st1:stockticker><span lang=EN-GB
 style='mso-ansi-language:EN-GB'>POS</span></st1:stockticker><span lang=EN-GB
style='mso-ansi-language:EN-GB'>) tagging system that relies on graph
clustering methods is described. Unlike in current state-of-the-art approaches,
the kind and number of different tags is generated by the method itself. We
compute and merge two partitionings of word graphs: one based on context
similarity of high frequency words, another on log-likelihood statistics for
words of lower frequencies. Using the resulting word clusters as a lexicon, a
Viterbi </span><st1:stockticker><span lang=EN-GB style='mso-ansi-language:EN-GB'>POS</span></st1:stockticker><span
lang=EN-GB style='mso-ansi-language:EN-GB'> tagger is trained, which is refined
by a morphological component. The approach is evaluated on three different languages
by measuring agreement with existing taggers.<o:p></o:p></span></p>

<p class=AbstractTitle><span lang=EN-GB style='mso-ansi-language:EN-GB'>A
Flexible Approach to Natural Language Generation for Disabled Children<o:p></o:p></span></p>

<p class=AbstractAuthor><span lang=EN-GB style='mso-ansi-language:EN-GB'>Pradipta
Biswas<o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Natural
Language Generation (NLG) is a way to automatically realize a correct
expression in response to a communicative goal. This technology is mainly
explored in the fields of machine translation, report generation, dialog system
etc. In this paper we have explored the NLG technique for another novel
application assisting disabled children to take part in conversation. The
limited physical ability and mental maturity of our intended users made the NLG
approach different from others. We have taken a flexible approach where main
emphasis is given on flexibility and usability of the system. The evaluation
results show this technique can increase the communication rate of users during
a conversation.<o:p></o:p></span></p>

<p class=AbstractTitle><span lang=EN-GB style='mso-ansi-language:EN-GB'>Investigations
on Event-Based Summarization <o:p></o:p></span></p>

<p class=AbstractAuthor><span lang=EN-GB style='mso-ansi-language:EN-GB'>Mingli
Wu<o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>We
investigate independent and relevant event-based extractive mutli-document
summarization approaches. In this paper, events are defined as event terms and
associated event elements. With independent approach, we identify important
con-tents by frequency of events. With relevant approach, we identify important
contents by PageRank algorithm on the event map constructed from documents.
Experimental results are encouraging.<o:p></o:p></span></p>

<p class=AbstractTitle><span lang=EN-GB style='mso-ansi-language:EN-GB'>Modeling
Human Sentence Processing Data with a Statistical Parts-of-Speech Tagger<o:p></o:p></span></p>

<p class=AbstractAuthor><span lang=EN-GB style='mso-ansi-language:EN-GB'>Jihyun
Park<o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>It
has previously been assumed in the psycholinguistic literature that
finite-state models of language are crucially limited in their explanatory
power by the locality of the probability distribution and the narrow scope of
information used by the model. We show that a simple computational model (a
bigram part-of-speech tagger based on the design used by Corley and Crocker
(2000)) makes correct predictions on processing difficulty observed in a wide
range of empirical sentence processing data. We use two modes of evaluation:
one that relies on comparison with a control sentence, paralleling practice in
human studies; another that measures probability drop in the disambiguating
region of the sentence. Both are surprisingly good indicators of the processing
difficulty of garden-path sentences. The sentences tested are drawn from
published sources and systematically explore five different types of ambiguity:
previous studies have been narrower in scope and smaller in scale. We do not
deny the limitations of finite-state models, but argue that our results show
that their usefulness has been underestimated.<o:p></o:p></span></p>

<p class=AbstractTitle><span lang=EN-GB style='mso-ansi-language:EN-GB'>Annotation
Schemes and their Influence on Parsing Results<o:p></o:p></span></p>

<p class=AbstractAuthor><span lang=EN-GB style='mso-ansi-language:EN-GB'>Wolfgang
Maier<o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>Most
of the work on treebank-based statistical parsing exclusively uses the Wall-
Street-Journal part of the Penn treebank for evaluation purposes. Due to the
presence of this quasi-standard, the question of to which degree parsing
results depend on the properties of treebanks was often ignored. In this paper,
we use two similar German treebanks, T&uuml;Ba-D/Z and NeGra, and investigate the
role that different annotation decisions play for parsing. For these purposes,
we approximate the two treebanks by gradually taking out or inserting the
corresponding annotation components and test the performance of a standard PCFG
parser on all treebank versions. Our results give an indication of which
structures are favorable for parsing and which ones are not.<o:p></o:p></span></p>

<p class=AbstractTitle><span lang=EN-GB style='mso-ansi-language:EN-GB'>Sub-sentential
Alignment Using Substring Co-Occurrence Counts<o:p></o:p></span></p>

<p class=AbstractAuthor><span lang=EN-GB style='mso-ansi-language:EN-GB'>Fabien
Cromieres<o:p></o:p></span></p>

<p class=PosterAbstractText><span lang=EN-GB style='mso-ansi-language:EN-GB'>In
this paper, we will present an efficient method to compute the co-occurrence counts
of any pair of substring in a parallel corpus, and an algorithm that make use
of these counts to create subsentential alignments on such a corpus. This
algorithm has the advantage of being as general as possible regarding the
segmentation of text.<o:p></o:p></span></p>

<h1><span lang=EN-GB style='mso-ansi-language:EN-GB'>Reserve Papers<o:p></o:p></span></h1>

<p class=AbstractTitle>Multilingual Document Clustering: an Heuristic Approach
Based on Cognate Named Entities</p>

<p class=AbstractAuthor>Soto Montalvo<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Montalvo, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Raquel Mart&iacute;nez<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Mart&iacute;nez, R.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Arantza Casillas<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Casillas, A.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and V&iacute;ctor Fresno<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Fresno, V.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This paper presents an approach for Multilingual Document
Clustering<span style='mso-ansi-language:EN-GB'> </span>in comparable corpora.
The algorithm is of heuristic nature and it<span style='mso-ansi-language:EN-GB'>
</span>uses as unique evidence for clustering: the identification of<span
style='mso-ansi-language:EN-GB'> </span>cognate named entities between both
sides of the comparable corpora.<span style='mso-ansi-language:EN-GB'> </span>One
of the main advantages of this approach is that it does not<span
style='mso-ansi-language:EN-GB'> </span>depend on bilingual or multilingual
resources. However, it depends<span style='mso-ansi-language:EN-GB'> </span>on
the possibility of identifying cognate named entities between the<span
style='mso-ansi-language:EN-GB'> </span>languages used in the corpus. An
additional advantage of the<span style='mso-ansi-language:EN-GB'> </span>approach
is that it does not need any information about the right<span style='mso-ansi-language:
EN-GB'> </span>number of clusters; the algorithm calculates it. We have tested
this<span style='mso-ansi-language:EN-GB'> </span>approach with a comparable
corpus of news written in English and<span style='mso-ansi-language:EN-GB'> </span>Spanish.
In addition, we have compared the results with a system<span style='mso-ansi-language:
EN-GB'> </span>which translates selected document features. The obtained
results<span style='mso-ansi-language:EN-GB'> </span>are encouraging.</p>

<p class=AbstractTitle>Optimal Constituent Alignment with Edge Covers for
Semantic Projection</p>

<p class=AbstractAuthor>Sebastian Pado<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Pado, S.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Mirella Lapata<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Lapata, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Given a parallel
corpus, semantic projection</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>attempts to transfer semantic
role annotations</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>from one language to another,</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>typically by exploiting word alignments.<o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>In this paper, we
present an improved</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>method for obtaining
constituent alignments</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>between parallel sentences to
guide</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>the role projection task. Our extensions</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>are twofold: (a) we model constituent</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>alignment as minimum weight edge covers</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>in a bipartite graph, which allows us to</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>find a globally optimal solution efficiently;</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>(b) we propose tree pruning as a promising</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>strategy for reducing alignment noise.
Experimental</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>results on an English-German</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>parallel corpus demonstrate improvements</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>over state-of-the-art models.<o:p></o:p></span></p>

<p class=AbstractTitle>Punjabi Machine Transliteration</p>

<p class=AbstractAuthor>M. G. Abbas Malik<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;<span style='mso-fareast-font-family:
SimSun;mso-fareast-language:ZH-CN'>Malik, M.G.A.</span>&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>Machine Transliteration
is to transcribe a</span><span style='mso-font-kerning:0pt;mso-ansi-language:
EN-GB'> </span><span style='mso-font-kerning:0pt'>word written in a script with
approximate</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>phonetic equivalence in another language.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>It is useful for machine translation,</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>cross-lingual information retrieval,</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>multilingual text and speech processing.</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>Punjabi Machine Transliteration (PMT)</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>is a special case of machine transliteration</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>and is a process of converting a word</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>from Shahmukhi (based on Arabic script)</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>to Gurmukhi (derivation of Landa,</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>Shardha and Takri, old scripts of Indian</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>subcontinent), two scripts of Punjabi,
irrespective</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>of the type of word.<o:p></o:p></span></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>The Punjabi Machine
Transliteration</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'>
</span><span style='mso-font-kerning:0pt'>System uses transliteration rules
(character</span><span style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>mappings and dependency rules) for</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>transliteration of Shahmukhi words into</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>Gurmukhi. The PMT system can transliterate</span><span
style='mso-font-kerning:0pt;mso-ansi-language:EN-GB'> </span><span
style='mso-font-kerning:0pt'>every word written in Shahmukhi.<o:p></o:p></span></p>

<p class=AbstractTitle>Utilizing Co-Occurrence of Answers in Question Answering</p>

<p class=AbstractAuthor>Min Wu<!--[if supportFields]><span style='mso-element:
field-begin'></span> XE &quot;Wu, M.(1)&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Tomek Strzalkowski<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Strzalkowski, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText><span style='mso-font-kerning:0pt'>In this paper, we
discuss how to utilize the co-occurrence of answers in building an automatic
question answering system that answers a series of questions on a specific
topic in a batch mode. Experiments show that the answers to the many of the
questions in the series usually have a high degree of co-occurrence in relevant
document passages. This feature sometimes can¡¦t be easily utilized in an
automatic QA system which processes questions independently. However it can be
utilized in a QA system that processes questions in a batch mode. We have used
our pervious TREC QA system as baseline and augmented it with new answer
clustering and co-occurrence maximization components to build the batch QA
system. The experiment results show that the QA system running under the batch
mode get significant performance improvement over our baseline TREC QA system.<o:p></o:p></span></p>

<p class=AbstractTitle>Time Period Identification of Events in Text</p>

<p class=AbstractAuthor>Taichi Noro<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Noro, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Takashi Inui<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Inui, T.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]-->, Hiroya Takamura<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Takamura, H.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--><span
style='mso-spacerun:yes'>&nbsp;</span>and Manabu Okumura<!--[if supportFields]><span
style='mso-element:field-begin'></span> XE &quot;Okumura, M.&quot; <![endif]--><!--[if supportFields]><span
style='mso-element:field-end'></span><![endif]--></p>

<p class=MsoBodyText>This study aims at identifying when an event written in
text occurs. In particular, we classify a sentence for an event into four
time-slots; morning, daytime, evening, and night. To realize our goal, we focus
on expressions associated with time-slot (time-associated words). However,
listing up all the time-associated words is impractical, because there are
numerous time-associated expressions. We therefore use a semi-supervised
learning method, the Na&iuml;ve Bayes classifier backed up with the Expectation
Maximization algorithm, in order to iteratively extract time-associated words
while improving the classifier. We also propose to use Support Vector Machines
to filter out noisy instances that indicates no specific time period. As a
result of experiments, the proposed method achieved 0.864 of accuracy and
outperformed other methods. </p>

<h1 align=left style='text-align:left'><span lang=EN-AU>Author Index to Main
Session Papers and Posters</span></h1>

<p class=MsoNormal style='text-align:justify;text-justify:inter-ideograph'><!--[if supportFields]><span
style='mso-bidi-font-family:Arial'><span style='mso-element:field-begin'></span><span
style='mso-spacerun:yes'>&nbsp;</span>INDEX \y \c &quot;2&quot; \z
&quot;1028&quot; <span style='mso-element:field-separator'></span></span><![endif]--><span
style='mso-bidi-font-family:Arial'><span style='mso-no-proof:yes'><o:p></o:p></span></span></p>

</div>

<span style='font-size:10.0pt;font-family:"Book Antiqua";mso-fareast-font-family:
PMingLiU;mso-bidi-font-family:Arial;mso-font-kerning:1.0pt;mso-ansi-language:
EN-US;mso-fareast-language:ZH-TW;mso-bidi-language:AR-SA;mso-no-proof:yes'><br
clear=all style='page-break-before:auto;mso-break-type:section-break'>
</span>

<div class=Section2>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Abdalla,
R.M., 30<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Abekawa,
T., 27<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Acero, A.,
54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Adler, M.,
21<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Agrawal,
S., 20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Alegria,
I., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Alfonseca,
E., 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Allison,
B., 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Alm, C.O.,
59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Al-Onaizan,
Y., 16<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Amig&oacute;</span><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>, E.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 55<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ananiadou,
S., 53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Arifin,
S.M.N., 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Aronson,
A.R., 49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Arrieta,
B., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Atterer,
M., 62<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Aw, A., 60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Ayan, N.F.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 1<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Babych, B.,
59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Baldwin, T.
(2), 43<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Baldwin,
T.(1), 48<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bandyopadhyay,
S., 40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bangalore,
S., 7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Barr, C.,
51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Barrett,
L., 14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Barzilay,
R., 1<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Basu, A.,
64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Beal, M.J.,
46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bekki, D.,
66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bened&iacute;,
J.M., 44<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bergsma,
S., 2<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bhattacharyya,
P., 64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bigham, J.,
26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Blache, P.,
2<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Black, E.,
63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Blake, C.,
19<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Blunsom,
P., 3<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bod, R., 29<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bode, A.,
16<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Bollegala,
D., 13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Bouchard-C&ocirc;t&eacute;, A.</span><span style='mso-fareast-font-family:
"Arial Unicode MS";mso-no-proof:yes'>, 25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Brew, C.,
2, 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Briscoe,
T., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Brockett,
C., 8<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>Brody, S.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 4<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Brunet-Manquat, F.</span><span style='mso-fareast-font-family:
"Arial Unicode MS";mso-no-proof:yes'>, 31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>By, T.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 9<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Cahill, A.,
16, 34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Calzolari,
N., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Carroll,
J., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Carterette,
B., 51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Casacuberta,
F., 58<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Casillas,
A., 74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Castells,
P., 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Cercone, N.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 15<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>&Ccedil;etino&#287;lu,
&Ouml;., 5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chai, J.,
43<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chan, Y.S.,
3<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chang,
M-W., 62<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Charniak,
E., 11<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Charoenporn,
T., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chatterjee,
N., 20, 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Che, W., 65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen, B.,
52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen, C.,
57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen, H-H.,
33, 57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen,
J.(1), 4, 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen,
J.(2), 40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen,
J.(3), 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen,
W.(1), 18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen,
W.(2), 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chen, Y.,
35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Cherry, C.,
55<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chime,
Z.A., 38<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Chiocchetti, E.</span><span style='mso-fareast-font-family:
"Arial Unicode MS";mso-no-proof:yes'>, 31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chou, L-Y.,
50<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Choudhury,
M., 64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chrupa&#322;a,
G., 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chua, T-S.,
47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Chu-Carroll,
J., 35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Clark, S.,
22<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Clarke, J.,
12, 67<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Cohen-Sygal,
Y., 5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Cohn, T., 3<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Collier,
N., 11<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Conroy,
J.M., 68<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Cornell,
T.L., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Costello,
F.J., 24, 66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Creswell,
C., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Curran,
J.R., 12, 22<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Dagan, I.,
14, 52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Damrongrat,
C., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Dasgupta,
S., 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Daum&eacute; III,
H., 10<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Davidov,
D., 10<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Dchelotte, D.</span><span style='mso-fareast-font-family:
"Arial Unicode MS";mso-no-proof:yes'>, 57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>de
Ilarraza, A.D., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>de La Clergerie, &Eacute;.</span><span style='mso-fareast-font-family:
"Arial Unicode MS";mso-no-proof:yes'>, 11<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Demner-Fushman,
D., 28<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>DeNeefe,
S., 31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Di
Fabbrizio, G., 7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Diab, M.,
52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Do, Q., 62<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Dolan,
W.B., 8<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Dorr, B.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 1, 5, 31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Duan, J.,
47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Dubey, A.,
13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Duboue, P.,
35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Dunne, S.,
66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Eckart, R.,
42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Eisner, J.,
18, 56<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ekbal, A.,
40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Elhadad,
M., 21<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ellison,
T.M., 9<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Erkan, G.,
45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Evans, R.,
69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Fang, G.,
38<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Feinstein,
D., 35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Feldman,
R., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Feng, Z.,
17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ferret, O.,
9<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Filatova,
E., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Finch, A.,
63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Florian,
R., 15<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Forsyth,
D., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>Foth, K.A.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 9, 11, 63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Frampton,
M., 6<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Fraser, A.,
25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Fresno, V.,
74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Frunza, O.,
14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Fu, X., 53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Fujii, A.,
20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Fukumoto,
F., 49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Fung, P.,
52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Galley, M.,
31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gamage, K.,
41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gamon, M.,
8, 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ganguly,
G., 64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gao, J., 7,
15<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:SimSun;mso-ansi-language:FR;mso-fareast-language:
ZH-CN;mso-no-proof:yes'>Gardent, C.</span><span style='mso-fareast-font-family:
"Arial Unicode MS";mso-no-proof:yes'>, 45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gatt, A.,
45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Gauvain, J-L.</span><span style='mso-fareast-font-family:
"Arial Unicode MS";mso-no-proof:yes'>, 57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ge, R., 66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Geffet, M.,
52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gerdes, K.,
35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Giguet, E.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 58<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gildea, D.,
57, 58<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gim&eacute;nez,
J., 55<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Giuglea,
A-M., 30<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Glaysher,
E., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Glickman,
O., 14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gliozzo,
A., 14, 17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gobeill,
J., 49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Goh, H-K.,
47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Goldberg,
Y., 21<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Goldwater,
S., 21<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gonzalo,
J., 55<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gordon,
A.S., 65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gorman, J.,
12<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>Goyal, S.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Graehl, J.,
31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Granell,
R., 44<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Greiner,
R., 7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Greiner,
W., 51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Griffiths,
T.L., 1, 21<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Grishman,
R., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Gu, Z.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 15<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Gupta, K.,
64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Guthrie,
D., 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Guthrie,
L., 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ha, L.Q.,
50<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Haas, A.,
42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Habash, N.,
1, 21<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Haghighi,
A., 29<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hagiwara,
M., 12<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hahn, U.,
25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Haji&#269;, J.,
31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hakoda, K.,
51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hale, J., 5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hall, J.,
8, 62<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Halpin, H.,
28<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hamabe, R.,
40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Han, X., 53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hanna, P.,
50<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Harabagiu,
S., 30<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hargreaves,
K., 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Harper, M.,
5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hartley,
A., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Haruechaiyasak,
C., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hashimoto,
C., 41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hashimoto,
T., 51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hatzivassiloglou,
V., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hauptmann,
A., 34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hemforth,
B., 2<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hickl, A.,
30<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Higashinaka,
R., 9<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hirakawa,
H., 62<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hobbs,
J.R., 13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hockenmaier,
J., 16<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hopkins,
M., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Horacek,
H., 52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hovy, E.,
47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hsieh,
S-K., 41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hu, Y., 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Huang,
C-R., 39, 41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hulth, A.,
17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>H&uuml;wel, S.,
66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Hwang,
Y-S., 63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ichikawa,
H., 51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Iida, R.,
19<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Inagaki,
Y., 6, 57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Inkpen, D.,
14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-bidi-font-weight:bold;
mso-no-proof:yes'>Inui, K.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 19<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Inui, T.,
75<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Isahara,
H., 39, 40, 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ishikawa,
T., 20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ishioka, T.,
8<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ishizuka,
M., 13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Isozaki,
H., 7, 19, 25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Isu, N., 8,
60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Izagirre,
E., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jabbari,
S., 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jain, A.,
26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jang, F-L.,
60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jeong, M.,
48<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ji, D., 4,
47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ji, H., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jiao, F., 7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jin, Y., 20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jin, Z., 70<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jing, H.,
15<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Johansson,
R., 65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Johnson,
M., 11, 21<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jones, R.,
51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Judge, J.,
16<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Jurafsky,
D., 26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kacmarcik,
G., 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kahane, S.,
5, 35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kaji, N.,
67<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kambhatla,
N., 15, 48<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kameda, M.,
8<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kanamaru,
T., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kang, B.,
20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kashioka,
H., 6<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kate, R.J.,
30<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kawahara,
T., 40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kawai, A.,
8, 60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kelleher,
J.D., 24, 34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Keller, F.,
13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Khadivi,
S., 67<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Khaltar,
B-O., 20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Khegai, J.,
58<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kikui, G.,
70<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kim, S.N.,
48<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kim, S-M.,
47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kirby, S.,
9<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kitsuregawa,
M., 67<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Klakow, D.,
29<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Klein, D.,
14, 25, 29<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Klementiev,
A., 26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Knight, K.,
31, 64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>Koller, A.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kongyoung,
S., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>K&ouml;rding,
K.P., 1<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Korhonen,
A., 11<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Krasnyanskaya,
A., 5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Krishnan,
V., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kruijff,
G-J. M., 24, 34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Krymolowski,
Y., 11<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kuhlmann,
M., 63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kuhn, J.,
61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kuo, J-S.,
53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kurata, G.,
23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Kurohashi,
S., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lapata, M.,
4, 12, 67, 74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-bidi-font-weight:bold;
mso-no-proof:yes'>Lavie, A.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lease, M.,
5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lee, C.M.,
24<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lee, C-H.,
7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lee, G.G.,
48<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lee, J., 54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lee,
K.W.K., 45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lemon, O.,
6, 43<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, G., 33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, H., 53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, J.(1),
33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, J.(2),
61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>Li, J.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>(3), 17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, J-H.,
41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, M., 33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, Q., 20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, S., 14,
65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Li, W., 12,
32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Liang, P.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lifchits,
A., 26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lin, D., 2,
26, 55<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lin, J., 28,
31, 65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lin, M-S.,
33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lin, S.,
16, 19<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lin, W-H.,
34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lioma, C.,
49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Litman,
D.J., 6<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Liu, D., 57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Liu, Q.,
16, 19<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Liu, T.,
14, 65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Liu, Y.(1),
19<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Liu, Y.(2),
5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Liu, Z.,
54, 56<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Loeff, N.,
59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lowery, K.,
51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lu, Q., 12<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lu, R., 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lu, Z., 14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Luquet, P-S.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 58<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Lv, Y., 18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mahajan,
M., 54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>Malik, M.G.A.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Malioutov,
I., 1<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mani, I.,
24<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Manning,
C.D., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Marcu, D.,
3, 10, 25, 31, 36, 44<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Maritxalar,
M., 61<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Marmorshtein,
E., 14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>M&agrave;rquez,
L., 55<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Marrafa,
P., 51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mart&iacute;nez,
R., 74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mart&iacute;nez-Hinarejos,
C.D., 44<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Maruyama,
T., 6<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Maslennikov,
M., 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Masuda, K.,
33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Matsubara,
S., 6, 57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Matsumoto,
Y., 19, 22<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>McClosky,
D., 11<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>McDermott,
E., 7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>McKeown,
K., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Megyesi,
B.B., 17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Melamed,
I.D., 29, 32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mendes, S.,
51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>Menzel, W.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 9, 11, 63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mihalcea,
R., 34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mirkin, S.,
52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mitamura,
T., 14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Miyao, Y.,
15, 33, 66, 68<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Moldovan,
D., 30, 61, 70<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Monachini,
M., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Montalvo,
S., 74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mooney,
R.J., 30, 66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Moore,
J.D., 28<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Moore,
R.C., 16<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mori, S.,
23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Morihiro,
K., 8, 60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Moschitti,
A., 13, 30<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mukherjee,
A., 64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Mulkar, R.,
13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Munteanu,
D.S., 3<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Murata, M.,
39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Murray,
G.C., 31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Myaeng,
S-H., 20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nagata, M.,
23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nagata, R.,
8, 60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nair, A.,
64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nakagawa,
T., 22<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nakatsu,
C., 36<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nanba, H.,
68<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Naskar,
S.K., 40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Navigli</span><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>, R.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 4<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ney, H., 67<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ng, A.Y.,
26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ng, H.T., 3<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ng, V., 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nguyen,
L-M., 54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nie, J-Y.,
18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nilsson,
J., 8, 62<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nilsson,
L., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ninomiya,
T., 33, 68<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nishino,
F., 38<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Niu, C., 15<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Niu, Z., 4,
47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nivre, J.,
8, 62, 63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Noro, T.,
75<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Novischi,
A., 30<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nowson, S.,
67<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Nugues. P.,
65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Oberlander,
J., 67<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Oflazer,
K., 5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ogawa, Y.,
12<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ohashi, K.,
23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ohno, T., 6<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ohta, T.,
33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ohtake, K.,
43<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Okanohara,
D., 15<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Okazaki,
N., 13, 53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Okumura,
M., 27, 47, 68, 75<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>O'Leary,
D.P., 68<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ookawa, H.,
53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Osborne,
M., 32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ounis, I.,
49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Pado, S.,
74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Palingoon,
P., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Palmer, M.,
40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Pan, F., 13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Pantel, P.,
4, 26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Papineni,
K., 16<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Park, J., 2<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Park, S-B.,
20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Park, S-Y.,
20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Parmentier</span><span lang=FR style='mso-fareast-font-family:
SimSun;mso-ansi-language:FR;mso-fareast-language:ZH-CN;mso-no-proof:yes'>, Y.</span><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>, 45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Pa&#351;ca, M.,
26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Patel, A.,
45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Pazienza,
M.T., 28<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Pecina, P.,
31, 54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Pennacchiotti,
M., 4, 26, 28<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Petrov, S.,
14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Phan, X-H.,
54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Power, R.,
69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Powers,
D.M.W., 71<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Prager, J.,
35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Prasad, R.,
9<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Prevot, L.,
39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Purver, M.,
1<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Pustejovsky,
J., 24<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Radev,
D.R., 45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Rambow, O.,
21<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ramsay, A.,
69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Rappoport,
A., 10<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Rathod, N.,
64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Rauzy, S.,
2<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ren, D., 33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Rieser, V.,
43<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Roark, B.,
5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Rosenfeld,
B., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Rotaru, M.,
6<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Roth, D.,
26, 62<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Roy, S., 23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ruch, P.,
49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ruiz-Casado,
M., 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Ryu, K., 57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sadat, F.,
1<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sagae, K.,
14, 63<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Sagot, B.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 11<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Saito, K.,
23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sangkeettrakarn,
C., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Santini,
M., 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sarikaya,
R., 18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sato, M.,
66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sato, S.,
41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Satta, G.,
57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Schlesinger,
J.D., 68<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Schlesinger,
P., 54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Schmid, H.,
6<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Schrader,
B., 55<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sch&uuml;tze,
H., 62<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Schuurmans,
D., 7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Schwenk, H.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 57<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sekine, S.,
48<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>S&eacute;rasset, G.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Seretan,
V., 31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shafran,
I., 5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sharoff,
S., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shen, D.,
29<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shen, S.,
45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shi, L., 15<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shibata,
T., 59<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shimazu,
A., 54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shimizu,
N., 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shirado,
T., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shirai, K.,
39, 53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Shrivastava,
M., 64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Singh, S.,
64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Smith,
D.A., 56<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Smith,
F.J., 50<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Smith,
N.A., 18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Snider, N.,
52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Snover, M.,
5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Snow, R.,
26<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sorensen,
J.S., 18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Soria, C.,
39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Soricut,
R., 36, 44<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sornlertlamvanich,
V., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sproat, R.,
3<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Srihari,
R.K., 46<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Stent, A.,
7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Stewart,
D.W., 50<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Stewart, R.,
5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Strapparava,
C., 14, 17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Strzalkowski,
T., 74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sturt, P.,
13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Su, J.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 2, 4, 27, 60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Subramaniam,
L.V., 23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sudoh, K.,
19<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sumita, E.,
63, 70<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sun, L., 18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Sun</span><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>, M.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Suzuki, D.,
50<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Suzuki, H.,
7, 34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Suzuki, J.,
7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Suzuki, Y.,
49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Swanson,
R., 65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tae, Y-S.,
20<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Takamura,
H., 75<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Takuma, D.,
23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Talbot, D.,
32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Tan, C.L.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 2, 4, 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tanaka-Ishii,
K., 70<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tao, T., 3<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Taskar, B.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Tatu, M.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 70<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tbahriti,
I., 49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Teh, Y.W.,
32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tenebaum,
J.B., 1<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Teufel, S.,
30<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Thater</span><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>, S.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 13<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Thayer, I.,
31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Thibaux,
R., 14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tian, Y.,
47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tiedemann,
J., 49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tillmann,
C., 23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tokunaga,
T., 39, 51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tom&aacute;s, J.,
58<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Toutanova, K.</span><span style='mso-fareast-font-family:
"Arial Unicode MS";mso-no-proof:yes'>, 34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Toyama, K.,
12<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tsai, J-L.,
50<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tsujii, J.,
15, 33, 66, 68<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tsukada,
H., 19, 25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Tsuruoka,
Y., 15, 33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Turian, J.,
29<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Turney,
P.D., 10<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Uchimoto,
K., 40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Unno, Y.,
68<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Utsumi, A.,
50<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Utsuro, T.,
41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Vadas, D.,
22<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>van
Deemter, K., 45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>van der
Plas, L., 49<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>van
Genabith, J., 16, 34, 69<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Veale, T.,
66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Verhagen,
M., 24<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Walker,
M.A., 9<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wang, H.,
14, 18, 33, 54, 56<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wang, M.,
14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wang,
S.(1), 7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wang,
S.(2), 35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wang, W.,
31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wang, Y-Y.,
54<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wasala, A.,
41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Watanabe,
T., 25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Waxmonsky,
S., 32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Weerasinghe,
R., 41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wehrli, E.,
31<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wei, Y-C.,
33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wellington,
B., 32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wellner,
B., 24<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Weng, F.,
17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wermter,
J., 25<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>White, M.,
36<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wiebe, J.,
34<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wintner,
S., 5, 35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wolska, M.,
52<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wong, K-F.,
32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wrede, B.,
66<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wu, A., 51<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wu, C-H.,
44, 60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wu, D., 45<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wu, H., 54,
56<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wu, M.(1),
74<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wu, M.(2),
12<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Wu, W., 47<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Xia, J., 39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Xia, Y., 32<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Xiao, J.,
60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Xing, E.P.,
56<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Xiong, D.,
16<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Xu, W., 12<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Xue, N., 40<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yamada, K.,
64<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yamamoto,
K., 23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yang, D.,
71<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yang, M-Z.,
44<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Yang, X.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 2<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yang, Y-K.,
53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yao, J., 14<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yeh, J-F.,
44<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yih, W., 16<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yoshida,
K., 33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yu, B., 7<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yu, H., 38,
39<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yu, L-C.,
60<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yuan, C.,
12<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Yung, L., 5<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zanzotto,
F.M., 13, 28<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zens, R.,
67<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhai, C., 3<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang, C.,
43<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang, H.,
57, 58<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang,
J.(1), 27<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang,
J.(2), 18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Zhang, M.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 4, 27, 60, 65<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang, Q.,
17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang, R.,
70<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang, T.,
23<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang, W.,
18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang</span><span
style='mso-fareast-font-family:SimSun;mso-fareast-language:ZH-CN;mso-no-proof:
yes'>, X.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 17<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang,
Y.(1), 33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhang,
Y.(2), 42<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhao, B.,
56<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhao, T.,
53<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span lang=FR
style='mso-fareast-font-family:"Arial Unicode MS";mso-ansi-language:FR;
mso-no-proof:yes'>Zhou, G.</span><span style='mso-fareast-font-family:"Arial Unicode MS";
mso-no-proof:yes'>, 4, 27<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhou, M.,
15, 33, 35<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhu, J.(1),
18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhu, J.(2),
41<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zhu, M., 33<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zitouni,
I., 15, 18<o:p></o:p></span></p>

<p class=MsoIndex1 style='tab-stops:right dotted 207.15pt'><span
style='mso-fareast-font-family:"Arial Unicode MS";mso-no-proof:yes'>Zock, M., 9<o:p></o:p></span></p>

</div>

<span style='font-size:10.0pt;font-family:"Book Antiqua";mso-fareast-font-family:
PMingLiU;mso-bidi-font-family:Arial;mso-font-kerning:1.0pt;mso-ansi-language:
EN-US;mso-fareast-language:ZH-TW;mso-bidi-language:AR-SA;mso-no-proof:yes'><br
clear=all style='page-break-before:auto;mso-break-type:section-break'>
</span>

<div class=Section3>

<p class=MsoNormal style='text-align:justify;text-justify:inter-ideograph'><!--[if supportFields]><span
style='mso-bidi-font-family:Arial'><span style='mso-element:field-end'></span></span><![endif]--><span
style='mso-bidi-font-family:Arial'><o:p>&nbsp;</o:p></span></p>

</div>

</body>

</html>
