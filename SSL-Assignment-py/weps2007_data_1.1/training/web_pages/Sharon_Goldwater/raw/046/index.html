<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<META name="keywords" content="fai, forum for artifical intelligence,
forum for ai, ai, artificial intelligence, ai seminar, ai talks, texas, university of texas, austin">

<head>
  <title>Forum for Artificial Intelligence</title>
  <meta http-equiv="Content-Type"
 content="text/html; charset=iso-8859-1">
  <style type="text/css">
<!--
p {  font-family: "Times New Roman", Times, serif; color: #FFFFFF}
h2 {  font-family: Georgia, "Times New Roman", Times, serif; color: #FFFFFF; font-style: italic}
h3 {  font-family: Georgia, "Times New Roman", Times, serif; color: #FFFFFF; font-style: italic}
h4 {  font-family: Georgia, "Times New Roman", Times, serif; color: #FFFFFF}
a:hover {  color: #00CCCC; text-decoration: none}
a:active {  color: #FFFFFF; text-decoration: none}
a:link {  color: #66CCFF; text-decoration: underline}
a:visited {  color: #66CCFF; text-decoration: underline}
h1 {  font-family: Georgia, "Times New Roman", Times, serif; color: #FFFFFF}
-->
  </style>
</head>
<body style="background-color: rgb(0, 0, 0); color: rgb(255, 255, 255);">
<div align="center">
<p><br>
<img src="FAI-iRobot.jpg" title=""
 alt="Forum for Artificial Intelligence"  style="width: 400px; "><br>
<!--  alt="Forum for Artificial Intelligence"  style="width: 499px; "><br> -->
</p>
<br>

<p>
<center>
<b>
[ <a href="index.html#about">About FAI</a> &nbsp;  |  &nbsp;  
  <a href="index.html#upcoming">Upcoming talks</a>  &nbsp;  |   &nbsp;  
  <a href="index.html#past">Past talks</a> ]
</b>
</center>

<h2><a name="about">About FAI</a></h2>

<table border="0" cellspacing="5" cellpadding="5"
 style="width: 80%;">
  <tbody>
    <tr bgcolor="#333366">
      <td>
      <p align="left">The Forum for Artificial Intelligence meets every
other week (or so) to discuss scientific, philosophical, and cultural
issues in artificial intelligence. Both technical research topics and
broader inter-disciplinary aspects of AI are covered, and all
are welcome to attend!</p>

<p style="text-align: left;">If you would like to be added to the FAI
mailing list, or have any questions or comments, please send email to <a
href="mailto:nkj@cs.utexas.edu">Nick Jong</a>, <a
href="mailto:lilyanamATcs.utexas.edu">Lily Mihalkova</a>, or <a
href="mailto:tecuciATcs.utexas.edu"> Dan Tecuci</a> .</p>

       <div style="text-align: left;"> </div>
      </td>
    </tr>
  </tbody>
</table>


<h2><a name="upcoming">Upcoming talks</a></h2>
<h3>

<table border="1" cellpadding=3 width=80%>
<col width=15%>
<col width=18%>
<col width=47%>


<!-- UPCOMING TALK TITLES GO HERE -->

 <tr>
     <td> Wednesday, March 7 <br>
          11:00am, ACES 2.402</td>
     <td> <a
          href="http://www.cogsci.ed.ac.uk/~steedman/">Mark Steedman</a><br>
	  University of Edinburgh</td>
     <td> <a href="index.html#Mar7">The Computational Problem of Natural Language Acquisition</a> </td>
  </tr>

<tr>
   <td> Friday, March 9 <br>
        11:00am, ACES 6.304</td>
   <td> <a href="http://pi7.fernuni-hagen.de/helbig/index_en.html">Hermann Helbig</a><br>
        University of Hagen, Germany</td>
  <td><a href="index.html#Mar9">Multilayered Extended Semantic Networks as a Knowledge Representation Paradigm and Interlingua for Meaning Representation</a></td>
</tr>

  <tr>
     <td> Friday, March 30 <br>
          2:00pm, ACES 2.402</td>
     <td> <a
          href="http://www.inf.unisinos.br/~renata/">Renata Vieira</a><br>
	  Department of Informatics <br>
          UNISINOS<br>
          Sao Leopoldo, Brazil</td>
     <td> <a href="index.html#Mar30">Title TBA</a> </td>
  </tr>


 <tr>
     <td> Monday, April 23 <br>
          11:00am, ACES 2.302 (Avaya)</td>
     <td> <a
          href="http://web.mit.edu/nickroy/www/">Nicholas Roy</a><br>
	  Massachusetts Institute of Technology</td>
     <td> <a href="index.html#Apr23">Title TBA</a> </td>
  </tr>

</table>







</h3>
<table width="80%" border="0" cellspacing="5" cellpadding="5">
<tbody>


<!-- UPCOMING TALK ABSTRACTS GO HERE -->



<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Wednesday, March 7, 11:00am<br><br>
  Coffee at 10:45am<br><br>
    ACES 2.402</h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Mar7"></a>The Computational Problem of Natural Language Acquisition</h4>
        <h4>Dr. Mark Steedman &nbsp;&nbsp;[<a href="http://www.cogsci.ed.ac.uk/~steedman/">homepage</a>] <br><br>
	University of Edinburgh
        </h4>
 <p><h4>
     [<a
     href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=MarkSteedman">Sign-up
     schedule for individual meetings</a>]
     </h4>
<p>The talk reviews work-in-progress on language acquisition in
children and robots using combinatory categorial grammar (CCG),
building on work by Siskind, Villavicencio, and Zettlemoyer, among
others.</p>

<p>CCG is a theory of grammar in which all language-specific
grammatical information resides in the lexicon.  A small universal set
of strictly type-driven, non-structure dependent, syntactic rules
(based on Curry's combinators B, S, and T) then "projects" lexical
items into sentence-meaning pairs.  The task that faces the child in
the earliest stages of language acquisition can therefore be seen as
learning a lexicon on the basis of exposure to (probably ambiguous,
possibly somewhat noisy) sentence-meaning pairs, given this universal
combinatory "projection principle", and a mapping from semantic types
to the set of all universally available lexical syntactic types.</p>

<p>The talk argues that a very simple statistical model allows
children to arrive at a target lexicon without navigation of subset
principles, or attention to any attendant notion of trigger other than
the notion "reasonably short sentence in a reasonably understandable
situation".  The model explains the pattern of errors that have been
found in elicitation experiments.  The linguistic notion of
"parameter" appears to be redundant to this process.</p>

<p>The talk goes on to consider some more general implications of the 
theory, including its application to the phenomenon of "syntactic
bootstrapping," touching on the question of the prelinguistic origin
of the combinatory projection principle itself.</p>
<h4>About the speaker:</h4>

<p>Mark Steedman is Professor in the School of Informatics at the
University of Edinburgh. He received his PhD from the University of
Edinburgh in 1973.  He came to Edinburgh in 1998 from the University
of Pennsylvania, where he was Professor in the Department of Computer
and Information Science.  He is a Fellow of the American Association
for Artificial Intelligence, a Fellow of the Royal Society of
Edinburgh, and a Fellow of the British Academy.</p>

<p>His research interests cover issues in computational linguistics,
artificial intelligence, computer science, and cognitive science, and
their applications in practical systems, including syntax and
semantics of natural language, wide-coverage parsing, comprehension of
natural language by humans and by machine, and the role of intonation
in spoken language generation and analysis.  Some of his research
concerns the analysis of music by humans and machines.  He has acted
as advisor for twenty-four PhDs.</p>
</p>
</td>    
</tr>


<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Friday, March 9, 11:00am<br><br>
  Coffee at 10:45am<br><br>
    ACES 6.304</h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Mar9"></a>Multilayered Extended Semantic Networks as a Knowledge Representation Paradigm and Interlingua for Meaning Representation</h4>
        <h4>Dr. Hermann Helbig &nbsp;&nbsp;[<a href="http://pi7.fernuni-hagen.de/helbig/index_en.html">homepage</a>] <br><br>
	University of Hagen
        </h4>
 <p><h4>
      [<a href = http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=HermannHelbig>Sign-up
    schedule for individual meetings</a>]
     </h4>
<p>The talk gives an overview of Multilayered Extended Semantic Networks (abbreviated MultiNet), which is one of the most comprehensively described
knowledge representation paradigms used as a semantic interlingua in large-scale NLP applications and for linguistic investigations into the semantics and pragmatics of natural language.

<p>As with other semantic networks, concepts are represented in MultiNet by nodes, and relations between concepts are represented as arcs between these nodes. Additionally to that, every node is classified according to a predefined conceptual ontology forming a hierarchy of sorts,
and the nodes are embedded in a multidimensional space of layer
attributes and their values.

<p>MultiNet provides a set of about 150 standardized relations and
functions which are described
in a very concise way including an axiomatic apparatus, where the
axioms are classified
according to predefined types. The representational means of MultiNet
claim to fulfill the
criteria of universality, homogeneity, and cognitive adequacy. In the
talk, it is also shown,
how MultiNet can be used for the semantic representation of different
semantic phenomena.

<p>To overcome the quantitative barrier in building large knowledge bases
and semantically
oriented computational lexica, MultiNet is associated with a set of
tools including a semantic
interpreter NatLink for automatically translating natural language
expressions into MultiNet
networks, a workbench LIA for the computer lexicographer, and a
workbench MWR for the
knowledge engineer for managing and graphically manipulating semantic networks.

<p>The applications of MultiNet as a semantic interlingua range from
natural language interfaces
to the Internet and to dedicated databases, over question-answering
systems, to systems for
automatic knowledge acquisition.

<h4>About the speaker:</h4>

<p>Hermann Helbig is Professor at the University of Hagen, Germany, and head of
the chair Intelligent Information and Communication Systems. He received his
Dr.rer.nat. (PhD) in 1976 in Automatic Symbolic Formula Manipulation and his
Dr.rer.nat.habil. (Habilitation) in 1986 in Knowledge Representation. His
experiences in AI research cover a period of more than 30 years. His main
contributions lie in the fields of question answering (question answering
system FAS-80), natural language interfaces to data bases (NLI-AIDOS),
word-class controlled functional analysis (WCFA), knowledge representation
(MultiNet paradigm), and computational lexicography (semantically based
computational lexicon HaGenLex). He is author of several monographs in AI,
his last book relevant to the talk is "Knowledge Representation and
the Semantics of Natural Language".
 <p> His research interests cover issues in Natural Language Processing,
Computational Lexicography, Knowledge Representation and Management,
Semantics of NL, and  Electronic Distance Teaching in AI.
</td>    
</tr>

<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Friday, March 30, 2:00pm<br><br>
  Coffee at 1:45pm<br><br>
    ACES 2.402</h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Mar30"></a>Title TBA</h4>
        <h4>Dr. Renata Vieira &nbsp;&nbsp;[<a href="http://www.inf.unisinos.br/~renata/">homepage</a>] <br><br>
	Department of Inofrmatics <br>
        UNISINOS <br>
        Sao Leopoldo, Brazil
        </h4>
 <p><h4>
<!--      [<a -->
<!--      href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=WilliamW.Cohen">Sign-up -->
<!--      schedule for individual meetings</a>]  -->
     </h4>
<p>
Abstract TBA
</p>
<h4>About the speaker:</h4>
<p>
Bio TBA
</p>
</td>    
</tr>

<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Monday, April 23, 11:00am<br><br>
  Coffee at 10:45am<br><br>
    ACES 2.302 (Avaya)</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Apr23"></a>Title TBA</h4>
        <h4>Dr. Nicholas Roy &nbsp;&nbsp;[<a href="http://web.mit.edu/nickroy/www/">homepage</a>] <br><br>
	Massachusetts Institute of Technology
        </h4>
<!--  <p><h4> -->
<!--       [<a -->
<!--      href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=Dr.RobertHolte">Sign-up -->
<!--       schedule for individual meetings</a>] -->
<!--      </h4> -->
<p>Abstract TBA</p>
<h4>About the speaker:</h4>
<p>Bio TBA</p>
</td>    
</tr>


</tbody>
</table>
<h2><a name="past">Past talks</a></h2>
<h3>

<table border="1" cellpadding=3 width=80%>
<col width=15%>
<col width=20%>
<col width=45%>

<!-- PAST TALK TITLES GO HERE -->



  <tr>
     <td> Thursday, July 13 <br>
          1:00pm, ACES 2.402</td>
     <td> <a
          href="http://www.cs.cmu.edu/~wcohen/">William W. Cohen</a><br>
	  CMU</td>
     <td> <a href="index.html#Jul13">A Framework for Learning to Query Heterogeneous Data</a> </td>
  </tr>


  <tr>
     <td> Friday, Aug. 25 <br>
          11:00am, ACES 6.304</td>
     <td> <a
          href="http://www.cs.cmu.edu/~pbennett/">Paul Bennett</a>,<br>
          CMU</td>
     <td> <a href="index.html#Aug25">Building Reliable Metaclassifiers for Text Learning</a> </td>
  </tr>


  <tr>
     <td> Thursday, Aug. 31 <br>
          3:30pm, ACES 2.302</td>
     <td> <a
          href="http://web.media.mit.edu/~dkroy/">Deb Roy</a>,<br>
          MIT</td>
     <td> <a href="index.html#Sep1">Meaning Machines</a> </td>
  </tr>


  <tr>
     <td> Thursday, Sep. 7 <br>
          3:30pm, ACES 2.302</td>
     <td> <a
          href="http://www.natural-selection.com/people_dfogel.html">David Fogel</a>,<br>
          Natural Selection, Inc.</td>
     <td> <a href="index.html#Sep8">Behind the Scenes with Blondie24: Evolving Intelligence in Checkers
and Chess</a> </td>
  </tr>

 <tr>
     <td> Friday, November 3 <br>
          3:00pm, ACES 2.402</td>
     <td> <a
          href="http://www.me.utexas.edu/~campbell/index.htm">Matthew Campbell</a><br>
	  University of Texas at Austin, Department of Mechanical Engineering</td>
     <td> <a href="index.html#Nov3">Search Methods for Finding Optimal Graph Topologies</a> </td>
  </tr>

 <tr>
     <td> Friday, November 10 <br>
          11:00am, ACES 2.402</td>
     <td> <a
          href="http://comp.ling.utexas.edu/erk/">Katrin Erk</a><br>
	  University of Texas at Austin, Department of Linguistics</td>
     <td> <a href="index.html#Nov10">Automatic meaning analysis of free text: small steps towards a big goal</a> </td>
  </tr>

 <tr>
     <td> Wednesday, November 29 <br>
          2:00pm, ACES 2.402</td>
     <td> <a
          href="http://www.cse.msu.edu/~ofria/">Charles Ofria</a><br>
	  Michigan State University</td>
     <td> <a href="index.html#Nov29">Life in the Machine: The Evolution of Novel Complexity in Digital Organisms</a> </td>
  </tr>

 <tr>
     <td> Friday, December 8 <br>
          11:00am, ACES 2.402</td>
     <td> <a
          href="http://www.ai.sri.com/people/basu/">Sugato Basu</a><br>
	  SRI International, Menlo Park, CA</td>
     <td> <a href="index.html#Dec8">Machine Learning in Web 2.0: Analyzing Dynamic Content-driven Social 
Networks</a> </td>
  </tr>

 <tr>
     <td> Friday, February 9 <br>
          11:00am, ACES 2.402</td>
     <td> <a
          href="http://www.cs.cornell.edu/~caruana/">Rich Caruana</a><br>
	  Cornell University</td>
     <td> <a href="index.html#Feb9">Which Supervised Learning Method Works Best for What?<br>
An Empirical Comparison of Learning Methods and Metrics++</a> </td>
  </tr>

 <tr>
     <td> Thursday, February 15<br>
          2:00pm, ACES 2.402</td>
     <td> <a
          href="http://www.cog.brown.edu/~mj/">Mark Johnson</a><br>
	  Brown University</td>
     <td> <a href="index.html#Feb15">Bayesian Inference of Grammars</a> </td>
  </tr>

 <tr>
     <td> Friday, February 23 <br>
          11:00am, ACES 2.302 (Avaya)</td>
     <td> <a
          href="http://www.cs.ualberta.ca/~holte/">Robert Holte</a><br>
	  University of Alberta</td>
     <td> <a href="index.html#Feb23">Additive Pattern Database Heuristics</a> </td>
  </tr>


</table>

<p>
<table width="80%" border="0" cellspacing="5" cellpadding="5">
<tbody>

<!-- PAST TALK ABSTRACTS GO HERE -->


<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Thursday, July 13, 1:00pm<br><br>
  Coffee at 12:45pm<br><br>
    ACES 2.402</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Jul13"></a>A Framework for Learning to Query Heterogeneous Data</h4>
        <h4>Dr. William W. Cohen &nbsp;&nbsp;[<a href="http://www.cs.cmu.edu/~wcohen/">homepage</a>] <br><br>
	Machine Learning Department<br>
	Carnegie Mellon University</h4>
 <p><h4>
     [<a
     href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=WilliamW.Cohen">Sign-up
     schedule for individual meetings</a>] 
     </h4>
<p>
A long-term goal of research on data integration is to develop data
models and query languages that make it easy to answer structured
queries using heterogeneous data.  In this talk, I will describe a
very simple query language, based on typed similarity queries, which
are answered based on a graph containing a heterogeneous mixture of
textual and non-textual objects.  The similarity metric proposed is
based on a lazy graph walk, which can be approximated efficiently
using methods related to particle filtering.  Machine learning
techniques can be used to improve this metric for specific tasks,
often leading to performance far better than plausible task-specific
baseline methods.  We experimentally evaluate several classes of
similarity queries from the domains of analysis of biomedical text and
personal information management: for instance, in one set of
experiments, a user's personal information is represented as a graph
containing messages, calendar information, social network information,
and a timeline, and similarity search is used to find people likely to
attend a meeting.

<p>This is joint work with Einat Minkov and Andrew Ng.

</p>
<h4>About the speaker:</h4>
<p>
William Cohen received his bachelor's degree in Computer Science from Duke
University in 1984, and a PhD in Computer Science from Rutgers University
in 1990. From 1990 to 2000 Dr. Cohen worked at AT&amp;T Bell Labs and later
AT&amp;T Labs-Research, and from April 2000 to May 2002 Dr. Cohen worked at
Whizbang Labs, a company specializing in extracting information from the
web. Dr. Cohen is member of the board of the International Machine
Learning Society, and has served as an action editor for the Journal of
Machine Learning Research, the journal Machine Learning and the Journal of
Artificial Intelligence Research. He co-organized the 1994 International
Machine Learning Conference, is the co-Program Committee Chair for the
2006 International Machine Learning Conference, and has served on more
than 20 program committees or advisory committees.
<p>
Dr. Cohen's research interests include information integration and machine
learning, particularly information extraction, text categorization and
learning from large datasets. He holds seven patents related to learning,
discovery, information retrieval, and data integration, and is the author
of more than 100 publications.
</p>
</td>    
</tr>


<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Friday, Aug. 25, 11:00am<br><br>
  Coffee at 10:45am<br><br>
    ACES 6.304</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Aug25"></a>Building Reliable Metaclassifiers for Text Learning</h4>
        <h4>Dr. Paul Bennett &nbsp;&nbsp;[<a href="http://www.cs.cmu.edu/~pbennett/">homepage</a>] <br><br>
	Computer Science Department<br>
	Carnegie Mellon University</h4>
 <p><h4>
     [<a
     href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=PaulBennett">Sign-up
     schedule for individual meetings</a>]
     </h4>
<p>
Appropriately combining information sources is a broad topic that has been researched in many forms. It includes sensor fusion, distributed data-mining, regression combination, classifier combination, and even the basic classification problem. After all, the hypothesis a classifier emits is just a specification of how the information in the basic features should be combined.  This talk addresses one subfield of this domain: leveraging locality when combining classifiers for text classification.</p>

<p>After discussing and introducing improved methods for recalibrating classifiers, we define local reliability, dependence, and variance and discuss the roles they play in classifier combination. Using these insights, we motivate a series of reliability-indicator variables which intuitively abstract the input domain to capture the local context related to a classifier's reliability.</p>

<p>We then present our main methodology, STRIVE. STRIVE employs a metaclassification approach to learn an improved model which varies the combination rule by considering the local reliability of the base classifiers via the indicators. The resulting models empirically outperform state-of-the-art metaclassification approaches that do not use locality.  Next, we analyze the contributions of the various reliability indicators to the combination model and suggest informative features to consider when redesigning the base classifiers.  Finally, we show how inductive transfer methods can be extended to increase the amount of labeled training data for learning a combination model by collapsing data traditionally viewed as coming from different learning tasks.</p>
<h4>About the speaker:</h4>
<p>
Paul Bennett is currently a Postdoctoral Fellow in the Language Technologies Institute at Carnegie Mellon University where he serves as Chief Learning Architect on the RADAR project.  Paul's primary research interests are in text classification, information retrieval, ensemble methods, and calibration, with wider interests in statistical learning and applications of artificial intelligence in adaptive systems in general.  His published work includes research on classifier combination, action-item detection, calibration, inductive transfer, machine translation, and recommender systems.  Paul received his Ph.D. (2006) from the Computer Science Department at Carnegie Mellon University.
</p>
</td>    
</tr>


<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Thursday, Aug. 31, 3:30pm<br><br>
  Coffee at 3:15pm<br><br>
    ACES 2.302, Avaya Auditorium</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Sep1"></a>Meaning Machines</h4>
        <h4>Dr. Deb Roy &nbsp;&nbsp;[<a href="http://web.media.mit.edu/~dkroy/">homepage</a>] <br><br>
	MIT Media Laboratory<br>
	MIT</h4>
 <p><h4>
 [<a href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=DebRoy">Sign-up schedule for individual meetings</a>]
     </h4>
<p>
People use words to refer to the world as a means for influencing the beliefs and actions of others. Although many
isolated aspects of the structure and use of language have been extensively studied, a unified model of situated
language use remains unexplored. Any attempt to explain unconstrained adult language use appears futile due to the
overwhelming complexity of the physical, cognitive, and cultural factors at play. A strategy for making progress
towards a holistic account of language use is to study simple forms of language (e.g., conversational speech about
objects and events in the here-and-now in limited social contexts) and strive for "vertically integrated"
computational models. I will present experiments guided by this strategy in building conversational robots and
natural language interfaces for video games. An emerging framework suggests a semiotic perspective may be useful
for designing systems that process language grounded in social and physical context.
</p>
<h4>About the speaker:</h4>
<p>
Deb Roy is Associate Professor of Media Arts and Sciences at the Massachusetts Institute of Technology. He is
Director of the Cognitive Machines Group at the MIT Media Laboratory which he founded in 2000. Roy also directs
the 10x research program, a lab-wide effort to design new technologies for enhancing human cognitive and physical
capabilities. Roy has published numerous peer-reviewed papers in the areas of knowledge representation, speech and
language processing, machine perception, robotics, information retrieval, cognitive modeling, and human-machine
interaction, and has served as guest editor of the journal Artificial Intelligence. He has lectured widely in
academia and industry. His work has been featured in various popular press venues including the New York Times,
the Globe and Mail, CNN, BBC, and PBS. In 2003 Roy was appointed AT&T Career Development Professor. He holds a
B.A.Sc. in Computer Engineering from University of Waterloo, and a Ph.D. in Media Arts and Sciences from MIT.
</p>
</td>    
</tr>


<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Thursday, Sep. 7, 3:30pm<br><br>
  Coffee at 3:15pm<br><br>
    ACES 2.302, Avaya Auditorium</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Sep8">Behind the Scenes with Blondie24: Evolving Intelligence in Checkers
and Chess</a></h4>
        <h4>Dr. David Fogel &nbsp;&nbsp;[<a href="http://www.natural-selection.com/people_dfogel.html">homepage</a>] <br><br>
	Chief Executive Officer<br>
	Natural Selection, Inc.</h4>
 <p><h4>
      [<a
     href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=DavidFogel">Sign-up
     schedule for individual meetings</a>]
     </h4>
<p>
Blondie24 is a self-learning checks program that taught itself to play at
the level of human experts. Starting with only rudimentary information about
the location, number, and types of checkers pieces on the board, Blondie24
learned to play well enough to be ranked in the top 500 of 120,000 checkers
players registered at Microsoft's zone.com. The program uses a simple
evolutionary algorithm to optimize neural networks as board evaluators. Any
sophisticated features used to interpret the positions of pieces were
invented within the neural network. Furthermore, the evolving neural
networks were not told whether they won, lost, or drew any specific game;
instead, the only feedback they received was a point score associated with
an overall result of playing a random number of games. In so doing, the line
of research addressed two fundamental issues raised by Arthur Samuel and
Allen Newell over three decades ago: Can a computer invent features in
checkers and can a computer learn how play without receiving explicit credit
assignment? A similar process has also been applied to chess (Blondie25).
Starting with an open source program rated about 1800 (Class A), the evolved
program has demonstrated grandmaster-level performance. The lecture will
provide motivation and technical details for this research, as well as offer
materials not found in any technical or book treatments of the development.
Attendees will be able to challenge Blondie to a game, if they like.
</p>
<h4>About the speaker:</h4>
<p>
Dr. David Fogel is chief executive officer of Natural Selection, Inc. in La
Jolla, California. Dr. Fogel has over 200 technical publications and 6
books, including Blondie24: Playing at the Edge of AI (Morgan Kaufmann,
2002) and How to Solve It: Modern Heuristics (with Zbigniew Michalewicz, 2nd
ed., Springer 2005, translated into Chinese and Polish). Among many
leadership roles, Dr. Fogel was the founding editor-in-chief of the IEEE
Transactions on Evolutionary Computation (1996-2002), general chairman for
the 2002 IEEE World Congress on Computational Intelligence, and will chair
the upcoming 2007 IEEE Symposium Series in Computational Intelligence to be
held April 1-5, 2007 in Honolulu, Hawaii. He was elected a Fellow of the
IEEE in 1999 and received the 2004 IEEE Kiyo Tomiyasu Technical Field Award.
He was elected president-elect of the IEEE Computational Intelligence
Society for 2007.
</p>
</td>    
</tr>

<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Friday, November 3, 3:00pm<br><br>
  Coffee at 2:45pm<br><br>
    ACES 2.402</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Nov3"></a>Search Methods for Finding Optimal Graph Topologies</h4>
        <h4>Dr. Matthew Campbell &nbsp;&nbsp;[<a href="http://www.me.utexas.edu/~campbell/index.htm">homepage</a>] <br><br>
	Mechanical Engineering<br>
        University of Texas at Austin</h4>
 <p><h4>
<!--      [<a -->
<!--      href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=WilliamW.Cohen">Sign-up -->
<!--      schedule for individual meetings</a>]  -->
     </h4>
<p>
This research offers a fundamental new view of topology
optimization. To date, topological synthesis approaches are simply
augmentations of existing stochastic optimization techniques. The
generic approach defined here combines aspects of existing
optimization techniques, graph theory, mathematical programming,
artificial intelligence, and shape and graph grammars. Graph
transformation research has existed for nearly 40 years in an esoteric
corner of artificial intelligence but only recently has the work been
deemed useful in design automation as knowledge and heuristics of a
particular problem domain can be encapsulated into rules. In this
presentation, various example problems are presented that are in the
process of being solved by these newly defined search methods.
</p>
<h4>About the speaker:</h4>
<p>
Dr. Campbell joined the Department of Mechanical Engineering at the
University of Texas at Austin in 2000, and is currently an Associate
Professor in the Manufacturing and Design area. His research focuses
on computational methods that aid the engineering designer earlier in
the design process than traditional optimization would. To date, he
has been awarded $1.57 million in research funding, including the
CAREER award for research into a generic graph topology optimization
method. This research represents a culmination of past computational
synthesis research including the automatic design of sheet metal
components, multi-stable MEMS devices, MEMS resonators, function
structures, and electro-mechanical configurations. Dr. Campbell is a
member of the AAAI, the AIAA, Phi Kappa Phi Honor Society, Pi Tau
Sigma Mechanical Engineering Honorary Fraternity, the ASME, the ASEE,
and the Design Society and has been acknowledged with best paper
awards at conferences sponsored by the latter three.
</p>
</td>    
</tr>

<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Friday, November 10, 11:00am<br><br>
  Coffee at 10:45am<br><br>
    ACES 2.402</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Nov10"></a>Automatic meaning analysis of free text: small steps towards a big goal</h4>
        <h4>Dr. Katrin Erk &nbsp;&nbsp;[<a href="http://comp.ling.utexas.edu/erk/">homepage</a>] <br><br>
	Department Of Linguistics<br>
        University of Texas at Austin</h4>
 <p><h4>
<!--      [<a -->
<!--      href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=WilliamW.Cohen">Sign-up -->
<!--      schedule for individual meetings</a>]  -->
     </h4>
<p>
Viewed as a whole, the problem of doing an automatic meaning analysis
of free text is huge. But maybe the problem can be carved up in more
manageable pieces: Recently several approaches to an
automatic predicate-argument structure analysis have been proposed,
what has been called a ``who does what to whom'' analysis. This can be
seen as a first building block in a modular meaning analysis (where
other, very much necessary, building blocks would include negation and
modals). It is an important building block, which focuses on lexical
semantics and on the link to semantic taxonomies -- and a building
block that has recently become much more accessible, with the
availability of manually annotated corpora.
<br>
In this talk I first take a closer look at the data for
predicate-argument structure, from the viewpoint of a manual
annotation effort, where we annotated a German corpus with
FrameNet-style information. I then present a system for automatic
predicate-argument structure analysis, its architecture and the
statistical modeling for its subtasks. Lastly, I discuss a study on
cross-lingual semantic analysis  -- which opens up the possibility of
deriving cross-lingual paraphrases.

</p>
<h4>About the speaker:</h4>
<p>
Katrin Erk is an assistant professor in the Department of Linguistics
at the University of Texas at Austin. She completed her dissertation
on tree description languages at Saarland University in 2002, advised
by Gert Smolka. From 2002 to 2006, she held a researcher position in
Saarbruecken working with Manfred Pinkal. Her current work includes
research on machine learning methods for semantic analysis, the
acquisition of lexical information from corpora, manual semantic
annotation, the detection of multiword expression, and computational
models for word sense.
</p>
</td>    
</tr>


<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Wednesday, November 29, 2:00pm<br><br>
  Coffee at 1:45pm<br><br>
    ACES 2.402</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Nov29"></a>Life in the Machine: The Evolution of Novel Complexity in Digital Organisms</h4>
        <h4>Dr. Charles Ofria &nbsp;&nbsp;[<a href="http://www.cse.msu.edu/~ofria/">homepage</a>] <br><br>
	Computer Science and Engineering<br>
	Michigan State University</h4>
 <p><h4>
     [<a
     href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=CharlesOfria">Sign-up
     schedule for individual meetings</a>]
     </h4>
<p>
When Darwin first proposed his theory of evolution by natural selection, he
realized that it had a problem explaining the origins of traits of "extreme
perfection and complication" such as the vertebrate eye.  Over the years,
critics of Darwin's theory have latched onto this perceived flaw as proof
that Darwinian evolution is impossible.  In anticipation of this issue,
Darwin described the perfect data needed to understanding this process, but
lamented that such data are "scarcely ever possible" to obtain.  In this
talk, I will discuss research where we use digital organisms (populations of
self-replicating and evolving computer programs) to elucidate the process by
which new, highly-complex traits arise, drawing inspiration directly from
Darwin's wistful thinking and hypotheses.  I will also explore some of the
implications of this research to other aspects of evolutionary biology and
new ways that these evolutionary principles can be applied toward solving
computational problems.
</p>
<h4>About the speaker:</h4>
<p>
Dr. Charles Ofria is an assistant professor at Michigan State University in
the Computer Science Department and the Ecology, Evolutionary Biology, and
Behavior Program.  He has a heavily multidisciplinary background, receiving
a PhD from the Computation and Neural Systems department at Caltech under
physicist Chris Adami, then doing a postdoc for three years in the Microbial
Ecology program at MSU under biologist Richard Lenski.  He is now the
director of the MSU Digital Evolution Lab, a multidisciplinary group using
digital organisms to answer fundamental questions in evolutionary biology
and harnessing the results to solve more applied computational problems.
Please see http://devolab.cse.msu.edu/ for more information.
</p>
</td>    
</tr>

<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Friday, December 8, 11:00am<br><br>
  Coffee at 10:45am<br><br>
    ACES 2.402</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Dec8"></a>Machine Learning in Web 2.0: Analyzing Dynamic Content-driven Social 
Networks</h4>
        <h4>Dr. Sugato Basu &nbsp;&nbsp;[<a href="http://www.ai.sri.com/people/basu/">homepage</a>] <br><br>
	SRI International<br>
        Menlo Park, CA</h4>
 <p><h4>
     [ <a 
      href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=SugatoBasu(2)">Sign-up 
      schedule for individual meetings</a>] 
     </h4>
<p>
In the last decade, machine learning and data mining techniques have seen 
widespread successful application to different Internet technologies, 
including web search, product recommendation, spam detection, spelling 
correction, and news clustering. However, the web is fast undergoing a 
paradigm shift, moving from being a mechanism for delivering static 
web-content in the existing Web 1.0 model to a platform facilitating 
dynamic collaborative content creation in the emerging Web 2.0 paradigm. 
This trend is reflected in the growing popularity of new social 
web-services, for example, tagging (Flickr) compared to photo editing 
(Ofoto), and blogging (Blogger) compared to homepage hosting (Geocities).
<br>
This talk will outline how this new emphasis on rapid creation and sharing 
of consumer-generated data (CGM) over large social networks has given rise 
to dynamic content-driven social networks, and a new set of challenging 
machine learning problems in this context. Focusing on a project (iLink) 
that the speaker is currently working on, the talk will discuss research 
problems like online learning of topic models over streaming text, 
large-scale topic analysis over social networks, and learning to route 
messages in a social query model.
</p>
<h4>About the speaker:</h4>
<p>
Sugato Basu works on machine learning, data mining, information retrieval, 
statistical pattern recognition and optimization, with applications to 
analysis of text data and social networks on the web.  He did his PhD from 
UT Austin in 2005, and is now a research scientist at the AI Center in SRI 
International. For more information: http://www.ai.sri.com/people/basu/
</p>
</td>    
</tr>

<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Friday, February 9, 11:00am<br><br>
  Coffee at 10:45am<br><br>
    ACES 2.402 </h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Feb9"></a>Which Supervised Learning Method Works Best for What?<br>
An Empirical Comparison of Learning Methods and Metrics++</h4>
        <h4>Dr. Rich Caruana &nbsp;&nbsp;[<a href="http://www.cs.cornell.edu/~caruana/">homepage</a>] <br><br>
	Cornell University
        </h4>
 <p><h4>
     [<a 
      href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=Dr.RichCaruana">Sign-up
      schedule for individual meetings</a>]  
     </h4>
<p>
Decision trees are intelligible, but do they perform well enough that
you should use them?  Have SVMs replaced neural nets, or are neural
nets still best for regression, and SVMs best for classification?
Boosting maximizes margins similar to SVMs, but can boosting compete
with SVMs?  And if it does compete, is it better to boost weak models,
as theory might suggest, or to boost stronger models?  Bagging is
simpler than boosting -- how well does bagging stack up against
boosting?  Breiman said Random Forests are better than bagging and as
good as boosting.  Was he right?  And what about old friends like
logistic regression, KNN, and naive bayes?  Should they be relegated
to the history books, or do they still fill important niches?</p>

<p>In this talk we compare the performance of these supervised learning
methods on a number of preformaance criteria: Accuracy, F-score, Lift,
Precision/Recall Break-Even Point, Area under the ROC, Average
Precision, Squared Error, Cross-Entropy, and Probability Calibration.
The results show that no one learning method does it all, but some
methods can be "repaired" so that they do very well across all
performance metrics.  In particular, we show how to obtain the best
probabilities from max margin methods such as SVMs and boosting via
Platt's Method and isotonic regression.  We then describe a new
ensemble method that combines select models from these ten learning
methods to yield much better performance.  Although these ensembles
perform extremely well, they are too complex for many applications.
We'll describe a model compression method we are developing to fix
that.  Finally, if time permits, we'll discuss how the performance
metrics relate to each other, and which of them you probably should
(or shouldn't) use.
</p>
<h4>About the speaker:</h4>
<p>
Rich Caruana obtained his Ph.D. in computer science from Carnegie
Mellon University in 1998.  His current research focus is on ensemble
learning, model calibration, inductive transfer, and adaptive
clustering, and applications of these methods to problems in medical
decision making and bioinformatics.  In 2000 Caruana led a team that
developed the first automated system for the early detection of
bioterrorist releases of anthrax.  The system applies data mining to
consumer purchases in supermarkets to look for unexplained increases
in the sales of products such as cough syrup.  Because consumers tend
to self-medicate using easily available products such as cough syrup
and throat lozenges before consulting physicians, the system can
detect the onset of flu-like symptoms 24-48 hours before these can be
detected by visits to hospitals and doctors offices.  A theme that
runs through all of Professor Caruana's work is the importance of
developing methods that are effective on real-world problems. He likes
to mix algorithm development with applications work to insure that the
methods he develops are useful in practice.
</p>
</td>    
</tr>


<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Thursday, February 15, 2:00pm<br><br>
  Coffee at 1:45pm<br><br>
    ACES 2.402 </h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Feb15"></a>Bayesian Inference of Grammars</h4>
        <h4>Dr. Mark Johnson &nbsp;&nbsp;[<a href="http://www.cog.brown.edu/~mj/">homepage</a>] <br><br>
	Brown University
        </h4>
 <p><h4>
     [<a 
     href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=Dr.MarkJohnson">Sign-up 
      schedule for individual meetings</a>]  
     </h4>
<p>
Even though Maximum Likelihood Estimation (MLE) of Probabilistic
  Context-Free Grammars (PCFGs) is well-understood (the Inside-Outside
  algorithm can do this efficiently from the terminal strings alone) the
  inferred grammars are usually linguistically inaccurate.  In order to
  better understand why maximum likelihood finds poor grammars, this
  talk examines two simple natural language induction problems:
  morphological segmentation and word segmentation.  We identify several
  problems with the MLE PCFG models of these problems and propose
  Hierarchical Dirichlet Process (HDP) models to overcome them.  In
  order to test these HDP models we develop MCMC algorithms for Bayesian
  inference of these models from strings alone.  Finally, we discuss to
  what extent the lessons learnt from these examples can be put into a
  unified framework and applied to the general problem of grammar
  induction.
<br>
  Joint work with Sharon Goldwater and Tom Griffiths.
</p>
<h4>About the speaker:</h4>
<p>
Mark Johnson is a Professor of Cognitive and Linguistic Science and Computer Science at Brown University and a Visiting Researcher in the Natural Language group at Microsoft Research for 2006--2007. He was awarded a BSc (Hons) in 1979 from the University of Sydney, an MA in 1984 from the University of California, San Diego and a PhD in 1987 from Stanford University. He held a postdoctoral fellowship at MIT from 1987 until 1988, and has been a visiting researcher at the University of Stuttgart, the Xerox Research Centre in Grenoble and CSAIL at MIT. He has worked on a wide range of topics in computational linguistics, but his main research area is parsing and its applications to text and speech processing. He was President of the Association for Computational Linguistics in 2003.
</p>
</td>    
</tr>

<tr>
 <td bgcolor="#6666FF" valign="top">
  <div align="center">
   <h4>Friday, February 23, 11:00am<br><br>
  Coffee at 10:45am<br><br>
    ACES 2.302 (Avaya)</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top">
     <h4><a name="Feb23"></a>Additive Pattern Database Heuristics</h4>
        <h4>Dr. Robert Holte &nbsp;&nbsp;[<a href="http://www.cs.ualberta.ca/~holte/">homepage</a>] <br><br>
	University of Alberta
        </h4>
 <p><h4>
      [<a 
     href="http://www.cs.utexas.edu/department/webevent/utcs/events/cgi/show_schedule.cgi?person=Dr.RobertHolte">Sign-up 
      schedule for individual meetings</a>]  
     </h4>
<p>
This research studies heuristic functions defined by abstractions, where
the distance from a state S to the goal state is estimated with the true
distance from the abstract state corresponding to S to the abstract
goal state.  When precomputed and stored as lookup tables, such heuristics
are called pattern databases (PDBs), and are the most powerful heuristics
known for many problems.<br>
The question addressed in this presentation is: under what conditions is the
sum of several PDB heuristic functions admissible (guaranteed never
to overestimate a distance) ?<br>
This question has previously been addressed by Felner, Korf, and Hanan in
a 2004 JAIR paper.  Our work generalizes their answer, greatly enlarging
the types of search spaces for which admissible additive heuristics can
be defined.  Experimental results on the Pancake puzzle show that
well-chosen additive PDBs reduce solution time by three orders of magnitude
over the best published results for this puzzle.  We also show that additive
PDBs are not always superior to taking the maximum over heuristics based
on the same abstractions.<br>
The presentation assumes basic knowledge of heuristic search, but does not
require any knowledge of pattern databases.
</p>
<h4>About the speaker:</h4>
<p>
Professor Robert Holte is a well-known member of the international machine learning research community, former editor-in-chief of the leading international journal in this field (Machine Learning), and current director of the Alberta Ingenuity Centre for Machine Learning. His main scientific contributions are his seminal works on the problem of small disjuncts and the performance of very simple classification rules. His current machine learning research investigates cost-sensitive learning and learning in game-playing (for example: opponent modelling in poker, and the use of learning for gameplay analysis of commercial computer games). In addition to machine learning he undertakes research in single-agent search (pathfinding): in particular, the use of automatic abstraction techniques to speed up search. He has over 55 scientific papers to his credit, covering both pure and applied research, and has served on the steering committee or program committee of numerous major international AI conferences.
</p>
</td>    
</tr>


</tbody>
</table>
<h2>Past Schedules</h2>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2005-2006.html">Fall 2005 - Spring 2006</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2005-spring.html">Spring 2005</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2004-fall.html">Fall 2004</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2004-spring.html">Spring 2004</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2003-fall.html">Fall 2003</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2003-spring.html">Spring 2003</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2002-fall.html">Fall 2002</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2002-spring.html">Spring 2002</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2001-fall.html">Fall 2001</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2001-spring.html">Spring 2001</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2000-fall.html">Fall 2000</a></p>
<p><a href="http://www.cs.utexas.edu/users/ai-lab/fai/2000-spring.html">Spring 2000</a></p>
<!-- <p><b>fai</b> (fA) <i>n. Archaic. </i>[Middle English]: Faith.</p> -->
</div>
</body>
</html>


<!--  
<tr> 
 <td bgcolor="#6666FF" valign="top"> 
  <div align="center"> 
   <h4>DATE<br><br>
  Coffee at <br><br>
   LOCATION</h4>
   </h4>
</div>
</td>
  <td bgcolor="#333366" valign="top"> 
     <h4><a name="ANCHOR"></a>TITLE</h4>
        <h4>Dr. NAME &nbsp;&nbsp;[<a href="http://">homepage</a>]<br>
 AFFILIATION#1<br>
 AFFILIATION#2</h4>
<p><h4>
      [<a
     href="http://www.cs.utexas.edu/users/UTCS/webevent/utcs/events/cgi/show_schedule.cgi?person=">Sign-up
     schedule for individual meetings</a>]
     </h4>
<p>
ABSTRACT
</p>

		<h4>About the speaker:</h4>
<p>

</p>
      </td>
    </tr>
-->


