<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta name=Title content=References>
<meta name=Keywords content="">
<meta http-equiv=Content-Type content="text/html; charset=macintosh">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 10">
<meta name=Originator content="Microsoft Word 10">
<link rel=File-List href="http://www.clir.org/pubs/reports/trant04/trantrefs_files/filelist.xml">
<title>References</title>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>J. Trant</o:Author>
  <o:Template>Normal</o:Template>
  <o:LastAuthor>Brian Leney</o:LastAuthor>
  <o:Revision>2</o:Revision>
  <o:LastPrinted>2004-02-10T18:09:00Z</o:LastPrinted>
  <o:Created>2004-02-10T18:28:00Z</o:Created>
  <o:LastSaved>2004-02-10T18:28:00Z</o:LastSaved>
  <o:Pages>3</o:Pages>
  <o:Words>18795</o:Words>
  <o:Characters>107132</o:Characters>
  <o:Company>Archives &amp; Museum Informatics</o:Company>
  <o:Lines>892</o:Lines>
  <o:Paragraphs>214</o:Paragraphs>
  <o:CharactersWithSpaces>131565</o:CharactersWithSpaces>
  <o:Version>10.260</o:Version>
 </o:DocumentProperties>
</xml><![endif]-->
<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:Zoom>150</w:Zoom>
  <w:TrackRevisions/>
  <w:DoNotShowRevisions/>
  <w:DoNotPrintRevisions/>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:DisplayVerticalDrawingGridEvery>0</w:DisplayVerticalDrawingGridEvery>
  <w:UseMarginsForDrawingGridOrigin/>
 </w:WordDocument>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:"Times New Roman";
	panose-1:0 2 2 6 3 5 4 5 2 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Arial;
	panose-1:0 2 11 6 4 2 2 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Courier New";
	panose-1:0 2 7 3 9 2 2 5 2 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Geneva;
	panose-1:0 2 11 5 3 3 4 4 4 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Tms Rmn";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:77;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Helv;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:77;
	mso-generic-font-family:swiss;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"MS Serif";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:77;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"MS Sans Serif";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:77;
	mso-generic-font-family:swiss;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"New York";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:77;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:System;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:77;
	mso-generic-font-family:swiss;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Wingdings;
	panose-1:0 5 2 1 2 1 8 4 8 7;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 16 0 0 -2147483648 0;}
@font-face
	{font-family:"\FF2D\FF33 \660E\671D";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:fixed;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:"\FF2D\FF33 \30B4\30B7\30C3\30AF";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-format:other;
	mso-font-pitch:fixed;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:Century;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:77;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Verdana;
	panose-1:0 2 11 6 4 3 5 4 4 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:AGaramond;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"American Typewriter";
	panose-1:0 2 9 6 4 2 0 4 2 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"American Typewriter Condensed";
	panose-1:0 2 9 6 6 2 0 4 2 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"American Typewriter Light";
	panose-1:0 2 9 3 4 2 0 4 2 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Arial Black";
	panose-1:0 2 11 10 4 2 1 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Arial Narrow";
	panose-1:0 2 11 5 6 2 2 2 3 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Arial Rounded MT Bold";
	panose-1:0 2 15 7 4 3 5 4 3 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"B Palatino Bold";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Baskerville;
	panose-1:0 2 2 5 2 7 4 1 2 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Baskerville Semibold";
	panose-1:0 2 2 7 2 7 4 0 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"BI Palatino BoldItalic";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Big Caslon";
	panose-1:0 2 0 6 3 9 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Brush Script MT";
	panose-1:0 3 6 8 2 4 4 6 7 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Chalkboard;
	panose-1:0 3 5 6 2 4 2 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Chicago;
	panose-1:0 2 11 8 6 8 6 4 4 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Cochin;
	panose-1:0 2 0 6 3 2 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Comic Sans MS";
	panose-1:0 3 15 7 2 3 3 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Copperplate;
	panose-1:0 2 0 5 4 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Copperplate Light";
	panose-1:0 2 0 6 4 3 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Didot;
	panose-1:0 2 0 5 3 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Futura;
	panose-1:0 2 11 6 2 2 2 4 2 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Futura Condensed";
	panose-1:0 2 11 5 6 2 2 4 3 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Georgia;
	panose-1:0 2 4 5 2 5 4 5 2 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Gill Sans";
	panose-1:0 2 11 5 2 2 1 4 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Gill Sans Light";
	panose-1:0 2 11 3 2 2 1 4 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Helvetica Neue";
	panose-1:0 2 0 5 3 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Helvetica Neue Black Condensed";
	panose-1:0 2 0 10 6 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Helvetica Neue Bold Condensed";
	panose-1:0 2 0 8 6 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Helvetica Neue Light";
	panose-1:0 2 0 4 3 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Helvetica Neue UltraLight";
	panose-1:0 2 0 2 6 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Herculanum;
	panose-1:0 2 0 5 5 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"I Palatino Italic";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Lucida Grande";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Marker Felt";
	panose-1:0 2 0 4 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Minion BoldCondensed";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Minion BoldCondensedItalic";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Minion Condensed";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Minion CondensedItalic";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Minion Ornaments";
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 16 0 0 -2147483648 0;}
@font-face
	{font-family:Monaco;
	panose-1:0 2 0 5 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Optima;
	panose-1:0 2 0 5 3 6 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Optima ExtraBlack";
	panose-1:0 2 0 11 3 0 0 0 2 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Palatino;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Palatino BoldItalicOsF";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Palatino BoldOsF";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Palatino ItalicOsF";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Palatino SC";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Papyrus;
	panose-1:0 2 11 6 2 4 2 0 2 3;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Skia;
	panose-1:0 2 13 5 2 2 2 4 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Stencil;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Trebuchet MS";
	panose-1:0 2 11 6 3 2 2 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Webdings;
	panose-1:0 5 3 1 2 1 5 9 6 7;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 16 0 0 -2147483648 0;}
@font-face
	{font-family:"Zapf Dingbats";
	panose-1:0 5 2 1 2 1 7 4 2 6;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 16 0 0 -2147483648 0;}
@font-face
	{font-family:Zapfino;
	panose-1:0 3 3 3 2 4 7 7 7 12;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:"Courier CE";
	panose-1:0 2 0 5 0 0 0 0 0 0;
	mso-font-charset:88;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:83886080 0 0 0 2 0;}
@font-face
	{font-family:"Geneva CE";
	panose-1:0 2 11 5 3 3 4 4 4 2;
	mso-font-charset:88;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:83886080 0 0 0 2 0;}
@font-face
	{font-family:"Helvetica CE";
	panose-1:0 2 0 5 0 0 0 0 0 0;
	mso-font-charset:88;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:83886080 0 0 0 2 0;}
@font-face
	{font-family:"Monaco CE";
	panose-1:0 2 0 5 0 0 0 0 0 0;
	mso-font-charset:88;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:83886080 0 0 0 2 0;}
@font-face
	{font-family:"Times CE";
	panose-1:0 2 0 5 0 0 0 0 0 0;
	mso-font-charset:88;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:83886080 0 0 0 2 0;}
@font-face
	{font-family:"Apple LiGothic Medium";
	panose-1:0 2 0 5 0 0 0 0 0 0;
	mso-font-charset:81;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 2056 268435456 0 1048576 0;}
@font-face
	{font-family:Taipei;
	mso-font-charset:81;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 2056 268435456 0 1048576 0;}
@font-face
	{font-family:Beijing;
	mso-font-charset:80;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 3592 268435456 0 262144 0;}
@font-face
	{font-family:Hei;
	panose-1:0 2 0 5 0 0 0 0 0 0;
	mso-font-charset:80;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 3592 268435456 0 262144 0;}
@font-face
	{font-family:\534E\6587\9ED1\4F53;
	mso-font-charset:80;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 3592 268435456 0 262144 0;}
@font-face
	{font-family:\534E\6587\7EC6\9ED1;
	mso-font-charset:80;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 3592 268435456 0 262144 0;}
@font-face
	{font-family:Osaka;
	panose-1:0 2 11 6 0 0 0 0 0 0;
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:Osaka\2212\7B49\5E45;
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:"\30D2\30E9\30AE\30CE\89D2\30B4 Pro W3";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:"\30D2\30E9\30AE\30CE\89D2\30B4 Pro W6";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:"\30D2\30E9\30AE\30CE\89D2\30B4 Std W8";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:"\30D2\30E9\30AE\30CE\4E38\30B4 Pro W4";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:"\30D2\30E9\30AE\30CE\660E\671D Pro W3";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:"\30D2\30E9\30AE\30CE\660E\671D Pro W6";
	mso-font-charset:78;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1800 268435456 0 131072 0;}
@font-face
	{font-family:AppleGothic;
	panose-1:0 2 0 5 0 0 0 0 0 0;
	mso-font-charset:79;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:16777216 1545 268435456 0 524288 0;}
@font-face
	{font-family:"Arial Unicode MS";
	mso-font-alt:Times;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1 -369098753 63 0 4129023 0;}
@font-face
	{font-family:Charcoal;
	mso-font-alt:Times;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:50331648 0 0 0 1 0;}
@font-face
	{font-family:Marlett;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:AGaramond;}
h1
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-indent:0in;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	mso-list:l0 level1 lfo21;
	tab-stops:list 0in;
	font-size:10.0pt;
	font-family:Helvetica;
	mso-font-kerning:14.0pt;
	font-weight:bold;}
h2
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-indent:0in;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:2;
	mso-list:l0 level2 lfo21;
	tab-stops:list 0in;
	font-size:10.0pt;
	font-family:Helvetica;
	font-weight:bold;}
h3
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-indent:0in;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:3;
	mso-list:l0 level3 lfo21;
	tab-stops:list .25in;
	font-size:9.0pt;
	font-family:Helvetica;
	font-weight:bold;}
h4
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-indent:.25in;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:4;
	mso-list:l0 level4 lfo21;
	tab-stops:list .5in;
	font-size:9.0pt;
	font-family:Helvetica;
	font-weight:bold;}
h5
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-indent:0in;
	mso-pagination:widow-orphan;
	mso-outline-level:5;
	mso-list:l0 level5 lfo21;
	tab-stops:list 0in;
	font-size:10.0pt;
	font-family:AGaramond;
	font-weight:normal;}
h6
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-indent:0in;
	mso-pagination:widow-orphan;
	mso-outline-level:6;
	mso-list:l0 level6 lfo21;
	tab-stops:list 0in;
	font-size:10.0pt;
	font-family:AGaramond;
	font-weight:normal;
	font-style:italic;}
p.MsoHeading7, li.MsoHeading7, div.MsoHeading7
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-indent:0in;
	mso-pagination:widow-orphan;
	mso-outline-level:7;
	mso-list:l0 level7 lfo21;
	tab-stops:list 0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoHeading8, li.MsoHeading8, div.MsoHeading8
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-indent:0in;
	mso-pagination:widow-orphan;
	mso-outline-level:8;
	mso-list:l0 level8 lfo21;
	tab-stops:list 0in;
	font-size:10.0pt;
	font-family:AGaramond;
	font-style:italic;}
p.MsoHeading9, li.MsoHeading9, div.MsoHeading9
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-indent:0in;
	mso-pagination:widow-orphan;
	mso-outline-level:9;
	mso-list:l0 level9 lfo21;
	tab-stops:list 0in;
	font-size:9.0pt;
	font-family:AGaramond;
	font-style:italic;}
p.MsoToc1, li.MsoToc1, div.MsoToc1
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoToc2, li.MsoToc2, div.MsoToc2
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:10.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoToc3, li.MsoToc3, div.MsoToc3
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:20.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoToc4, li.MsoToc4, div.MsoToc4
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:30.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoToc5, li.MsoToc5, div.MsoToc5
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:40.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoToc6, li.MsoToc6, div.MsoToc6
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:50.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoToc7, li.MsoToc7, div.MsoToc7
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:60.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoToc8, li.MsoToc8, div.MsoToc8
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:70.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoToc9, li.MsoToc9, div.MsoToc9
	{mso-style-update:auto;
	mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:80.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:right dotted 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoNormalIndent, li.MsoNormalIndent, div.MsoNormalIndent
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	margin-bottom:.0001pt;
	text-indent:-.5in;
	mso-pagination:widow-orphan;
	font-size:9.0pt;
	font-family:AGaramond;}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:center 3.0in right 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoFooter, li.MsoFooter, div.MsoFooter
	{margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:center 3.0in right 6.0in;
	font-size:10.0pt;
	font-family:AGaramond;}
span.MsoFootnoteReference
	{vertical-align:super;}
span.MsoEndnoteReference
	{vertical-align:super;}
p.MsoEndnoteText, li.MsoEndnoteText, div.MsoEndnoteText
	{margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:AGaramond;}
p.MsoTitle, li.MsoTitle, div.MsoTitle
	{margin:0in;
	margin-bottom:.0001pt;
	text-align:center;
	mso-pagination:widow-orphan;
	tab-stops:right -121.5pt left .5in 1.0in 1.5in right 423.0pt 427.5pt;
	font-size:12.0pt;
	font-family:Helvetica;
	font-weight:bold;}
p.MsoBodyTextIndent, li.MsoBodyTextIndent, div.MsoBodyTextIndent
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:.25in;
	mso-pagination:widow-orphan;
	tab-stops:.5in 1.0in 1.5in 2.0in;
	font-size:10.0pt;
	font-family:AGaramond;
	mso-ansi-language:EN-GB;}
p.MsoListContinue, li.MsoListContinue, div.MsoListContinue
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:.25in;
	mso-pagination:widow-orphan;
	tab-stops:.5in 1.0in 1.5in 2.0in;
	font-size:10.0pt;
	font-family:AGaramond;
	mso-ansi-language:EN-GB;}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;
	text-underline:single;}
a:visited, span.MsoHyperlinkFollowed
	{color:purple;
	text-decoration:underline;
	text-underline:single;}
p
	{margin-right:0in;
	mso-margin-top-alt:auto;
	mso-margin-bottom-alt:auto;
	margin-left:0in;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Arial Unicode MS";}
span.arial2
	{mso-style-name:arial2;}
span.arialtitle
	{mso-style-name:arialtitle;}
p.definition, li.definition, div.definition
	{mso-style-name:definition;
	margin-right:0in;
	mso-margin-top-alt:auto;
	mso-margin-bottom-alt:auto;
	margin-left:0in;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Arial Unicode MS";}
p.sp, li.sp, div.sp
	{mso-style-name:sp;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-indent:.5in;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:Arial;}
p.ReferencesText, li.ReferencesText, div.ReferencesText
	{mso-style-name:"References Text";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:AGaramond;}
ins
	{mso-style-type:export-only;
	text-decoration:none;}
span.msoDel
	{mso-style-type:export-only;
	mso-style-name:"";
	text-decoration:line-through;
	display:none;
	color:red;}
@page Section1
	{size:8.5in 11.0in;
	margin:1.0in 76.5pt 1.0in 1.25in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-even-header:url(":trantrefs_files:header.htm") eh1;
	mso-header:url(":trantrefs_files:header.htm") h1;
	mso-even-footer:url(":trantrefs_files:header.htm") ef1;
	mso-footer:url(":trantrefs_files:header.htm") f1;
	mso-first-header:url(":trantrefs_files:header.htm") fh1;
	mso-first-footer:url(":trantrefs_files:header.htm") ff1;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
 /* List Definitions */
@list l0
	{mso-list-id:-5;
	mso-list-template-ids:1603066824;}
@list l0:level1
	{mso-level-style-link:"Heading 1";
	mso-level-tab-stop:0in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:0in;}
@list l0:level2
	{mso-level-style-link:"Heading 2";
	mso-level-text:"%1\.%2";
	mso-level-tab-stop:0in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:0in;}
@list l0:level3
	{mso-level-number-format:none;
	mso-level-style-link:"Heading 3";
	mso-level-text:"";
	mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:0in;}
@list l0:level4
	{mso-level-number-format:none;
	mso-level-style-link:"Heading 4";
	mso-level-text:"";
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:.25in;}
@list l0:level5
	{mso-level-style-link:"Heading 5";
	mso-level-text:"%1\.%2\.%3\.%4\.%5";
	mso-level-tab-stop:0in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:0in;}
@list l0:level6
	{mso-level-style-link:"Heading 6";
	mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6";
	mso-level-tab-stop:0in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:0in;}
@list l0:level7
	{mso-level-style-link:"Heading 7";
	mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7";
	mso-level-tab-stop:0in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:0in;}
@list l0:level8
	{mso-level-style-link:"Heading 8";
	mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7\.%8";
	mso-level-tab-stop:0in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:0in;}
@list l0:level9
	{mso-level-style-link:"Heading 9";
	mso-level-text:"%1\.%2\.%3\.%4\.%5\.%6\.%7\.%8\.%9";
	mso-level-tab-stop:0in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:0in;}
@list l1
	{mso-list-id:6835567;
	mso-list-type:hybrid;
	mso-list-template-ids:-983526412 -1055365910 783575740 -1566564162 2004640586 452617398 -1510458766 -493578172 -831729406 1207743396;}
@list l1:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l2
	{mso-list-id:114839453;
	mso-list-type:hybrid;
	mso-list-template-ids:-341156510 1223096264 865220224 1943063070 -37846866 -938999492 1571457628 -1762730968 1423889806 -1262731872;}
@list l2:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l3
	{mso-list-id:161239225;
	mso-list-type:hybrid;
	mso-list-template-ids:-1536939178 -603708842 197641 328713 66569 197641 328713 66569 197641 328713;}
@list l3:level1
	{mso-level-start-at:0;
	mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:26.0pt;
	mso-level-number-position:left;
	margin-left:26.0pt;
	text-indent:-.25in;
	font-family:Symbol;}
@list l4
	{mso-list-id:170490142;
	mso-list-type:hybrid;
	mso-list-template-ids:-278775554 905501324 197641 328713 66569 197641 328713 66569 197641 328713;}
@list l4:level1
	{mso-level-start-at:0;
	mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:26.0pt;
	mso-level-number-position:left;
	margin-left:26.0pt;
	text-indent:-.25in;
	font-family:Symbol;}
@list l5
	{mso-list-id:178398741;
	mso-list-type:hybrid;
	mso-list-template-ids:1676605800 -1969040030 -630786928 1443113996 -2135135114 -1620306044 1322291424 1253310596 1598051138 2036640610;}
@list l5:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l6
	{mso-list-id:277953020;
	mso-list-type:hybrid;
	mso-list-template-ids:1694367964 66569 197641 328713 66569 197641 328713 66569 197641 328713;}
@list l6:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:0in;
	mso-level-number-position:left;
	margin-left:0in;
	text-indent:-.25in;
	font-family:Symbol;}
@list l7
	{mso-list-id:289366565;
	mso-list-type:hybrid;
	mso-list-template-ids:-727438790 -406177698 -1635200394 698899764 843736180 -2021086446 -119876512 -1353948120 433096992 1100269762;}
@list l7:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l8
	{mso-list-id:433669149;
	mso-list-type:hybrid;
	mso-list-template-ids:-1089060776 984073 1639433 1770505 984073 1639433 1770505 984073 1639433 1770505;}
@list l8:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l9
	{mso-list-id:478545189;
	mso-list-type:hybrid;
	mso-list-template-ids:525605624 -1865284624 -120960642 -1203231582 1997689338 483949244 -1219964116 1381562912 -1024684994 880050778;}
@list l9:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l10
	{mso-list-id:486945967;
	mso-list-type:hybrid;
	mso-list-template-ids:1111401516 984073 1639433 1770505 984073 1639433 1770505 984073 1639433 1770505;}
@list l10:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l11
	{mso-list-id:590895616;
	mso-list-type:hybrid;
	mso-list-template-ids:410919458 66569 197641 328713 66569 197641 328713 66569 197641 328713;}
@list l11:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-family:Symbol;}
@list l12
	{mso-list-id:962728535;
	mso-list-type:hybrid;
	mso-list-template-ids:-1392243968 -1445699882 -620571926 -458326230 106343458 1626499960 -516130044 1538554398 1353617672 -2053068768;}
@list l12:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l13
	{mso-list-id:1014571350;
	mso-list-type:hybrid;
	mso-list-template-ids:587513672 1378929388 -1988595924 2141474296 -759423264 1053227386 -1498242712 -1621594730 -261447484 2020135774;}
@list l13:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l14
	{mso-list-id:1016420909;
	mso-list-type:hybrid;
	mso-list-template-ids:1644228262 -88279686 1323084688 2004007834 -596855602 430626268 1393825346 314356696 -1421860078 -1078963488;}
@list l14:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l15
	{mso-list-id:1252660130;
	mso-list-type:hybrid;
	mso-list-template-ids:-1003953104 687258506 1815267762 -1456586652 -686756120 -1174660942 -270095962 863560742 -595009810 -54862764;}
@list l15:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l16
	{mso-list-id:1476557968;
	mso-list-type:hybrid;
	mso-list-template-ids:-106414982 1737257662 1803862350 -2091237884 658942476 2117607900 1750372228 1467016644 1897577248 -863726548;}
@list l16:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l17
	{mso-list-id:1529178467;
	mso-list-type:hybrid;
	mso-list-template-ids:-2098296662 -1455142664 -1866070454 1604738532 563270512 -918134368 87047794 -647470606 -1394803688 1745619872;}
@list l17:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l17:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:1.0in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:"Courier New";}
@list l18
	{mso-list-id:1571891020;
	mso-list-type:hybrid;
	mso-list-template-ids:-2067001514 -362239430 985543820 -1212622156 639544968 -1476470640 -1672589438 745076972 -460921906 -1759222578;}
@list l18:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l19
	{mso-list-id:1620529458;
	mso-list-type:hybrid;
	mso-list-template-ids:1862714612 -751417490 -1498127768 -890188172 139333344 1470499690 631436988 -877517362 2106068326 -128949880;}
@list l19:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l20
	{mso-list-id:1627395542;
	mso-list-type:hybrid;
	mso-list-template-ids:-856647020 -776682770 124031612 515509270 -1292223498 1213376496 -1586432454 -851518896 -1912444626 2081839952;}
@list l20:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l21
	{mso-list-id:1663193836;
	mso-list-type:hybrid;
	mso-list-template-ids:-99085494 822634782 1156606132 -1906427772 1949962476 262295568 269762550 1662788006 54171202 -250995542;}
@list l21:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l22
	{mso-list-id:1698198239;
	mso-list-type:hybrid;
	mso-list-template-ids:-1487224594 1901871390 197641 328713 66569 197641 328713 66569 197641 328713;}
@list l22:level1
	{mso-level-start-at:0;
	mso-level-number-format:bullet;
	mso-level-text:-;
	mso-level-tab-stop:20.0pt;
	mso-level-number-position:left;
	margin-left:20.0pt;
	text-indent:-.25in;
	font-family:"Times New Roman";}
@list l23
	{mso-list-id:1706173325;
	mso-list-type:hybrid;
	mso-list-template-ids:441501294 -1225915552 146169046 696160498 -1078453520 -826373098 48630238 1406826550 1806849308 143980946;}
@list l23:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l24
	{mso-list-id:1780560966;
	mso-list-type:hybrid;
	mso-list-template-ids:648961056 -1062821694 112999048 1334234262 2104379532 1217557168 -1758424328 228500980 -2133272774 -475512530;}
@list l24:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l25
	{mso-list-id:2047022631;
	mso-list-type:hybrid;
	mso-list-template-ids:1997602774 -1691347502 677934730 1770505 984073 1639433 1770505 984073 1639433 1770505;}
@list l25:level1
	{mso-level-text:%1;
	mso-level-tab-stop:.75in;
	mso-level-number-position:left;
	margin-left:.75in;
	text-indent:-.5in;
	font-size:10.0pt;
	font-family:"Times New Roman";}
@list l25:level2
	{mso-level-number-format:alpha-upper;
	mso-level-tab-stop:1.0in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l26
	{mso-list-id:2054039597;
	mso-list-type:hybrid;
	mso-list-template-ids:297185878 -1474805680 -1380821638 -1391457868 -2019627864 -167093154 935627442 1134867846 726552040 1608684604;}
@list l26:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
@list l27
	{mso-list-id:2143035118;
	mso-list-type:hybrid;
	mso-list-template-ids:-2061066568 -1281317490 871012148 1716390436 745289904 664568096 -987751970 273737282 -1855834360 169275254;}
@list l27:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-size:10.0pt;
	font-family:Symbol;}
ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>
</head>
<body bgcolor=white lang=EN-US link=blue vlink=purple style='tab-interval:.5in'>
<div class=Section1>
  <p class=MsoTitle>References</p>
  <h1 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    1.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Literature Review</h1>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    1.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Information Retrieval Generally</h2>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Bates 1998</h3>
  <p class=MsoNormal>Marcia Bates. Indexing and access for Digital Libraries
    and the Internet. <i>Journal of the American Society for Information
    Science </i><span
style='font-style:normal'>49 (November 1998): 1185 – 1205. Available <a
href="http://www.gseis.ucla.edu/faculty/bates/articles/indexdlib.html">http://www.gseis.ucla.edu/faculty/bates/articles/indexdlib.html</a></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Downie 2002a</h3>
  <p class=MsoNormal>J. Stephen Downie. “Who, What, When,Where and Why: Introduction
    and Acknowledgements (first Edition). Papers Presented at the Workshop
    on the Creation of Standardized Test Collections, Tasks, and Metrics
    for Music Information Retrieval (MIR) and Music Digital Library (MDL)
    Evaluation, 18 July, 2002. Available: http://music-ir.org/evaluation/wp2/wp1_downie_who.pdf</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Downie 2002b</h3>
  <p class=MsoNormal>J. Stephen Downie. Establishing Music Information Retrieval
    (MIR) and Music Digital Library (MDL) Evaluation Frameworks: Preliminary
    Foundations and Infrastructures. Papers Presented at the Workshop on
    the Creation of Standardized Test Collections, Tasks, and Metrics for
    Music Information Retrieval (MIR) and Music Digital Library (MDL) Evaluation,
    18 July, 2002. Available. <a
href="http://music-ir.org/evaluation/wp2/wp1_downie_establishing.pdf">http://music-ir.org/evaluation/wp2/wp1_downie_establishing.pdf</a> [Nov
    3. 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Downie 2002c</h3>
  <p class=MsoNormal>J. Stephen Downie. Interim Report on Establishing MIR/MDL
    Evaluation Fram<ins cite="mailto:J.%20Trant" datetime="2004-01-05T16:55">e</ins>works:
    Commentary on Consensus Building. Panel on Music Information Retrieval
    Evaluation Frameworks at ISMIR 2002, 17 October, 2002. Available. http://music-ir.org/evaluation/wp2/wp2_downie_con.pdf
    [Nov 3. 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T16:56"><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></ins></span>
    <![endif]>
    <ins cite="mailto:J.%20Trant"
datetime="2004-01-05T16:56">Downie 2003</ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T16:59">a</ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T16:56"><o:p></o:p></ins></h3>
  <p class=ReferencesText><span style='color:black'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T16:57">J. Stephen Downie. “MIR/MDL Evaluation: Making
        Progress</ins><ins cite="mailto:J.%20Trant" datetime="2004-01-05T16:58">” </ins><ins
cite="mailto:J.%20Trant" datetime="2004-01-05T16:56">SIGIR 2003: Workshop
        on the Evaluation of Music Information Retrieval </ins></span><ins
cite="mailto:J.%20Trant" datetime="2004-01-05T16:56">(MIR) Systems, August
        1, 2003, Toronto, Canada.</ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T16:57"> Available: </ins><span class=MsoHyperlink><span
class=msoDel><del cite="mailto:J.%20Trant" datetime="2004-01-05T17:00"><a
href="http://music-ir.org/evaluation/wp1/wp1_downie_proposal.pdf"></a></del></span><ins
cite="mailto:J.%20Trant" datetime="2004-01-05T16:59"><u><o:p></o:p></u></ins></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:03"><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></ins></span>
    <![endif]>
    <ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:03">Downie 2003b<o:p></o:p></ins></h3>
  <p class=ReferencesText><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:03">J/ Stephen Downie. </ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:04">“T</ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:03">he TREC Like </ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:04">Evaluation of Music Retrieval Systems” Appendix
      C of </ins><span style='color:black'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:05">The MIR/MDL Evaluation Project White Paper Collection</ins></span><ins cite="mailto:J.%20Trant" datetime="2004-01-05T17:05">, <span style='color:black'>Edition
      #3 Available: </span></ins><span
style='mso-prop-change:"J\. Trant" 20040105T1707'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:06"><span style='mso-prop-change:"J\. Trant" 20040105T1707'>http://music-ir.org/evaluation/wp3/wp3_<span
style='mso-prop-change:"J\. Trant" 20040105T1707'>appendixC.pdf</span></span></ins><span
class=msoDel><del cite="mailto:J.%20Trant" datetime="2004-01-05T17:06"><a
href="http://music-ir.org/evaluation/wp.html"></a></del></span><ins
cite="mailto:J.%20Trant" datetime="2004-01-05T17:05"><o:p></o:p></ins></span></p>
  <p class=ReferencesText><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:05">
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></ins></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:06"><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></ins></span>
    <![endif]>
    <ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:05">Downie 200</ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:06">3c</ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:05"><o:p></o:p></ins></h3>
  <p class=MsoNormal><span style='color:black'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:06">J. Stephen Downie (ed.) </ins><i><span
style='mso-prop-change:"J\. Trant" 20040105T1706'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:05"><span style='mso-prop-change:"J\. Trant" 20040105T1706'>The
              MIR/MDL Evaluation Project White Paper Collection</span></ins></span></i></span><i><span
style='mso-prop-change:"J\. Trant" 20040105T1706'><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:05"><span style='mso-prop-change:"J\. Trant" 20040105T1706'>, </span></ins></span></i><span style='color:black;font-style:normal'><ins
cite="mailto:J.%20Trant" datetime="2004-01-05T17:05">Edition #3</ins><ins
cite="mailto:J.%20Trant" datetime="2004-01-05T17:07"> Includes: </ins></span><ins
cite="mailto:J.%20Trant" datetime="2004-01-05T17:07">Part I. Papers Presented
              at the Workshop on the Creation of Standardized Test Collections,
              Tasks, and Metrics for Music Information Retrieval (MIR) and
              Music Digital Library (MDL) Evaluation, 18 July, 2002. Part
              II. Panel on Music Information Retrieval Evaluation Frameworks
              at ISMIR 2002, 17 October, 2002.<span
style="mso-spacerun: yes">&nbsp; </span>and </ins><ins cite="mailto:J.%20Trant"
datetime="2004-01-05T17:05"><span style="mso-spacerun: yes">&nbsp;</span></ins><ins
cite="mailto:J.%20Trant" datetime="2004-01-05T17:07">Part III. Workshop on
              the Evaluation of Music Information Retrieval (MIR) Systems
              at SIGIR 2003, 1 August, 2003</ins><span style='font-size:12.0pt;font-family:Charcoal;
color:black'><ins cite="mailto:J.%20Trant" datetime="2004-01-05T17:07">. </ins></span><span
style='color:black'><ins cite="mailto:J.%20Trant" datetime="2004-01-05T17:05">Available </ins></span><ins cite="mailto:J.%20Trant" datetime="2004-01-05T17:06"><a
href="http://music-ir.org/evaluation/wp.html">http://music-ir.org/evaluation/wp.html</a> [December
              2004]</ins></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Rhyne 1997</h3>
  <p class=MsoNormal>Charles Rhyne. “Images as Evidence in Art History and
    Related Images” <i>Museums and the Web 97: Selected Papers</i><span
style='font-style:normal'> Pittsburgh: Archives &amp; Museum Informatics,
    1997, 347-361 Available <a href="http://www.reed.edu/~cryhne/papers/images.html">http://www.reed.edu/~cryhne/papers/images.html</a></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Rhyne 1995</h3>
  <p class=MsoNormal>Charles Rhyne. Computer Images for Research, Teachning
    and Publication in Art History and Related Disciplines. <i>Visual Resources.
    An International Journal of Documentation.</i><span style='font-style:normal'> Vol
    XIL (1995) 19-51. Available: http://www.reed.edu/~crhyne/papers/computer.html</span><i><o:p></o:p></i></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Sorbel 1994</h3>
  <p class=MsoNormal>Dagobert Sorgel. Indexing and Retrieval Performance:
    The Logical Evidence. <i>Journal of the American Society for Inforamation
    Science</i><span
style='font-style:normal'>. 45:8, 589-599. 1994.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    TREC </h3>
  <p class=MsoEndnoteText>Text REtrieval Conference (TREC). web site.<span
style="mso-spacerun: yes">&nbsp; </span><a
href="http://trec.nist.gov/overview.html">http://trec.nist.gov/overview.html</a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    TREC Genomics Pre-Track</h4>
  <p class=MsoNormal>An initiative developing set of genomics-focussed retrieval
    tasks to be evaluated at TREC. Chaired by William Hersh, Professor and
    Head, Division of Medical Informatics &amp; Outcomes Research, Oregon
    Health &amp; Science University http://medir.ohsu.edu/~genomics/index.html</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Guidelines for the TREC-2002 Video Track</h4>
  <p class=MsoNormal>Available: <a
href="http://www-nlpir.nist.gov/projects/t2002v/t2002v.html">http://www-nlpir.nist.gov/projects/t2002v/t2002v.html</a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Procedure for Proposing New TREC Tracks</h4>
  <p class=MsoNormal>Ellen Voorhees, Chair, TREC Program Committee, September
    2002 Available: http://trec.nist.gov/trec.tracks.html</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    TREC 2001</h4>
  <p class=MsoNormal>The Tenth Text Retrieval Conference (TREC-2001) Proceedings. </p>
  <p class=MsoNormal>NIST Special Publication 500-250 <a
href="http://trec.nist.gov/pubs/trec10/t10_proceedings.html">http://trec.nist.gov/pubs/trec10/t10_proceedings.html</a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Harman 1992 </h4>
  <p class=MsoNormal>Donna Harman. Overview of the first Text Retrieval Conference
    (TREC-1). NIST Available http://trec.nist.gov/pubs/trec1/papers/01.txt</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Voorhees 2002a</h3>
  <p class=MsoNormal>Ellen M. Voorhees. Whither Music IR Evaluation Infrastructure:
    Lessons to be learned from TREC. Papers Presented at the Workshop on
    the Creation of Standardized Test Collections, Tasks, and Metrics for
    Music Information Retrieval (MIR) and Music Digital Library (MDL) Evaluation,
    18 July, 2002 Available http://music-ir.org/evaluation/wp2/wp1_vorhees.pdf: </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Voorhees 2002b</h3>
  <p class=MsoNormal>Ellen Voorhees , Chair TREC Program Committee, Procedure
    for Proposing New TREC Tracks. [2002]. <a
href="http://trec.nist.gov/trec.tracks.html">http://trec.nist.gov/trec.tracks.html</a></p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    1.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Image Indexing and Retrieval Specifically</h2>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Burford et al 2003</h3>
  <p class=ReferencesText>Burford, B, Briggs, P, &amp; Eakins, JE<span
style="mso-spacerun: yes">&nbsp; </span>“A Taxonomy of the Image: On the</p>
  <p class=ReferencesText>Classification of Content for Image Retrieval” <i>Visual
      Communication</i><span style='font-style:normal'> 2(2), 2003. 123-161.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Cawkell 1992</h3>
  <p class=MsoNormal>A.E. Cawkell. Selected aspects of image processing and
    management: review and future prospects. <i>Journal of Information Science </i><span
style='font-style:normal'><span style="mso-spacerun: yes">&nbsp;</span>8:3
    179-192.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Chen and Rasmussen 1999</h3>
  <p class=MsoNormal>Hsin-lian Chen and Edie M. Rasmussen. “Intellectual
    Access to Images”. <i>Library Trends</i><span style='font-style:normal'>,
    Special Issue “ Progress in Visual Information Access and Retrieval Edited
    by Beth Sandore. 48:2, Fall 1999.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Choi and Rasmussen 2003</h3>
  <p class=MsoNormal>Youngok Choi and Edie M. Rasmussen, “Searching for Images:
    the Analysis of Users’ queries for Image Retrieval in American History”. <i>Journal
    of the American Society for Information Science and Technology</i><span
style='font-style:normal'>, 54:6 498-511, 2003</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Chu 2001</h3>
  <p class=MsoNormal>Heting Chu. Research in Image Indexing and Retrieval
    as Reflected in the Literature. <i>Journal of the American Society for
    Information Science and Technology. </i><span style='font-style:normal'><span
style="mso-spacerun: yes">&nbsp;</span>52(12) 1011-1018, 2001</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Connis et al 2000</h3>
  <p class=ReferencesText>Lynne R Conniss, A Julie Ashford and Margaret E
    Graham, Information seeking behaviour in image retrieval: VISOR I final
    report. Newcastle-upon-Tyne: Institute for Image Data Research, 2000.
    147pp. (Library and Information Commission Research Report 95)</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Eakins 2002 </h3>
  <p class=ReferencesText>J P Eakins,. Towards intelligent image retrieval. <i>Pattern
      Recognition</i><span style='font-style:normal'>. 35, 2002, 3-14.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Eakins and Graham 2000 </h3>
  <p class=MsoNormal>John Eakins and Margaret Graham.Content-based Image
    Retrieval. JISC Technology Applications Programme Report 39.JTAP Report </p>
  <p class=MsoNormal>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Enser 2000 </h3>
  <p class=ReferencesText>Peter Enser. <span style='color:black'>Visual image
      retrieval: Seeking the alliance of concept-based and content-based <i>Journal
      of Information Science</i></span><span style='color:black'>. 26: 4</span>. <span
style='color:black'><span style="mso-spacerun: yes">&nbsp;</span>2000</span>, <span
style='color:black'>pg. 199-210</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Goodrum 2000</h3>
  <p class=ReferencesText>A..Goodrum, A. Image Information Retrieval: An
    Overview of Current Research” <i>Informing Science</i><span style='font-style:normal'>.
    Vol. 2, No.2, 2000 33-66. </span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Goodrum et al. 2001</h3>
  <p class=MsoNormal>Abby A Goodrum, Mark E. Rorvig, Ki-Tai Jeong, Chitturi
    Suresh. “An Open Source Agenda for Research Linking Test and Image Content
    Features”.<i> Journal of the American Society for Information Science
    and Technology. </i><span style='font-style:normal'>52(11) 948-953. September.
    2001.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Graham 2001</h3>
  <p class=ReferencesText style='text-align:justify'>M E. Graham, The cataloguing
    and indexing of images: time for a new paradigm? <i>Art Libraries Journal</i><span
style='font-style:normal'>. 26(1), 2001, p22-27.</span><span style='font-size:
12.0pt'><o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Greenberg 2001</h3>
  <p class=MsoNormal>Jane Greenberg. A quantitative Categorical Analysis
    of metadata elements in image applicable metadata schemas. <i>Journal
    of the American Society for Information Science and Technology.</i><span
style='font-style:normal'><span style="mso-spacerun: yes">&nbsp; </span>52:11
    917-924 September 2001.</span><i><o:p></o:p></i></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Heidorn and Snadore 1996</h3>
  <p class=MsoNormal>P. Bryan Heidorn and Beth Sandore, the 33rd Annual Clinic
    on Library Applications of Data Processing, University of Illinois, Urbana-Champaign,
    March 1996, Urbana-Champaign: University of Illinois at Urbana- Champaign,
    1997, 29-41.<span style='font-size:9.0pt;font-family:Helvetica'><b><o:p></o:p></b></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    James and Chang 2000</h3>
  <p class=MsoNormal>Alejandro Jaimes and Shih-Fu Chang. “A conceptual Framework
    for Idexing Visual Information at Multiple levels. <i>I&amp;ST/SPIE Internet
    Imaging</i><span style='font-style:normal'>. Vol 3964. San Jose, CA,
    Jan 2000. Available http://www.ctr.columbia.edu/~ajaimes/Pubs/spie00_internet.pdf</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Jorgensen 1999</h3>
  <p class=MsoNormal>Corinne örgensen. “Image Indexing: An analysis of selected
    classification systems in relation to iamge attributes named by naïve
    users. Annual Review of OCLC Research 1999. Available: <a
href="http://www.oclc.org/research/publications/arr/199/jorgensen/">http://www.oclc.org/research/publications/arr/199/jorgensen/</a> [August
    15, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Jörgensen 2001</h3>
  <p class=MsoNormal>Corinne Jörgensen, “Introduction and Overview” <i>Journal
      of the American Society for Information Society and Technology.</i><span
style='font-style:normal'> 52(2): 906:910.</span><i> </i><span
style='font-style:normal'>2001.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Kiernan, Rhyne and Spronk 2001</h3>
  <p class=MsoNormal>Kevin Kiernan, Charles Rhyne and Ron Spronk, Digital
    Imagery for Works of Art, A report of a meeting at the Harvard University
    Art Museums, Cambridge, Massachusetts, November 19-20, 2001 Sponsored
    by The Andrew W. Mellon Foundation, The National Science Foundation,
    The Harvard University Art Museums. Available: <a href="http://www.dli2.nsf.gov/mellon/index.html">http://www.dli2.nsf.gov/mellon/index.html</a></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Lewis et al<span style="mso-spacerun: yes">&nbsp; </span>2002</h3>
  <p class=MsoNormal>Paul Lewis, David Dupplaw and Kirk Martinez. “Content-Based
    Multimedia Information Handling: Should we Stick to metadata?” <i>Cultivate
    Interactive</i><span style='font-style:normal'>, Issue 6 February 2002.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Panofsky 1962</h3>
  <p class=MsoNormal>Erwin Panofsky, <i>Studies in iconology: Humanistic
      themes in the Art of the Renaissance</i><span style='font-style:normal'> New
      York: Harper &amp; Row, 1962, 3-31.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Persson n.d. [2000]</h3>
  <p class=MsoNormal>Olle Persson. “Image indexing – a first author co-citation
    map” Available: <a href="http://www.umu.se/inforsk/Imageindexing/imageindex.htm">http://www.umu.se/inforsk/Imageindexing/imageindex.htm</a> [Nov
    4, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Pisciotta et al 2001</h3>
  <p class=MsoNormal>Henry Pisciotta, Roger Brisson, Eric Ferrin, Michael
    Dooris, and Amanda Spink. Penn State Visual Image User Study <i>D-Lib
    Magazine</i><span
style='font-style:normal'> Volume 7 Number 7/8. July/August 2001 Available: <a
href="http://www.dlib.org/dlib/july01/pisciotta/07pisciotta.html">http://www.dlib.org/dlib/july01/pisciotta/07pisciotta.html</a> [Nov.
    6, 2002]</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Rasmussen 1997</h3>
  <p class=MsoNormal>Edie Rasmussen “Indexing Images”, <i>Annual Review of
      Information Science and Technology </i><span style='font-style:normal'>(ARIST)
      32 (1997)169-196. </span><i><o:p></o:p></i></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Roberts 2001</h3>
  <p class=MsoNormal>Helene E. Roberts, “A Picture is Worth a Thousand Words:
    Art Indexing in Electronic Databases”. <i>Journal of the American Society
    for Information Scienct and Technology. </i><span style='font-style:normal'><span
style="mso-spacerun: yes">&nbsp;</span>52(11) 911-916. 2001.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Sandore 1999</h3>
  <p class=MsoNormal>Beth Sandore (ed.), &quot;Progress in Visual Information
    Access and Retrieval&quot; (Thematic Issue), <i>Library Trends</i><span
style='font-style:normal'>, 48, #2 (Fall, 1999)</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Shatford 1986</h3>
  <p class=MsoNormal>Sarah Shatford. Analysing the subject of a picture:
    A theoretical approach”. <i>Cataloguing and Classification Quarterly</i><span
style='font-style:normal'>.6. 39-62.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Shatford Lane 1994</h3>
  <p class=MsoNormal>Sara Shatford Lane. “Some Issues in the Indexing of
    Images”. <i>Journal of the American Society for Information Science.</i><span
style='font-style:normal'> 45:8, 583-588, September 1994.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Smeulders et al 2000</h3>
  <p class=MsoNormal>Smeulders, Arnold W. M., Worring, Marcel, Santini, Simone,
    Gupta, Amarnath;,Jain, Rameth. Content-based image retrieval at the end
    of the early</p>
  <p class=MsoNormal>years.<span style="mso-spacerun: yes">&nbsp; </span><i>IEEE
      Transactions on Pattern Analysis and Machine Intelligence</i><span
style='font-style:normal'>, 22</span></p>
  <p class=MsoNormal>(12), December (2000), 1349-1379.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Svenonius 1994</h3>
  <p class=MsoNormal>Elaine Svenonius. Access to Nonbook materials: The Limits
    of Subject Indexing for Visual and Aural Languages. <i>Journal of the
    American Society for Information Science</i><span style='font-style:normal'>.
    45:8, 600-606. 1994. </span></p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    1.3<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Content Based Image Retrieval<span style="mso-spacerun:
yes">&nbsp; </span>(CBIR)</h2>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Barnard et al 2003</h3>
  <p class=ReferencesText><span style='color:black'>Kobus Barnard, Pinar
      Duygulu, David Forsyth, Nando de Freitas,David M. Blei, Michael I.
      Jordan; </span>Matching Words and Pictures <span style='color:black'>JMLR
      Special Issue on Machine Learning Methods for Text and Images3(Feb):1107-1135,
      2003</span> Available: <a
href="http://www.jmlr.org/papers/volume3/barnard03a/barnard03a.pdf">http://www.jmlr.org/papers/volume3/barnard03a/barnard03a.pdf</a></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Barnard et al 2001</h3>
  <p class=ReferencesText>Kobus Barnard, Pinar Duygulu, and David Forsyth,
    Clustering Art, Computer Vision and Pattern Recognition, 2001, pp. II:434-439.
    Available <a
href="http://www.cs.arizona.edu/people/kobus/research/publications/CVPR-01/index.html">http://www.cs.arizona.edu/people/kobus/research/publications/CVPR-01/index.html</a> [August
    17, 2002].</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Barnard and Forsyth 2001</h3>
  <p class=MsoNormal>Kobus Barnard and David Forsyth, “Exploiting Image Semantics
    for Picture Libraries’ The First ACM/IEE-CS Joint Conference on Digital
    Libraries, 2001. p 469</p>
  <p class=MsoNormal>Available: http://www.cs.arizona.edu/people/kobus/research/publications/JCDL-01/index.html</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Barnard et al 2002</h3>
  <p class=MsoNormal>Kobus Barnard, Pinar Duygulu, Nando de Freitas, David
    Forsyth, David Blei, and Michael I. Jordan, &quot;Matching Words and
    Pictures&quot;, submitted for publication to JMLR. Available: <a
href="http://www.cs.arizona.edu/people/kobus/research/publications/JMLR/index.html">http://www.cs.arizona.edu/people/kobus/research/publications/JMLR/index.html</a> [Nov.
    3, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Castelli et al 1998. </h3>
  <p class=ReferencesText>V. Castelli, L. D. Bergman, I. Kontoyiannis, C.-S.
    Li, J. T.<span style='font-size:12.0pt'> R</span>obinson and J. J. Turek,
    on “Progressive search and retrieval in large image archives” IBM Journal
    of Research and Development, Vol. 42, No. 2, Multimedia<span style='font-size:
12.0pt;font-family:Charcoal;color:black'> </span>Systems 1998.<span
style='font-size:12.0pt;font-family:Charcoal;color:black'> </span><span
style="mso-spacerun: yes">&nbsp;</span>Available: <a
href="http://www.research.ibm.com/journal/rd/422/castelli.html"><span
style='color:windowtext'>http://www.research.ibm.com/journal/rd/422/castelli.html</span></a> [July
    2003].<span style='font-size:12.0pt'><o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Duygulu et al 2002</h3>
  <p class=MsoNormal>Pinar Duygulu, Kobus Barnard, Nando de Freitas, and
    David Forsyth, “Object recognition as machine translation: learning a
    lexicon for a fixed image vocabulary’ Seventh European Conference on
    Computer Vision, IV:97-112, 2002. available: http://www.cs.arizona.edu/people/kobus/research/publications/ECCV-02-1/ECCV-02-1.pdf</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Eakins and Graham, 2000 </h3>
  <p class=ReferencesText style='text-align:justify'>Eakins, John<span
style="mso-spacerun: yes">&nbsp; </span>and Margaret Graham, Content-based
    Image Retrieval,<span style="mso-spacerun: yes">&nbsp; </span>JISC Technology
    Applications Programme (JTAP). January 1999.<span style="mso-spacerun:
yes">&nbsp; </span>Available <span style='font-size:12.0pt'><a
href="http://www.jisc.ac.uk/jtap/htm/jtap-039.html">http://www.jisc.ac.uk/jtap/htm/jtap-039.html</a>.
    [</span>August 12, 2002] <a href="http://www.unn.ac.uk/iidr/report.html">http://www.unn.ac.uk/iidr/report.html</a> [August
    14, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Huang and Zabih 1999</h3>
  <p class=MsoNormal>Jing Huang and Ramin Zabih. Combining Color and Spatial
    Information for Content-based Image Retrieval. European Conference on
    Digital Libraries. 22-24 September 1999 Available <a
href="http://www.cs.cornell.edu/rdz/Papers/ecdl2/spatial.htm">http://www.cs.cornell.edu/rdz/Papers/ecdl2/spatial.htm</a> [Aug
    15, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Li 2000</h3>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>Jia
    Li, James Z. Wang, Gio Wiederhold, ``IRM: Integrated region matching
    for image retrieval,'' Proceedings of the 2000 ACM Multimedia Conference,
    147-156, Los Angeles, ACM, October, 2000.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Li and Wang 2003</h3>
  <p class=ReferencesText>Jia Li and James Z. Wang, “Automatic Linguistic
    Indexing of Pictures by a Statistical Modeling Approach”. <i>IEEE Transactions
    on Pattern Analysis and Machine Intelligence</i><span style='font-style:normal'>.
    Vol 25, no 10. Octover 2003. </span><i><span style="mso-spacerun:
yes">&nbsp;</span><o:p></o:p></i></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Rui et al 1997</h3>
  <p class=MsoNormal>Yong Rui, Thomas S. Huang, Shih-Fu Chu. Image Retrieval:
    Past, Present and Future. International Symposium on Multimedia Information
    Processing, 1997 Available: </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Venters and Cooper 2000</h3>
  <p class=ReferencesText>Venters, C. C., and Cooper, M. D. A Review of Content-Based
    Image Retrieval Systems. JISC Technology Assessment Program Report, March
    2000. Available <span class=MsoHyperlinkFollowed><a
href="http://www.jtap.ac.uk/reports/htm/jtap-054.html"><span style='color:purple'>http://www.jtap.ac.uk/reports/htm/jtap-054.html</span></a></span> [August
    12, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Ward et al 2001 </h3>
  <p class=ReferencesText>Annette A. Ward , Margaret Graham, Jonathan Riley,
    Neil Eliot, and John Eakins, Nic Sheen, and Cathy Pringle. “Collage and
    Content-based Image Retrieval: Collaboration for Enhanced Services for
    the London Guildhall Library”. <i>Museums and the Web 2001</i><span
style='font-style:normal'>. Archives &amp; Museum Informatics. Available <a
href="http://www.archimuse.com/mw2001/papers/ward/ward.html">http://www.archimuse.com/mw2001/papers/ward/ward.html</a> [August
    15, 2002]</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Wang 2001</h3>
  <p class=ReferencesText>James Z. Wang, Jia Li, Gio Wiederhold, ``SIMPLIcity:
    Semantics-sensitive Integrated Matching for Picture LIbraries,'' IEEE
    Trans. PAMI, vol 23, no.9, pp. 947-963, 2001.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Zoran 1997</h3>
  <p class=ReferencesText>Zoran Pecenovic, “Image Retrieval using Latent
    Semantic Indexing” Final year graduate thesis, Department of Electrical<span
style='font-size:12.0pt;font-family:Charcoal;color:black'> </span>Engineering
    Audiovisual Communications Laboratory,<span style='font-size:12.0pt;font-family:
Charcoal;color:black'> </span>L'Ecole Polytechnique Fédérale de Lausanne,<span
style='font-size:12.0pt;font-family:Charcoal;color:black'> </span>May, 1997.Available:
    http://lcavwww.epfl.ch/LSI/documents/final.html</p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    1.4<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Image Retrieval Benchmarking/Evaluation</h2>
  <p class=MsoNormal>Methods for constructing such systems are discussed
    at <span
class=MsoHyperlink><span style='color:blue'><a
href="http://www.benchathlon.net/activity/index.html">http://www.benchathlon.net/activity/index.html</a>,</span></span> and
    in more general terms at <span class=MsoHyperlink><span style='color:blue'>http://viper.unige.ch/benchmarking/</span></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Barnard and Shirahatti 2003</h3>
  <p class=ReferencesText><span style='color:black'>Kobus Barnard and Nikhil
      V. Shirahatti, &quot;A method for comparing content based image retrieval
      methods&quot;, Internet Imaging IX, Electronic Imaging 2003.</span> Available: <span
style='color:black'>kobus.ca/research/publications/SPIE-03-bench/SPIE-03-bench.pdf</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Barnard et al 2002</h3>
  <p class=MsoNormal>Kobus Barnard, Lindsay Martin, Brian Fund and Adam Coath,
    “A Data Set for Color Research,” <i>Color Research and Application. </i><span
style='font-style:normal'>27:3, 148-152, 2002.</span></p>
  <p class=MsoNormal>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Barnard et al 2003</h3>
  <p class=ReferencesText>Kobusbus Barnard, Brian Funt, Vlad Cardei &quot;A
    Comparison of Computational Color Constancy Algorithms; Part One: Methodology
    and Experiments with Synthesized Data,&quot; IEEE Transactions in Image
    Processing, Vol. 11, No. 9, pp. 972-984 Available: <a
href="http://www.cs.arizona.edu/people/kobus/research/publications/comparison_1/index.html">http://www.cs.arizona.edu/people/kobus/research/publications/comparison_1/index.html</a> [Nov
    3. 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Bauer 1997</h3>
  <p class=MsoNormal>Charly Bauer. Relevace Judgements for Images: Pilot
    Study. Unpublished research paper, Spring 1997. Available: http://images.grainger.uiuc.edu/research/Relevance/MARS.html </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Black et all 2002</h3>
  <p class=MsoEndnoteText>John A. Black, Jr., Gamal Fahmy, and Sethuraman
    Panchanathan</p>
  <p class=MsoEndnoteText>A Method for Evaluating the Performance of Content-Based
    Image Retrieval Systems Based on Subjectively Determined Similarity between
    Images”, Image and Video Retrieval, International Conference, CIVR 2002,
    London, UK, July 18-19, 2002, Proceedings. Lecture Notes in Computer
    Science 2383 Springer 2002, p. 356 ff. Available: <a
href="http://link.springer.de/link/service/series/0558/bibs/2383/23830356.htm">http://link.springer.de/link/service/series/0558/bibs/2383/23830356.htm</a> [August
    15, 2002].</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CLIR/RLG/DLF 2002</h3>
  <p class=MsoNormal>Council on Library and Information Resources, Research
    Libraries Group and the Digital Library Federation.<span style="mso-spacerun:
yes">&nbsp; </span>and Research Libraries Group, Guides to Quality in Visual
    Resource Imaging. July 2000 (<a href="http://www.rlg.org/visguides/">http://www.rlg.org/visguides/</a>).</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Gunther and Beretta<span style="mso-spacerun:
yes">&nbsp; </span>2001</h3>
  <p class=MsoEndnoteText>Neil J. Gunther, Giordano Beretta<span
style="mso-spacerun: yes">&nbsp; </span>. A Benchmark for Image Retrieval
    using Distributed Systems over the Internet: BIRDS--I<span style="mso-spacerun:
yes">&nbsp; </span>. HP Labs, Palo Alto, Technical Report HPL--2000--162,
    San Jose, 2001</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Harman 1998</h3>
  <p class=MsoNormal>Donna Harman. The Text Retrieval Conferences (TRECs):
    Providing a test-bed for information retrieval systems. <i>ASIS Bulletin</i><span
style='font-style:normal'> April/May1998. Available <a
href="http://www.asis.org/Bulletin/Apr-98/harman.html">http://www.asis.org/Bulletin/Apr-98/harman.html</a></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Harman 2000</h3>
  <p class=MsoEndnoteText>Donna Harman, What we have learned, and not learned
    from the TREC conferences, TREC/ NIST, April 5-7, 2000, Cambridge, England<span
style="mso-spacerun: yes">&nbsp; </span>(<a
href="http://www.itl.nist.gov/iaui/894.02/works/presentations/bcs-irsg/index.htm">http://www.itl.nist.gov/iaui/894.02/works/presentations/bcs-irsg/index.htm</a></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Howe 2000</h3>
  <p class=MsoNormal>Nicholas R. Howe. “Using artificial queries to evaluate
    image retrieval. IEEE Workshop on Content-based Access of Image and Video
    Libraries. in Proceedings of CBAIVL '00, 12 June 2000 in Hilton Head,
    South Carolina. 5-9</p>
  <p class=MsoNormal>Donna Harman , “The Text REtrieval Conferences (TRECs):
    Providing a Test-Bed for Information Retrieval Systems” in The Bulletin
    of the American Society for Information Science, April 1998 (<a
href="http://www.asis.org/Bulletin/Apr-98/harman.html">http://www.asis.org/Bulletin/Apr-98/harman.html</a>)</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Jorgensen and Srihari 1999</h3>
  <p class=MsoNormal>Corinne Jörgensen and Rohini K. Srihari. Creating a
    Web-Based Image database for benchmarking image retrieval. Proceedings
    of SPIE. Vol. 3644, 534-541. </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Markkula and Sormunen 2000</h3>
  <p class=ReferencesText><span style='color:black'>Marjo Markkula and Eero
      Sormunen</span>, <span style='color:black'><span style="mso-spacerun:
yes">&nbsp;</span>&quot;End-User Searching Challenges Indexing Practices
      in the Di</span>gital Newspaper Photo Archive&quot;, <span style='color:black'><i>Information
      Retrieval</i></span>, no.4<span style="mso-spacerun: yes">&nbsp; </span>2000,
      259-285.<span style='color:black'><o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Müller et al 2001a</h3>
  <p class=MsoNormal>Henning Müller, Wolfgang Müller, David McG. Squire,
    Stéphane Marchand--Maillet, Thierry Pun . Performance Evaluation in Content--Based
    Image Retrieval: Overview and Proposals , <i>Pattern Recognition Letters, </i><span
style='font-style:normal'>Vol. 22, No. 5, pp. 593--601, 2001.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Müller et al 2001b</h3>
  <p class=MsoNormal>Wolfgang Müller, Stéphane Marchand-Maillet, Henning
    Müller, Dsvid McG. Squire, and Theirry Pun. “Evaluating Image Browsers
    Using Structured Annotation.” <i>Journal of the American Society for
    Information Science and Technology</i><span style='font-style:normal'>.
    52(11):961-968, September 2001.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Müller et al 2001c </h3>
  <p class=MsoEndnoteText>Henning Müller, Wolfgang Müller, Stéphane Marchand-Maillet,
    Theirry Pun and David McG Squire. “Automated Benchmarking in Content
    Based Image Retrieval. Tech. Rep. 01.01, University of Geneva, May 2001.
    Available: http://vision.unige.ch/publications/postscript/2001/MuellerHMuellerWMarchandSquirePun_tr01.pdf</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Müller et al 2002</h3>
  <p class=MsoEndnoteText>Henning Müller, Stephane Marchand-Maillet, and
    Thierry Pun, “The Truth about Corel - Evaluation in Image Retrieval”.
    Image and Video Retrieval, International Conference, CIVR 2002, London,
    UK, July 18-19, 2002, Proceedings. Lecture Notes in Computer Science
    2383 Springer 2002, p. 38 ff. Available <a
href="http://link.springer.de/link/service/series/0558/bibs/2383/23830038.htm">http://link.springer.de/link/service/series/0558/bibs/2383/23830038.htm</a> [August
    15, 2002].</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Rasmussen 2002</h3>
  <p class=MsoNormal>Edie Rasmussesn. Evaluation in Information Retrieval.
    Panel on Music Information Retrieval Evaluation Frameworks at ISMIR 2002,
    17 October, 2002 Available: Panel on Music Information Retrieval Evaluation
    Frameworks at ISMIR 2002, 17 October, 2002</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Rodden 2001</h3>
  <p class=MsoNormal>K. Rodden, W. Basalaj, D. Sinclair, and K. Wood, Does
    Organisation by Similarity Assist Image Browsing?, ACM Conference on
    Human Factors in Computing Systems (ACM CHI 2001), Seattle, April 2001.Available: <b><o:p></o:p></b></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Rodden et al 1999</h3>
  <p class=MsoNormal>Kerry Rodden, Wojciech Basalaj, David Sinclair and Kenneth
    Wood. “Evaluating a Visualization of Image Similarity. Poster. Proceedings
    of SIGIR’99. ACM August 1999.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    <span style="mso-spacerun: yes">&nbsp;</span>Schmidt and Over 1999</h3>
  <p class=MsoNormal>*<span style="mso-spacerun: yes">&nbsp; </span>Schmidt,
    C. &amp; Over, P. Digital Video Test Collection. In proceedings of the
    Twenty-Second Annual International ACM-SIGIR Conference on Research and
    Development in Information Retrieval, Berkeley, CA, USA. (1999, August).
    Available: <a
href="http://www.itl.nist.gov/iad/894.02/works/papers/digital.video.html">http://www.itl.nist.gov/iad/894.02/works/papers/digital.video.html</a> [Nov
    3, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Slaughter et al 2000</h3>
  <p class=MsoNormal>Slaughter, L., Marchionini, G. and Geisler, G. Open
    Video: A framework</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>for
    a test collection. Journal of Network and Computer Applications, 23(3):</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>219-245,
    July 2000.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Smeaton et al</h3>
  <p class=MsoNormal>Alan F. Smeaton, Paul Over and Ramazan Taban. The TREC-2001
    Video Track Report. NIST Special Publication 500-250: The Tenth Text
    REtrieval Conference (TREC 2001) Available: http://trec.nist.gov/pubs/trec10/papers/TREC10Video_Proc_Report.pdf</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Smith 2001</h3>
  <p class=MsoNormal>John.R. Smith. “Quantitative Assessment of Image Retrieval
    Effectiveness.” <i>Journal of the American Society for Information Science
    and Technology</i><span style='font-style:normal'>. 52(11): 969-979.
    September 2001.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Smith and Benitez<span style="mso-spacerun: yes">&nbsp; </span>2000</h3>
  <p class=MsoNormal>Conceptual Modeling of audio-visual content. IEEE International
    Conference on Multimedia and Expo (CcME), New York, NY.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Sormunen, et al 1999</h3>
  <p class=ReferencesText><span style='color:black'>Sormunen E., Markkula
      M. and Järvelin K. (1999). The Perceived Similarity of Photos - A Test-Collection
      Based Evaluation Framework for the Content-Based Image Retrieval Algorithms.
      In: Draper S. et al., eds. Mira 99: Evaluating interactive information
      retrieval. Electronic Workshops in Computing. Available: http://www.ewic.org.uk/ewic/workshop/fetch.cfm/MIRA-99.pdf</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Voorhees &amp; Harman 1997</h3>
  <p class=ReferencesText>Voorhees, E., &amp; Harman, D.<span
style="mso-spacerun: yes">&nbsp; </span>Overview of the Sixth Text REtrieval
    Conference (TREC-6). In proceedings of the Sixth Text REtrieval Conference
    (TREC-6), Gaithersburg, Maryland, USA., November 1997. Available: http://trec.nist.gov/pubs/trec6/papers/overview.ps.gz</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Wang et al 2003</h3>
  <p class=ReferencesText>James Z. Wang, Jia Li, Sui Ching Lin, ``Evaluation
    strategies for automatic linguistic indexing of pictures,'' Proc. IEEE
    International Conference on Image Processing (ICIP), Barcelona, Spain,
    pp. -, IEEE, September 2003. Available: http://www-db.stanford.edu/~wangz/project/imsearch/ALIP/ICIP2003/</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Williams 2000</h3>
  <p class=MsoNormal>Don Williams, &quot;An Overview of Image Quality Metrics,&quot; in <i>Moving
      Theory into Practice: Digital Imaging for Libraries and Archive</i><span style='font-style:normal'>s,
      Anne R. Kenney and Oya Y. Rieger (editors and principle authors). Mountain
      View, CA: Research Libraries Group, 2000 </span></p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    1.5<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Metadata Based Image Retrieval</h2>
  <p class=ReferencesText>Researchers in metadata based retrieval, or hybrid
    retrieval systems that use metadata, are less organized than their peers
    in CBIR. In the absence of a complete bibliography, some recent and useful
    articles include:</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Angeles 1998</h3>
  <p class=ReferencesText>Angeles, M. Information Organization and Information
    Use of Visual Resources Collections. VRA Bulletin, 25 (3), 51-58. available: <a
href="http://studioid.com/articles/vruse/">http://studioid.com/articles/vruse/</a> [August
    15, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Barnett 1988</h3>
  <p class=ReferencesText>Barnett, P.J. (1988). An art information system:
    From integration to interpretation. Library Trends, 37 (2), 194-205.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Brickley 2001 </h3>
  <p class=ReferencesText>Dan Brickley, Harmany: a mid-term report (Or &quot;Resource
    Discovery for Multimedia Metadata&quot; revisited...) <a
href="http://www.ilrt.bris.ac.uk/discovery/2001/03/multimeta/">http://www.ilrt.bris.ac.uk/discovery/2001/03/multimeta/</a> March
    2001</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Goodrum et al 2000</h3>
  <p class=ReferencesText>Abby Goodrum, M. Rorvig, K. Jeong and C. Suresh.
    An Open Source Agenda for Research Linking Text and Image Content Features. <i>Journal
    of the American Society of Information Science</i><span style='font-style:normal'>,
    Available: </span></p>
  <p class=ReferencesText><a href="http://www.unt.edu/ir/papers/jasisg00.htm">http://www.unt.edu/ir/papers/jasisg00.htm</a> [August
    15, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Gordon 2001</h3>
  <p class=MsoNormal>Andrew S. Gordon. “Browsing Image Collections with Representations
    of Common-Sense Activities”. <i>Journal of the American Society for Information
    Science and Technology</i><span style='font-style:normal'> 52(11): 925-929,
    Sept. 2001.</span><i><o:p></o:p></i></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Greenberg 2001</h3>
  <p class=MsoNormal>Jane Greenberg. “A Quantitative Categorical Analysis
    of Metadata Elements in Image-Applicable Metadata Schemas.” Journal of
    the American Society for Information Science and Technology, 52(11):
    917-924 September 2001</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Hastings 1994</h3>
  <p class=MsoNormal>Samantha Hastings. Query categories in a study of intellectual
    access to digitized art images. American Society for Information Science,
    annual meeting, Chicago IL, October 1995.<i><o:p></o:p></i></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Hunter 2002</h3>
  <p class=MsoNormal>Jane Hunter. Combining the CIDOC CRM and MPEG-7 to Describe
    Multimedia in Museums. Museums and the Web 2002. Archives &amp; Museum
    Informatics.<span class=msoDel><del cite="mailto:J.%20Trant"
datetime="2002-08-16T20:29">2002.</del></span><span class=msoDel><del
cite="mailto:J.%20Trant" datetime="2002-08-16T20:29"><o:p></o:p></del></span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><ins
cite="mailto:J.%20Trant" datetime="2002-08-16T20:29">2002</ins>Available <a
href="http://www.archimuse.com/mw2002/papers/hunter/hunter.html">http://www.archimuse.com/mw2002/papers/hunter/hunter.html</a> [August
    15, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Hunter and Zhan 1999</h3>
  <p class=ReferencesText>Jane Hunter and<span style="mso-spacerun: yes">&nbsp; </span>Zhimin
    Zhan “An Indexing and Querying System for Online Images, Based on the
    PNG Format and Embedded Metadata” September, 1999 <a
href="http://archive.dstc.edu.au/RDU/staff/jane-hunter/PNG/paper.html">http://archive.dstc.edu.au/RDU/staff/jane-hunter/PNG/paper.html</a></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Jörgensen 1999</h3>
  <p class=MsoNormal>Corinne Jörgensen. “Image Indexing, an Analysis of Selected
    Classification Systems in relation to Image Attributes names by Naïve
    Users”. Annual Review of OCLC Research, 1999. Available: http://www.oclc.org/research/publications/arr/1999/jorgensen/
    [August 15, 2002].</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Jörgensen 2001</h3>
  <p class=MsoNormal>Corinne Jörgensen. “A Conceptual Framework and Empirical
    Research for Classifying Visual Descriptors:. <i>Journal of the American
    Society for Information Science and Technology</i><span style='font-style:normal'>.
    52(11): 938-947, September 2001.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Lu and Williams 1999</h3>
  <p class=ReferencesText>Guojun Lu and Ben Williams, Gippsland School of
    Computing and Information Technology Monash University, An Integrated
    WWW Image Retrieval System AusWeb99, The Fifth Australian World Wide
    Web Conference, held in Balliina, NSW, Australia from 17-20 April, 1999 <a
href="http://ausweb.scu.edu.au/aw99/papers/lu/paper.html"><span
style='font-size:12.0pt'>http://ausweb.scu.edu.au/aw99/papers/lu/paper.html</span></a>) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Markey 1998</h3>
  <p class=ReferencesText>Markey, K. (1988). Access to iconographical research
    collections. Library Trends, 37 (2), 154-174.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Perez-Lopez<span style="mso-spacerun: yes">&nbsp; </span>et al 1996</h3>
  <p class=ReferencesText>Kathleen Perez-Lopez, Brian Krasner, Gregory Baraghimian
    Mark Berlin, Smart Metadata for Content-based Retrieval from Large Image
    Databases, <a
href="http://www.computer.org/conferences/meta96/krasner/perez_lopez.html"><span
style='font-size:12.0pt'>http://www.computer.org/conferences/meta96/krasner/perez_lopez.html</span></a></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Roberts 2001</h3>
  <p class=ReferencesText>Helene E. Roberts: A picture is worth a thousand
    words: Art indexing in electronic databases. JASIST 52(11): 911-916 (2001)</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Shatford 1986</h3>
  <p class=ReferencesText>Shatford, S. (1986, Spring). Analyzing the subject
    of a picture: A theoretical approach. Cataloging &amp; Classification
    Quarterly, 6 (3), 39-62.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Tam and Leung 2001</h3>
  <p class=MsoNormal>A.M.Tam and C.H.C. Leung. “Structured Natural-Language
    Descriptions for Semantic Content Retrieval of Visual Materials”. <i>Journal
    of the American Society for Information Science and Technology.</i><span
style='font-style:normal'> 52(11):930:937. September 2001.</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Weibel 1997 </h3>
  <p class=ReferencesText>CNI/OCLC Image Metadata Workshop, September 24
    - 25, 1996 (3<sup>rd</sup> Dublin Core Workshop),</p>
  <p class=ReferencesText><span style='font-size:12.0pt'><a
href="http://www.dlib.org/dlib/january97/oclc/01weibel.html">http://www.dlib.org/dlib/january97/oclc/01weibel.html</a><o:p></o:p></span></p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    1.6<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Metadata Standards and Initiatives</h2>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Administrative Metadata for Electronic Resource Management</h3>
  <p class=MsoNormal><a
href="http://www.library.cornell.edu/cts/elicensestudy/home.html">http://www.library.cornell.edu/cts/elicensestudy/home.html</a></p>
  <p class=MsoNormal>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    AMICO Data Specification</h3>
  <p class=MsoNormal><a href="http://www.amico.org/AMICOlibrary/dataspec.html">http://www.amico.org/AMICOlibrary/dataspec.html</a> [Aug.
    15, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CDWA </h3>
  <p class=MsoNormal>Categories for the Description of Works of Art. The
    Report of the Art Information Task Force. http://www.getty.edu/research/institute/standards/cdwa/</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CIDOC Conceptual Reference Model (CRM)</h3>
  <p class=MsoNormal>Proposed ISO 21127. Available <a
href="http://cidoc.ics.forth.gr/index.html">http://cidoc.ics.forth.gr/index.html</a> [Aug.
    15, 2002].</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CIMI Access Points, 1995</h3>
  <p class=MsoNormal>A User Model for CIMI Z39.50 Application Profile, Kody
    Janney &amp; Jane Sledge, September 1995 Available <a
href="http://www.cimi.org/public_docs/Z3950_app_profile_0995.html">http://www.cimi.org/public_docs/Z3950_app_profile_0995.html</a> [Aug
    15, 2002]</p>
  <p class=MsoNormal><span style='font-size:9.0pt;font-family:Helvetica'><b>CIMI
        XML Schema for SPECTRUM<o:p></o:p></b></span></p>
  <p class=MsoNormal>http://www.cimi.org/wg/xml_spectrum/index.html</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Data Documentation Initiative</h3>
  <p class=MsoNormal>A standard for describing social science datasets, represented
    as an XML DTD.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Dublin Core Administrative Core</h3>
  <p class=MsoNormal>http://dublincore.org/groups/admin/</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Dublin Core Metadata Element Set (DCMES)</h3>
  <p class=MsoNormal>A set of 15 elements for simple resource description,
    used heavily in digital library applications, especially for visual materials
    and items in collections where full cataloging may not be warranted. <a
href="http://www.dublincore.org/">http://www.dublincore.org</a> [Aug. 12,
    2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Encoded Archival Description (EAD)</h3>
  <p class=MsoNormal>Machine-readable representation of archival finding
    aids, represented as an SGML DTD.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Federal Geographic Data Committee (FGDC)</h3>
  <p class=MsoNormal>The FGDC maintains this portal to geospatial metadata
    resources, including the Content Standard for Digital Geospatial Metadata
    (CSDGM).</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    MARC Standards</h3>
  <p class=MsoNormal>The LC Network Development and MARC Standards Office
    maintains this site relating to MARC Standards, which includes an HTML
    version of the MARC21 Concise Format for Bibliographic Data and other
    documentation.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Metadata Encoding and Transmission Standard (METS)</h3>
  <p class=MsoNormal>An emerging schema for encoding descriptive, administrative,
    and structural metadata regarding objects within a digital library.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    MPEG-7</h3>
  <p class=MsoNormal>International Standards Organisation / Organisation
    internationale de normalization, ISO/IEC JTCL/SC29/WG11 Coding of moving
    pictures and audio. Klangenfurt, July 2002 Available at:</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="http://mpeg.telecomitalialab.com/standards/mpeg-7/mpeg-7.htm">http://mpeg.telecomitalialab.com/standards/mpeg-7/mpeg-7.htm</a></p>
  <p class=MsoNormal>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    NISO Z39.87-2002</h3>
  <p class=MsoNormal>NISO Z39.87-2002 AIIM 20-2002 Data Dictionary - Technical
    Metadata for Digital Still Images (pdf format) Available: <a
href="http://www.niso.org/standards/resources/Z39_87_trial_use.pdf">http://www.niso.org/standards/resources/Z39_87_trial_use.pdf</a> [Aug.
    12, 2002]</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    SPECTRUM</h3>
  <p class=ReferencesText><span style='color:black'><i>SPECTRUM: The UK Museum
        Documentation Standard</i></span><span style='color:black'>, Second
        edition Revised and edited by Jeff Cowton<o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    VRA Core 3.0</h3>
  <p class=MsoEndnoteText>Visual Resources Association Data Standards Committee.
    VRA Core Categories, Version 3.0</p>
  <p class=MsoNormal>A metadata standard for describing visual resources,
    related to but much smaller than the Getty Categories for the Description
    of Art. Available <a href="http://www.vraweb.org/vracore3.htm">http://www.vraweb.org/vracore3.htm</a> [Aug.
    12, 2002]</p>
  <h1 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Related Organizations and Initatives</h1>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Image Research</h2>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Research Groups</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Lists of Research Groups</h4>
  <h5 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.1...1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Carnegie Mellon List of Groups involved in Computer Vision</h5>
  <p class=MsoNormal><span class=MsoHyperlink><span style='color:blue'><a
href="http://www-2.cs.cmu.edu/~cil/txtv-groups.html">http://www-2.cs.cmu.edu/~cil/txtv-groups.html</a></span></span>.</p>
  <p class=MsoNormal>University of Geneva list of Groups involved in Image<span
style="mso-spacerun: yes">&nbsp; </span>Retrieval </p>
  <p class=MsoNormal><span class=MsoHyperlink><span style='color:blue'><span
style="mso-spacerun: yes">&nbsp;</span><a
href="http://viper.unige.ch/other_systems/">http://viper.unige.ch/other_systems/</a><o:p></o:p></span></span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Carnegie Mellon University, Computer Vision Group </h4>
  <p class=MsoNormal><span class=MsoHyperlink><span style='color:blue'><a
href="http://www-2.cs.cmu.edu/~cil/vision.html">http://www-2.cs.cmu.edu/~cil/vision.html</a><o:p></o:p></span></span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Benchathlon</h4>
  <p class=ReferencesText>A collaboration headed by the University of Geneva
    to develop image retrieval benchmarks. <span class=MsoHyperlink><span
style='color:blue'><a href="http://www.benchathlon.net/">http://www.benchathlon.net/</a>.</span></span></p>
  <h5 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.1...1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Benchathlon Recommended Reading on CBIR and Related Topics</h5>
  <p class=ReferencesText>http://www.benchathlon.net/resources/publiByYear.html</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Massachusetts Institute of Technology, Media Lab. Vision and Modeling
    Group<span style="mso-spacerun: yes">&nbsp; </span>(no longer active)</h4>
  <p class=ReferencesText><span class=MsoHyperlink><span style='color:blue'>http://whitechapel.media.mit.edu/vismod/ <o:p></o:p></span></span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Pennsylvania State University, Multimedia Information Technology Research
    (James Z. Wang's Research Group)</h4>
  <p class=MsoNormal>previously at Stanford; <a
href="http://wang.ist.psu.edu/IMAGE">http://wang.ist.psu.edu/IMAGE</a>; recipient
    of NSF STIMULATE grant</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    University of California, Berkeley, Digital Library Project</h4>
  <p class=ReferencesText><span class=MsoHyperlink><span style='color:blue'><span
style="mso-spacerun: yes">&nbsp;</span>http://<a
href="http://www.elib.cs.berkeley.edu/">www.elib.cs.berkeley.edu</a> <o:p></o:p></span></span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    University of California, Berkeley, Computer Science Department, Computer
    Vision Group </h4>
  <p class=ReferencesText><span class=MsoHyperlink><span style='color:blue'><a
href="http://elib.cs.berkeley.edu/vision.html">http://elib.cs.berkeley.edu/vision.html</a><o:p></o:p></span></span></p>
  <h5 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.1...1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    “Computer vision Meets Digital Libraries” maintained by Kobus Barnard</h5>
  <h5 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.1...2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Browsing images from the Fine Arts Museum of San Francisco</h5>
  <p class=ReferencesText>http://elib.cs.berkeley.edu/kobus/famsf/model_2/text_and_blobs/bbox.html</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    <span style="mso-spacerun: yes">&nbsp;</span>University of Geneva, Viper
    Group</h4>
  <p class=MsoNormal>Visual Information Processing for Enhanced Retrieval; <a
href="http://viper.unige.ch/">http://viper.unige.ch/</a> <span
class=MsoHyperlink><span style='color:blue'><a
href="http://viper.unige.ch/~marchand/research/">http://viper.unige.ch/~marchand/research/</a></span></span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    University of Northumbria at Newcastle, Institute for Image Data Research</h4>
  <p class=ReferencesText><span class=MsoHyperlink><span style='color:blue'><a
href="http://www.unn.ac.uk/iidr/">http://www.unn.ac.uk/iidr/</a><o:p></o:p></span></span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    University of Washington, Department of Computer Science and Engineering</h4>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;</span><a
href="http://www.cs.washington.edu/research/imagedatabase">http://www.cs.washington.edu/research/imagedatabase</a> </p>
  <h6 style='mso-list:none;tab-stops:.5in'>(Two large NSF Grants)</h6>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Funders / Recent Projects</h2>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    United States of America: National Science Foundation <br>
    (excluding Medical Imaging)</h3>
  <p class=ReferencesText>Recent awards include</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Object and Concept Recognition for Content-Based Image Retrieval</h4>
  <p class=ReferencesText>NSF Org IIS</p>
  <p class=ReferencesText>Latest Amendment Date June 21, 2002</p>
  <p class=ReferencesText>Award Number 0097329</p>
  <p class=ReferencesText>Award Instrument Continuing grant</p>
  <p class=ReferencesText>Program Manager Bhavani Thuraisingham</p>
  <p class=ReferencesText>IIS DIV OF INFORMATION &amp; INTELLIGENT SYSTEMS</p>
  <p class=ReferencesText>CSE DIRECT FOR COMPUTER &amp; INFO SCIE &amp; ENGINR</p>
  <p class=ReferencesText>Start Date September 15, 2001</p>
  <p class=ReferencesText>Expires August 31, 2004 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $270000 (Estimated)</p>
  <p class=ReferencesText>Investigator Linda G. Shapiro shapiro@cs.washington.edu
    (Principal Investigator current)</p>
  <p class=ReferencesText>Sponsor U of Washington</p>
  <p class=ReferencesText>3935 University Way NE</p>
  <p class=ReferencesText>Seattle, WA 981056613 206/543-4043</p>
  <p class=ReferencesText>NSF Program 6855 INFORMATION &amp; DATA MANAGEMENT</p>
  <p class=ReferencesText>Field Application 0104000 Information Systems</p>
  <p class=ReferencesText>Program Reference Code 9218,HPCC,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=MsoNormal>The goal of this research is to develop the necessary
    methodology for automated recognition of generic object and concept classes
    (such as buildings, cars, boats, and trees) in digital images in order
    to substantially improve the process of content-based image retrieval,
    which has relied mainly on low-level color and texture features for matching
    queries to database images. The approach has three major aspects: (1)
    to design new high-level image features including cluster features that
    group together lower-level features and relationship features that capture
    spatial relationships among them; (2) to develop a unified representation
    that can express a large variety of both low- and high-level features
    in a form that can be used by learning systems; and (3) to automate the
    development of recognizers for object and concept classes through the
    use of a hierarchical, multiple classifier methodology. The resulting
    techniques are being evaluated on several different large image databases,
    including commercial databases whose images are grouped into broad classes
    and a ground-truth database that provides a list of the objects in each
    image. The results of this work will be a new generic object and concept
    recognition paradigm that can immediately be applied to automated or
    semi-automated indexing of large image databases. The methodology will
    help to bridge the gap between the high-level needs of users of image
    retrieval systems and the low-level features typically extracted from
    an image. The generic object class recognition algorithms we develop
    will begin a new era of object recognition research, leaving the geometric
    domain and entering the conceptual domain.</p>
  <p class=ReferencesText>https://www.fastlane.nsf.gov/servlet/showaward?award=0097329</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Efficient Content-Based Image Retrieval</h4>
  <p class=ReferencesText>NSF Org IIS</p>
  <p class=ReferencesText>Latest Amendment Date July 14, 1999</p>
  <p class=ReferencesText>Award Number 9711771</p>
  <p class=ReferencesText>Award Instrument Continuing grant</p>
  <p class=ReferencesText>Program Manager Maria Zemankova</p>
  <p class=ReferencesText>IIS DIV OF INFORMATION &amp; INTELLIGENT SYSTEMS</p>
  <p class=ReferencesText>CSE DIRECT FOR COMPUTER &amp; INFO SCIE &amp; ENGINR</p>
  <p class=ReferencesText>Start Date September 15, 1997</p>
  <p class=ReferencesText>Expires August 31, 2001 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $247000 (Estimated)</p>
  <p class=ReferencesText>Investigator Linda G. Shapiro shapiro@cs.washington.edu
    (Principal Investigator current)</p>
  <p class=ReferencesText>Sponsor U of Washington</p>
  <p class=ReferencesText>3935 University Way NE</p>
  <p class=ReferencesText>Seattle, WA 981056613 206/543-4043</p>
  <p class=ReferencesText>NSF Program 6855 INFORMATION &amp; DATA MANAGEMENT</p>
  <p class=ReferencesText>Field Application 0104000 Information Systems</p>
  <p class=ReferencesText>Program Reference Code 9139,HPCC,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=ReferencesText>The goal of this research project is to design
    and implement a system for content-based image retrieval that can (1)
    provide a large variety of image-distance measures that can be used singly
    or in combination to satisfy a wide range of user needs and (2) provide
    rapid access to images, even in an extremely large database. The focus
    of the work is the development of a general, scalable architecture to
    support fast querying of very large image databases with user-specified
    distance measures. This includes the development of distance-measure-independent
    algorithms and data structures for efficient image retrieval from large
    databases. Methods for merging the general, distance-measure-independent
    algorithms with other useful techniques that may be distance measure
    specific, such as keyword retrieval and relational indexing, are being
    pursued. The problem of providing users with multiple distance measures
    of many different varieties is being studied. New methods for combining
    distance measures and a language in which users can specify their queries
    without detailed knowledge of the underlying metrics are being designed.
    A prototype system is being implemented to test the developed methods,
    and evaluation is being performed on both a large general image database
    and a smaller controlled database. The results of this research will
    be: (1) techniques that facilitate rapid retrieval of images by eliminating
    huge portions of the image database from the search, making content-based
    retrieval feasible on very large and growing databases; (2) new, high-level
    methods by which users can combine distance measures to form meaningful
    queries, so that content-based queries can become a standard way to query
    image databases; and (3) a general framework for content-based retrieval
    that can accommodate new distance measures as they are developed by other
    research efforts. The work has application to medicine, art, photography,
    entertainment, and advertising/marketing. https://www.fastlane.nsf.gov/servlet/showaward?award=9711771</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Decentralized Image Retrieval for Education (DIRECT)</h4>
  <p class=ReferencesText>NSF Org DUE</p>
  <p class=ReferencesText>Latest Amendment Date September 10, 2001</p>
  <p class=ReferencesText>Award Number 0121596</p>
  <p class=ReferencesText>Award Instrument Standard Grant</p>
  <p class=ReferencesText>Program Manager Lee L. Zia</p>
  <p class=ReferencesText>DUE DIVISION OF UNDERGRADUATE EDUCATION</p>
  <p class=ReferencesText>EHR DIRECT FOR EDUCATION AND HUMAN RESOURCES</p>
  <p class=ReferencesText>Start Date January 1, 2002</p>
  <p class=ReferencesText>Expires August 31, 2003 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $494424 (Estimated)</p>
  <p class=ReferencesText>Investigator Scott T. Acton acton@virginia.edu
    (Principal Investigator current)</p>
  <p class=ReferencesText>Sponsor University of Virginia</p>
  <p class=ReferencesText>Post Office Box 9003</p>
  <p class=ReferencesText>Charlottesville, VA 229069003 804/924-0311</p>
  <p class=ReferencesText>NSF Program 7444 NATIONAL SMETE DIGITAL LIBRARY</p>
  <p class=ReferencesText>Field Application 0000099 Other Applications NEC</p>
  <p class=ReferencesText>Program Reference Code 7444,9178,SMET,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=ReferencesText>The Decentralized Image Retrieval for Education
    (DIRECT) project is developing a peer-to-peer content based image retrieval
    (CBIR) service for the National SMETE Digital Library program. CBIR allows
    the user to designate a query image so that the service can search the
    library for images of similar content. DIRECT matches images not by text
    metadata but by the color, texture, and shape of the image objects. With
    such a system the users of the NSDL do not need to know specialized languages
    to initiate a search. Furthermore, the matching process does not depend
    on a match between the cataloguer description and the user description.
    The system is available to all collections in the NSDL without imposing
    new standards or protocols. This offers the promise for the NSDL to support
    images that have not yet been cataloged or have incomplete metadata,
    without the image collection provider or aggregator having to incur additional
    cataloging overhead.</p>
  <p class=ReferencesText><a
href="https://www.fastlane.nsf.gov/servlet/showaward?award=0121596"><span
style='font-size:12.0pt'>https://www.fastlane.nsf.gov/servlet/showaward?award=0121596</span></a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Deriving Perceptually-Based Texture and Color Features for Image Segmentation,
    Categorization, and Retrieval</h4>
  <p class=ReferencesText>NSF Org CCR</p>
  <p class=ReferencesText>Latest Amendment Date June 21, 2002</p>
  <p class=ReferencesText>Award Number 0209006</p>
  <p class=ReferencesText>Award Instrument Continuing grant</p>
  <p class=ReferencesText>Program Manager John Cozzens</p>
  <p class=ReferencesText>CCR DIV OF COMPUTER-COMMUNICATIONS RESEARCH</p>
  <p class=ReferencesText>CSE DIRECT FOR COMPUTER &amp; INFO SCIE &amp; ENGINR</p>
  <p class=ReferencesText>Start Date June 1, 2002</p>
  <p class=ReferencesText>Expires May 31, 2005 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $300000 (Estimated)</p>
  <p class=ReferencesText>Investigator Thrasyvoulos N. Pappas pappas@ece.nwu.edu
    (Principal Investigator current)</p>
  <p class=ReferencesText>Sponsor Northwestern University</p>
  <p class=ReferencesText>633 Clark Street</p>
  <p class=ReferencesText>Evanston, IL 602081110 847/491-3003</p>
  <p class=ReferencesText>NSF Program 4720 SIGNAL PROCESSING SYS PROGRAM</p>
  <p class=ReferencesText>Field Application</p>
  <p class=ReferencesText>Program Reference Code 9216,HPCC,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=ReferencesText>The rapid accumulation of large collections of
    digital images has created the need for efficient and intelligent schemes
    for image retrieval. Since humans are the ultimate users of most retrieval
    systems, it is important to organize the contents semantically, according
    to meaningful categories. This requires an understandingof the important
    semantic categories that humans use for image classification, and the
    extraction of meaningful image features that can discriminate between
    these categories. Recent research efforts have addressed the first problem,
    but the second remains quite elusive. This research effort is aimed at
    addressing this second problem, that is, the extraction of low-level
    image features that can be correlated with high-level semantics and used
    to capture the semantic meaning of an image.</p>
  <p class=ReferencesText>The key to this research is the development of
    a new methodology for segmenting images, based on perceptual models and
    principles about the processing of texture and color information. This
    involves the identification of semantically important, spatially adaptive,
    low-level color and texture features that can be combined algorithmically
    to obtain image segmentations that convey semantic information. The same
    perceptual models and principles can be used to relate the features of
    the segmented regions (color and texture features, as well as segment
    location, size, and boundary shape) to semantic concepts that can be
    used for content-based image retrieval. An integral part of this research
    is the design and execution of subjective experiments in order to obtain
    some key parameters for the color and texture features, as well as for
    linking low-level image features to image semantics.</p>
  <p class=ReferencesText><a
href="https://www.fastlane.nsf.gov/servlet/showaward?award=0209006"><span
style='font-size:12.0pt'>https://www.fastlane.nsf.gov/servlet/showaward?award=0209006</span></a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    SGER: An Online Repository of Large Data Sets for Data Mining Research
    and Experimentation</h4>
  <p class=ReferencesText>NSF Org IIS</p>
  <p class=ReferencesText>Latest Amendment Date August 20, 1998</p>
  <p class=ReferencesText>Award Number 9813584</p>
  <p class=ReferencesText>Award Instrument Standard Grant</p>
  <p class=ReferencesText>Program Manager Maria Zemankova</p>
  <p class=ReferencesText>IIS DIV OF INFORMATION &amp; INTELLIGENT SYSTEMS</p>
  <p class=ReferencesText>CSE DIRECT FOR COMPUTER &amp; INFO SCIE &amp; ENGINR</p>
  <p class=ReferencesText>Start Date August 15, 1998</p>
  <p class=ReferencesText>Expires January 31, 2000 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $99737 (Estimated)</p>
  <p class=ReferencesText>Investigator Padhraic Smyth smyth@ics.uci.edu (Principal
    Investigator current)</p>
  <p class=ReferencesText>Dennis Kibler (Co-Principal Investigator current)</p>
  <p class=ReferencesText>Michael J. Pazzani (Co-Principal Investigator current)</p>
  <p class=ReferencesText>Sponsor U of Cal Irvine</p>
  <p class=ReferencesText>160 Administration Building</p>
  <p class=ReferencesText>Irvine, CA 926971875 949/824-7106</p>
  <p class=ReferencesText>NSF Program 6855 INFORMATION &amp; DATA MANAGEMENT</p>
  <p class=ReferencesText>Field Application 0104000 Information Systems</p>
  <p class=ReferencesText>Program Reference Code 9139,9237,HPCC,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=ReferencesText><span style='font-size:9.0pt'>Over the last two
      decades there has been an explosive growth in online data storage of
      various forms. These large datasets have motivated the rapid development
      of data mining methods. However, until now, there has been a lack of
      an online repository of large data sets for researchers to evaluate
      and compare their methods. In this project, an online repository of
      large and difficult data sets are being gathered that are representative
      of the diverse character of many important scientific and business
      domains. This repository includes high-dimensional data sets as well
      as data sets of different data types (time series, spatial data, transaction
      data, and so forth). The primary role of the repository is that of
      a benchmark testbed to enable researchers in data mining (including
      computer scientists, statisticians, engineers, and mathematicians)
      to scale existing and future data analysis algorithms to very large
      data sets. Each data set in the respository contains online documentation,
      metadata, and links to relevant background domain information such
      as prior published work. Availability of a standard set of large benchmark
      data sets will directly stimulate and foster systematic progress in
      data mining related research, similar to the affect that the UCI Machine
      Learning Data Repository has had on machine learning research. This
      repository will play a substantial role in brokering the gap between
      research-oriented algorithm development in the laboratory and the real-world
      practicalities and challenges of very large data sets. <a
href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a><o:p></o:p></span></p>
  <p class=ReferencesText><span style='font-size:9.0pt'><a
href="https://www.fastlane.nsf.gov/servlet/showaward?award=9813584">https://www.fastlane.nsf.gov/servlet/showaward?award=9813584</a><o:p></o:p></span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Metadata Model, Resource Discovery, and Querying on large-scale Multidimensional
    Datasets</h4>
  <p class=ReferencesText>NSF Org IIS</p>
  <p class=ReferencesText>Latest Amendment Date July 23, 2002</p>
  <p class=ReferencesText>Award Number 9905603</p>
  <p class=ReferencesText>Award Instrument Continuing grant</p>
  <p class=ReferencesText>Program Manager Stephen Griffin</p>
  <p class=ReferencesText>IIS DIV OF INFORMATION &amp; INTELLIGENT SYSTEMS</p>
  <p class=ReferencesText>CSE DIRECT FOR COMPUTER &amp; INFO SCIE &amp; ENGINR</p>
  <p class=ReferencesText>Start Date August 15, 2000</p>
  <p class=ReferencesText>Expires July 31, 2003 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $400000 (Estimated)</p>
  <p class=ReferencesText>Investigator Aidong Zhang azhang@cse.buffalo.edu
    (Principal Investigator current)</p>
  <p class=ReferencesText>David M. Mark (Co-Principal Investigator current)</p>
  <p class=ReferencesText>Raj Acharya (Co-Principal Investigator current)</p>
  <p class=ReferencesText>Sponsor SUNY Buffalo</p>
  <p class=ReferencesText>501 Capen Hall</p>
  <p class=ReferencesText>Buffalo, NY 14260 716/645-2977</p>
  <p class=ReferencesText>NSF Program 6857 SPECIAL PROJECTS (IIS)</p>
  <p class=ReferencesText>Field Application 0104000 Information Systems</p>
  <p class=ReferencesText>Program Reference Code 1364,9216,HPCC,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=ReferencesText>The objective of the proposed research is to investigate
    novel approaches to supporting effective and efficient access to various
    geographic image databases over the Internet leading to design of distributed
    geographic image retrieval systems. The research involves three research
    teams from: SUNY Buffalo, National Center for Science Information Systems
    (NACSIS) in Japan, and the University of Nantes in France. (IRESTE) The
    technical challenges are the creation of a new meta-level system for
    geographic image databases. To achieve this, research issues concerned
    with representation models for geographic data, relationships between
    metadata and resource discovery and efficient query processing in a distributed
    environment must be addressed. The problems addressed are critical to
    retrieval on large volume, multidimensional, distributed data over the
    Internet. Results can be broadly applied to numerous domain and interdisciplinary
    research areas.</p>
  <p class=ReferencesText><a
href="https://www.fastlane.nsf.gov/servlet/showaward?award=9905603"><span
style='font-size:12.0pt'>https://www.fastlane.nsf.gov/servlet/showaward?award=9905603</span></a></p>
  <p class=ReferencesText>NSF Award Abstract - #9619117 AWSFL008-DS3</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    STIMULATE: Multimodal Indexing, Retrieval, and Browsing: Combining Content-Based
    Image Retrieval with Text Retrieval</h4>
  <p class=ReferencesText>NSF Org IIS</p>
  <p class=ReferencesText>Latest Amendment Date February 23, 2001</p>
  <p class=ReferencesText>Award Number 9619117</p>
  <p class=ReferencesText>Award Instrument Continuing grant</p>
  <p class=ReferencesText>Program Manager Michael E. Lesk</p>
  <p class=ReferencesText>IIS DIV OF INFORMATION &amp; INTELLIGENT SYSTEMS</p>
  <p class=ReferencesText>CSE DIRECT FOR COMPUTER &amp; INFO SCIE &amp; ENGINR</p>
  <p class=ReferencesText>Start Date March 1, 1997</p>
  <p class=ReferencesText>Expires February 28, 2002 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $769111 (Estimated)</p>
  <p class=ReferencesText>Investigator James M. Allan allan@cs.umass.edu
    (Principal Investigator current)</p>
  <p class=ReferencesText>Raghavan Manmatha (Co-Principal Investigator current)</p>
  <p class=ReferencesText>Allen R. Hanson (Co-Principal Investigator former)</p>
  <p class=ReferencesText>Sponsor U of Massachusetts Amherst</p>
  <p class=ReferencesText>408 Goodell Building</p>
  <p class=ReferencesText>Amherst, MA 010033285 413/545-0698</p>
  <p class=ReferencesText>NSF Program 6845 HUMAN COMPUTER INTER PROGRAM</p>
  <p class=ReferencesText>Field Application 0104000 Information Systems</p>
  <p class=ReferencesText>0116000 Human Subjects</p>
  <p class=ReferencesText>Program Reference Code 9139,HPCC,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=ReferencesText>*** In the rapidly emerging area of multimedia
    information systems, effective indexing and retrieval techniques are
    critically important. In this project, the Center for Intelligent Information
    Retrieval (CIIR) will study algorithms and mechanisms that facilitate
    the.process of indexing and retrieving images, video, and associated
    text. Specifically, the CIIR will: 1) Develop techniques for browsing
    and retrieving images and videos by content. Image indexing is an emerging
    technology which is poorly understood. New and powerful techniques will
    be developed for indexing images and videos using visual attributes such
    as color, texture and 'appearance'; 2) Develop techniques for indexing
    images and videos using text present in the images. Methods of assisting
    with manual annotation of images will also be studied. The text indexing
    methods will be combined using the INQUERY probabilistic retrieval engine;
    3) Develop and evaluate interactive retrieval and browsing interfaces
    for image, video, and text retrieval. These interfaces will be based
    on novel visualization and user interface work done at CIIR. The CIIR
    will perform user studies to evaluate the appeal and effectiveness of
    the interfaces. In summary, the project will integrate innovative image
    matching, sophisticated text retrieval and new query formulation and
    visualization methods to create a powerful platform for indexing and
    retrieving images, video, and text.***</p>
  <p class=ReferencesText><a
href="https://www.fastlane.nsf.gov/servlet/showaward?award=9619117"><span
style='font-size:12.0pt'>https://www.fastlane.nsf.gov/servlet/showaward?award=9619117</span></a></p>
  <p class=ReferencesText>NSF Award Abstract - #9908441 AWSFL008-DS3</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Invariant, Intra-Class Retrieval in Digital Image Databases</h4>
  <p class=ReferencesText>NSF Org IIS</p>
  <p class=ReferencesText>Latest Amendment Date August 21, 2001</p>
  <p class=ReferencesText>Award Number 9908441</p>
  <p class=ReferencesText>Award Instrument Continuing grant</p>
  <p class=ReferencesText>Program Manager Bhavani Thuraisingham</p>
  <p class=ReferencesText>IIS DIV OF INFORMATION &amp; INTELLIGENT SYSTEMS</p>
  <p class=ReferencesText>CSE DIRECT FOR COMPUTER &amp; INFO SCIE &amp; ENGINR</p>
  <p class=ReferencesText>Start Date October 1, 2000</p>
  <p class=ReferencesText>Expires October 31, 2003 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $211000 (Estimated)</p>
  <p class=ReferencesText>Investigator Yuan-Fang Wang yfwang@cs.ucsb.edu
    (Principal Investigator current)</p>
  <p class=ReferencesText>Sponsor U of Cal Santa Barbara</p>
  <p class=ReferencesText>c/o Office of Research</p>
  <p class=ReferencesText>Santa Barbara, CA 93106 805/893-4188</p>
  <p class=ReferencesText>NSF Program 6855 INFORMATION &amp; DATA MANAGEMENT</p>
  <p class=ReferencesText>Field Application 0104000 Information Systems</p>
  <p class=ReferencesText>Program Reference Code 9216,HPCC,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=ReferencesText>Many image databases employ image features that
    describe the aggregate shape and color properties of a class of objects,
    and hence, are only capable of &quot;inter-classes&quot; discrimination
    (e.g., airplanes vs. butterflies). These features are sensitive to incidental
    changes in camera viewpoint and scene illumination, which severely constrain
    the appearance of query objects. The goal of this project is to design
    a set of new image-derived features which utilize detailed local image
    analysis to enable discriminating objects of very similar appearance
    within the same class (e.g., &quot;intra-class&quot; discrimination of
    different species of butterflies in a database of butterflies). These
    new features capture the essential traits of imaged objects in a way
    that is insensitive to incidental changes in both global environmental
    factors, such as viewpoint and illumination, and local configuration,
    such as shape deformation and articulated motion. The project addresses
    the efficiency and utility issues in deploying these invariant features
    in large, real-world image databases. In particular, flexible class templates
    are constructed for automating image segmentation and cataloging of database
    objects. Invariant image features are organized in a hierarchical manner,
    using both image-derived and domain-specific information, for efficient
    pruning of unlikely matches. A representation strategy, which combines
    global structure models with local invariant features, is used to achieve
    recognition insensitive to incidental articulated motion and deformation.
    As a result, the new image features are highly discriminative yet insensitive
    to incidental changes in shape, viewpoint, and illumination. In particular,
    they enable invariant, intra-class image retrieval, i.e., highly precise
    recognition and retrieval of images in large databases of similar objects
    (e.g., retrieving images of Old World Swallowtails from a database of
    butterflies) with few constraints on the appearance of query images.
    The results of the project will be disseminated by scientific papers,
    software that can be downloaded, and prototype image databases that can
    be queried on the Web. <a
href="http://www.cs.ucsb.edu/~yfwang"><span style='font-size:12.0pt'>http://www.cs.ucsb.edu/~yfwang</span></a></p>
  <p class=ReferencesText><a
href="https://www.fastlane.nsf.gov/servlet/showaward?award=9908441"><span
style='font-size:12.0pt'>https://www.fastlane.nsf.gov/servlet/showaward?award=9908441</span></a></p>
  <p class=ReferencesText>[NSF Logo] NSF Award Abstract - #0136348 AWSFL008-DS3</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    SGER: Flexible Index Structure for Relevance Feedback Content-Based Retrieval
    in Large Image Databases</h4>
  <p class=ReferencesText>NSF Org IIS</p>
  <p class=ReferencesText>Latest Amendment Date November 19, 2001</p>
  <p class=ReferencesText>Award Number 0136348</p>
  <p class=ReferencesText>Award Instrument Standard Grant</p>
  <p class=ReferencesText>Program Manager Bhavani Thuraisingham</p>
  <p class=ReferencesText>IIS DIV OF INFORMATION &amp; INTELLIGENT SYSTEMS</p>
  <p class=ReferencesText>CSE DIRECT FOR COMPUTER &amp; INFO SCIE &amp; ENGINR</p>
  <p class=ReferencesText>Start Date November 1, 2001</p>
  <p class=ReferencesText>Expires September 30, 2002 (Estimated)</p>
  <p class=ReferencesText>Expected Total Amount $50000 (Estimated)</p>
  <p class=ReferencesText>Investigator Jing Peng jp@eecs.tulane.edu (Principal
    Investigator current)</p>
  <p class=ReferencesText>Douglas R. Heisterkamp (Co-Principal Investigator
    current)</p>
  <p class=ReferencesText>Sponsor Tulane University</p>
  <p class=ReferencesText>6823 St. Charles Avenue</p>
  <p class=ReferencesText>New Orleans, LA 701185665 504/865-4000</p>
  <p class=ReferencesText>NSF Program 6855 INFORMATION &amp; DATA MANAGEMENT</p>
  <p class=ReferencesText>Field Application 0104000 Information Systems</p>
  <p class=ReferencesText>Program Reference Code 9218,9237,HPCC,</p>
  <p class=ReferencesText>Abstract</p>
  <p class=ReferencesText>The objective of this project is to design efficient
    indexing strategies that support flexible retrieval metric through relevance
    feedback learning. However, trying to satisfy both goals (efficiency
    and flexibility) at the same time leads to a conflict. A novel approach
    is explored to capture the inherent interplay between flexible metrics
    and indexing that has the potential to resolve the conflict. It is hypothesized
    that the interplay can be exploited to create effective content-based
    retrieval systems that meet performance and computational challenges
    encountered in practical image database applications. This exploratory
    project seeks to establish the proof of concept of an approach that trades
    off accuracy for efficiency, and that can avoid exhaustive search in
    large-scale image databases. The methods to be explored are based on
    bump-hunting in high-dimensional data for inducing a set of (possibly
    overlapping) boxes that capture the local data distributions. The induced
    boxes effectively cover the feature space, thereby providing an index
    to the image database. The flexibility and efficiency of the novel indexing
    technique will be tested in heterogeneous image databases that support
    a variety of query types, ranging from query-by-image to query-by-region.
    If successful, the results of this project will enable the use of flexible
    metric learning in large scale image databases, which will have a significant
    impact in content-based image retrieval in broad areas such as health-care,
    scientific images, education, or art.</p>
  <p class=ReferencesText>https://www.fastlane.nsf.gov/servlet/showaward?award=0136348</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Andrew W. Mellon Foundation</h3>
  <p class=ReferencesText>http://www.mellon.org</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CliMB, Columbia University</h4>
  <p class=ReferencesText>“One of the most serious bottlenecks in digitizing
    collections is in making them easy to search. The strategy proposed has
    the potential to provide rich, subject-oriented indexing for large image
    collections that would otherwise be prohibitively expensive to describe
    and index using manual techniques. A further advantage of the approach
    is that the descriptive metadata generated may be derived from authoritative
    scholarship in a way not normally feasible in standard cataloging practice.
    The project goal of CLiMB is to develop and test automatic approaches
    to the creation of descriptive metadata for improving access to digital
    library special collections. http://www.columbia.edu/cu/lweb/news/files/2002-04-26.climb.html
    [Aug 15, 2002.]</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    VIUS, Pennsylvania State University</h4>
  <p class=ReferencesText>The Andrew W. Mellon Foundation has awarded $755,000
    to the Penn State University Libraries to support an extensive study
    of digital image delivery.</p>
  <p class=MsoNormal>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Leading the study, the Libraries will partner with
    other Penn State units, including the Center for Education Technology
    Services, the Center for Quality and Planning, Library Computing Services,
    and the School of Information Sciences and Technology. The Visual Image
    User Study (VIUS, pronounced views) will examine the use of digital pictures
    at Penn State in the disciplines of the arts, environmental studies,
    and the humanities. The project includes the development and testing
    of a prototype system for image delivery.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Phase one of the project will employ a variety
    of needs assessment methods and information retrieval studies to analyze
    current and future needs of teachers, learners, and archival managers.
    The second phase, based on the results of phase one, will create the
    design and content of the prototype system.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Reviewers of the plan praise its client-centered
    approach, interdisciplinary scope, institutional teamwork, and potential
    to contribute useful data to an important aspect of digital library development.
    The project began in May 2001, and activities will continue for twenty-six
    months.</p>
  <p class=ReferencesText><span style="mso-spacerun:
yes">&nbsp;</span>http://www.libraries.psu.edu/crsweb/vius/section1.html#1-1</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    United Kingdom, Library and Information Commission<br>
    <span style="mso-spacerun: yes">&nbsp;</span><span class=MsoHyperlink><span
style='font-size:10.0pt;font-family:AGaramond;text-decoration:none;text-underline:
none;font-weight:normal'><a href="http://www.lic.gov.uk/awards/ir-curpj.html"><span
style='color:windowtext;text-decoration:none;text-underline:none'>http://www.lic.gov.uk/awards/ir-curpj.html</span></a></span></span> </h3>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Evaluation of Content-Based Image Retrieval in an operational setting</h4>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Grant number: RE/103</p>
  <p class=ReferencesText>Grantee: University of Northumbria at Newcastle</p>
  <p class=ReferencesText>Duration of grant: 1 January 2000 - 31 December
    2001</p>
  <p class=ReferencesText>Amount of award: £69,045</p>
  <p class=ReferencesText>Contact: Mrs Margaret Graham</p>
  <p class=ReferencesText>Address: Institute for Image Data Research, University
    of Northumbria at Newcastle, Newcastle upon Tyne NE1 8ST</p>
  <p class=ReferencesText>Tel: 0191-227 4646</p>
  <p class=ReferencesText>Fax: 0191-227 4637</p>
  <p class=ReferencesText>Email: margaret.graham@unn.ac.uk</p>
  <p class=ReferencesText>WWW: http://www.unn.ac.uk/iidr/staff/margaret.html</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>In recent years there has been enormous growth
    in interest in the potential of digital images, especially as technological
    advances make it now possible to store and access large quantities of
    data relatively cheaply. Coupled to this has been the rapid growth if
    imaging on the World Wide Web (WWW). Many organisations are taking advantage
    of various funding opportunities to digitise parts or all of their collections.
    But the process of digitisation does not in itself make image collections
    easier to manage or to use. There are several computerised image data
    management systems on the market which help to organise and view the
    digital images. Some forms of cataloguing and indexing are still necessary,
    since browsing is not an option except with small collections. These
    problems have stimulated research into content-based image retrieval
    (CBIR), the selection of images from a collection via features automatically
    extracted from the images themselves. Current CBIR systems typically
    provide image retrieval by low-level attributes such as colour, texture
    or shape, and few attempt higher levels of retrieval, such as by semantic
    content (e.g. the presence in an image of specific types of object, or
    the depiction of a particular type of event). There has been little systematic
    evaluation of CBIR system effectiveness on a large scale. Key questions,
    such as whether CBIR techniques can bring about worthwhile improvements
    in performance with real-life image retrieval systems, or where and how
    such techniques can most profitably be used, thus remain unanswered.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>The aim of this research is to evaluate CBIR systems
    in an operational setting. The project will install appropriate commercially-available
    CBIR software as additional functionality to the image data management
    systems currently in use in three pictorial libraries in the public and
    private sectors. An initial user study will be conducted to obtain the
    first impressions of the CBIR functionality by both staff and other end-users.
    Following a six months &quot;gestation&quot; period, detailed user evaluations
    will then be conducted. The outcomes will be three case studies, demonstrating
    CBIR in practice, and a body of evidence regarding the usefulness and
    effectiveness of CBIR as a searching tool in the context of the individual
    organisations. Specific research questions which will be investigated
    include:</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    How successful are CBIR systems in meeting user needs?</p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    What are the effects of CBIR provision on user search behaviour?</p>
  <p class=ReferencesText style='margin-left:26.0pt;text-indent:-.25in;
mso-list:l3 level1 lfo36;mso-list-change:\F0B7 "J\. Trant" 20040105T1655;
tab-stops:list 26.0pt'>
    <![if !supportLists]>
    <span style='font-family:Symbol'>·<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    To what extent can the use of CBIR systems be justified in different
    contexts?</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    VISOR II - a user-oriented evaluation framework for the development of
    electronic image retrieval systems in the workplace</h4>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Grant number: RE/104</p>
  <p class=ReferencesText>Grantee: University of Northumbria at Newcastle</p>
  <p class=ReferencesText>Duration of grant: 1 June 2000 - 31 May 2001</p>
  <p class=ReferencesText>Amount of award: £43,136</p>
  <p class=ReferencesText>Contact: Mrs Margaret Graham</p>
  <p class=ReferencesText>Address: Institute for Image Data Research, University
    of Northumbria at Newcastle, Newcastle upon Tyne NE1 8ST</p>
  <p class=ReferencesText>Tel: 0191-227 4646</p>
  <p class=ReferencesText>Fax: 0191-227 4637</p>
  <p class=ReferencesText>Email: margaret.graham@unn.ac.uk</p>
  <p class=ReferencesText>WWW: http://www.unn.ac.uk/iidr/staff/margaret.html</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>The chief aim of the project is to develop a user-oriented
    evaluation framework for electronic image retrieval in the workplace.
    This framework would span the overall process of image retrieval system
    design, development and implementation - something which includes an
    ongoing process of evaluation throughout all these stages. It is primarily
    intended as a practical tool to assist and guide those responsible for
    conducting evaluations of image retrieval systems from the user's perspective,
    though there are other potential benefits for researchers, professional
    groups and organisations as well as users themselves.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>This endeavour will utilise and build upon the
    results of and groundwork laid by the first phase of the VISOR research
    programme (Information seeking behaviour in image retrieval, LIC project
    LIC/RE/031). Thus the models of user search behaviour focus on users
    of images in context and this will lie at the heart of the development
    of an evaluation tool.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>A central focus of the evaluation framework will
    be the consideration of how well the system supports the user in their
    work, particularly in terms of functionality, interface/access and decision
    support. It must be emphasised that a search system and the search process
    together form the entire information searching and retrieval process
    and it is not acceptable to evaluate the system alone. The image retrieval
    systems will therefore be evaluated in context and from a user-oriented
    perspective.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>The evaluation tool will be developed by performing
    user-centred system evaluations with existing image retrieval systems
    currently in use in various organisations. The initial evaluation procedure
    will be informed by the models of image seeking behaviour developed during
    VISOR I, by a comprehensive review of the relevant literature and by
    input from experts in the field of evaluation. The results of the practical
    work conducted during a pilot phase (i.e. initial user-centred system
    evaluations) will be used to reformulate the evaluation procedure accordingly.
    The resulting procedure will then be used in a second organisation to
    verify the approach and make further modifications as necessary. Finally,
    an evaluation framework to guide the development of electronic image
    retrieval systems will be formulated, incorporating the experience gained
    throughout VISOR II. Throughout the project, feedback sessions will be
    held with both participant organisations and experts in the field.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Information seeking behaviour in image retrieval</h4>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Grant number: RE/031</p>
  <p class=ReferencesText>Grantee: University of Northumbria at Newcastle</p>
  <p class=ReferencesText>Duration of grant: 5 May 1998 to 4 May 2000</p>
  <p class=ReferencesText>Amount of award: £60,560</p>
  <p class=ReferencesText>Contact: Margaret E Graham</p>
  <p class=ReferencesText>Address: Institute for Image Data Research, University
    of Northumbria at Newcastle, Ellison Building, Newcastle upon Tyne NE1
    8ST</p>
  <p class=ReferencesText>Tel: 0191 227 4646</p>
  <p class=ReferencesText>Fax: 0191 227 4637</p>
  <p class=ReferencesText>Email: margaret.graham@unn.ac.uk</p>
  <p class=ReferencesText>WWW: http://www.unn.ac.uk/iidr/staff/margaret.html</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>The aim of this project is to investigate the information-seeking
    behaviour of image users in specific disciplines or domains, in order
    to increase our understanding of how and why people seek for and use
    visual information. It is intended that the results should influence
    the design of future image retrieval systems so that digital collections
    of images can be exploited to their full potential.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>There is a wealth of research into users' information-seeking
    behaviour, but almost exclusively in the area of textual information.
    There is little understanding of how people seek for or use images. Recently,
    there has been research and development activity in so-called content-based
    image retrieval (CBIR) where images are selected from a collection via
    features automatically extracted from the images themselves. Current
    CBIR systems typically provide image retrieval by low-level attributes
    such as colour, texture or shape, and few attempt higher levels of retrieval,
    such as by semantic content (e.g. the presence in an image of specific
    types of object, or the depiction of a particular type of event). How
    important is colour, texture or shape to the retrieval of visual information?
    When, and by whom, are higher levels of retrieval needed? What searching
    strategies are appropriate for image retrieval? How important is browsing
    to the retrieval of visual information?</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>The research will be essentially qualitative in
    nature. The project will study the behaviour of real users of visual
    information in real situations. It will build up a series of case studies
    based on representative organisations from within certain subject domains,
    such as Architecture, Medicine, Journalism and Art History, and will
    study subjects in these organisations who use images/visual information
    as part of their normal work. Through the analysis of relevant documentation
    and current systems and the recordings of interviews and observations,
    the project will categorise the uses of images in different domains and
    thus develop models of the information seeking behaviour of image users.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Design and implementation factors in electronic image retrieval systems</h4>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Grant number: RE/029</p>
  <p class=ReferencesText>Grantee: University of Brighton</p>
  <p class=ReferencesText>Duration of grant: 20th March 1998 to 30th June
    2000</p>
  <p class=ReferencesText>Amount of award: £54,429</p>
  <p class=ReferencesText>Contact: Dr P G B Enser</p>
  <p class=ReferencesText>Address: School of Information Management, University
    of Brighton, Watts Building, Moulsecoomb, Brighton BN2 4GJ</p>
  <p class=ReferencesText>Tel: 01273 643505</p>
  <p class=ReferencesText>Fax: 01273 642405</p>
  <p class=ReferencesText>Email: P.G.B.Enser@brighton.ac.uk</p>
  <p class=ReferencesText>WWW: http://www.it.bton.ac.uk/im/</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>This project aims to contribute to the development
    of effective retrieval mechanisms for visual image material. It will
    seek to develop deeper, evaluative insights into the emerging and future
    practice of image retrieval, looking beyond the technical characteristics
    and embracing the economic, political and social factors which are shaping
    the design and implementation of electronic visual information retrieval
    systems among the library/information service, gallery and museum communities.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Central to this endeavour is a recognition of the
    need to find effective indexing and retrieval strategies amid the proliferation
    of techniques and tools for the storage and manipulation of digitised
    images. The imperative to incorporate, to a far greater extent, the real
    needs of end-users and to move to a standardised platform, or approach,
    for visual information retrieval developments are clearly indicated and
    will also figure prominently in the project.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>The objective is to produce a state-of-the-art
    review of the planning, organisation and implementation of electronic
    visual information retrieval systems, based on a study of a representative
    selection of organisations and their client interaction. The study will
    involve the identification of key participants and decision processes,
    the examination of individual system solutions and the local and sectoral
    contexts within which these solutions emerge.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>By providing a richer picture of the diverse elements
    which form the inputs and outcomes of current initiatives in visual information
    retrieval systems for existing customer bases, the study seeks to engage
    with the economic, political and social factors which will condition
    the further development of such systems. From this examination, a guide
    to good practice will be generated, of relevance to those many organisations
    which are planning to update to electronic visual information retrieval
    mechanisms in the next few years.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Image retrieval through perceptual shape modelling</h4>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Grant number: RE/013</p>
  <p class=ReferencesText>Grantee: University of Northumbria at Newcastle</p>
  <p class=ReferencesText>Duration of grant: 25th July 1997 to 24th July
    2000</p>
  <p class=ReferencesText>Amount of award: £99,250</p>
  <p class=ReferencesText>Contact: Dr J P Eakins</p>
  <p class=ReferencesText>Address: Department of Computing, University of
    Northumbria at Newcastle, Ellison Place, Newcastle upon Tyne NE1 8ST.</p>
  <p class=ReferencesText>Tel: 0191 227 4539</p>
  <p class=ReferencesText>Fax: 0191-227 3662</p>
  <p class=ReferencesText>Email: john.eakins@unn.ac.uk</p>
  <p class=ReferencesText>WWW: http://computing.unn.ac.uk/~johne/IIDR.html</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>Effective shape retrieval is still proving an elusive
    goal; no current system appears able to mirror human judgements of shape
    similarity with sufficient reliability. One possible reason for this
    is that virtually all current shape retrieval systems derive indexing
    features purely from explicit representations of image elements such
    as region boundaries. The ARTISAN system, developed at the University
    of Northumbria at Newcastle under a previoue British Library Research
    and Innovation Centre grant, is an exception to this, in that it derives
    indexing features from virtual boundaries generated by grouping image
    regions into families using principles derived from Gestalt psychology.
    Cognitive psychologists have accumulated a considerable body of evidence
    about the way the human eye and brain perceive and interpret an image.
    ARTISAN appears to yield promising retrieval results, even though it
    makes only limited use of such findings.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>The aim of the present investigation is therefore
    to test the extent to which a systematic application of findings from
    human visual cognition studies can improve retrieval performance. The
    investigation will review the current state of the art in human visual
    perception in some depth, identifying hypotheses and experimental findings
    of potential relevance to shape retrieval. A model of the shape retrieval
    process will be constructed, and used to guide the development of an
    improved shape retrieval prototype, capable of representing and matching
    shapes more effectively than any current system. Specific aspects on
    which the model is expected to concentrate include:</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    replacing ill-defined image elements with &quot;idealized&quot; equivalents</p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    building up multi-view representations of &quot;ambiguous&quot; shapes,
    allowing alternative interpretations of their content</p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    investigating the utility of fractal shape representation techniques</p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    measuring the salience of different types of image feature to a given
    query</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>The effectiveness of this model of the shape retrieval
    process will be tested by measuring its effect on retrieval performance
    over the same set of test queries and images as that supplied by the
    Patent Office for the evaluation of the earlier ARTISAN system. It is
    expected that this study will lead to a significant improvement in the
    understanding of the shape retrieval process, which should enable the
    development of more powerful image retrieval systems in the future.</p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <p class=ReferencesText>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    <span style="mso-spacerun: yes">&nbsp;</span>United Kingdom, Resource<br>
    <span style="mso-spacerun: yes">&nbsp;</span><span class=MsoHyperlink><span
style='color:blue'><a href="http://www.resource.gov.uk/">http://www.resource.gov.uk/</a>,</span></span></h4>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></h4>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    European Union, European Commission, Information Society Directorate
    General</h3>
  <p class=ReferencesText><span style='color:black'>http://www.europa.eu.int/comm/dgs/information_society/index_en.htm</span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></h3>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></h3>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.3<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Conferences and Societies </h2>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Lists of Conferences</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span class=MsoHyperlink><span
style='text-decoration:none;text-underline:none'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span>
    <![endif]>
    Maintained by the Multimedia Information Processing Group, of Eurécom<span style="mso-spacerun: yes">&nbsp; </span><span
class=MsoHyperlink><span style='color:blue'><a
href="http://www.eurecom.fr/~bmgroup/conferences.html">http://www.eurecom.fr/~bmgroup/conferences.html</a></span></span><span
class=MsoHyperlink><span style='text-decoration:none;text-underline:none'><o:p></o:p></span></span></h4>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    ACM SIG-MM</h3>
  <p class=ReferencesText>Association of Computing<span style="mso-spacerun:
yes">&nbsp; </span>Machinery (ACM) SIG Multimedia </p>
  <p class=ReferencesText>http://www.acm.org/sigmm/</p>
  <p class=ReferencesText><span class=MsoHyperlink><span style='color:blue'><a
href="http://www.nii.ac.jp/mir2000/">http://www.nii.ac.jp/mir2000/</a>;<o:p></o:p></span></span></p>
  <p class=MsoEndnoteText><span class=MsoHyperlink><span style='color:blue'><span
style="mso-spacerun: yes">&nbsp;</span><a href="http://www.info.uqam.ca/~misrm/">http://www.info.uqam.ca/~misrm/</a>); <o:p></o:p></span></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    ACM SIG-IR</h3>
  <p class=MsoNormal>Association of Computing Machinery (ACM) Special interest
    group on Information Retrieval </p>
  <p class=MsoNormal>http://www.acm.org/sigir/</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    ACM/IEEE- JDL</h3>
  <p class=ReferencesText>Association of Computer Machinery / Institute for
    Electronic and Electrical Engineering Joint Conference on Digital Libraries</p>
  <p class=ReferencesText>http://www.jcdl.org/</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    ASIS&amp;T</h3>
  <p class=MsoNormal>American Society for Information Science and Technology</p>
  <p class=MsoNormal>http://www.asis.org</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Challenge of Image Retrieval / Challenge of Image and Video Retrieval
    . CIR<span style="mso-spacerun: yes">&nbsp; </span>/ CIVR.</h3>
  <p class=MsoNormal>http://www.civr.org</p>
  <p class=MsoNormal>Challenge of Image Retrieval, 1998</p>
  <p class=MsoNormal>Challenge of Image Retrieval, 1999</p>
  <p class=MsoNormal>Challenge of Image Retrieval, 2000</p>
  <p class=MsoNormal>Challenge of Image and Video Retrieval, 2002 <a
href="http://www.civr2002.org/">http://www.civr2002.org/</a> Proceedings:
    Springer Lecture Notes in Computer Science series. Vol 2383</p>
  <p class=MsoNormal>Challenge of Image and Video Retrieval, 2003</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Computer Vision and Pattern Recognition (since 1997)</h3>
  <p class=MsoNormal>IEEE Computer Society Conference on Computer Vision
    and Pattern Recognition</p>
  <p class=MsoNormal>http://www.cs.toronto.edu/cvpr2003/</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    DELOS </h3>
  <p class=ReferencesText><a
href="http://www.ercim.org/publication/ws-proceedings/DELOS4/index.html"><b>http://www.ercim.org/publication/ws-proceedings/DELOS4/index.html</b></a></p>
  <p class=MsoNormal>DELOS Network of Excellence for Digital Libraries</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    ECDL</h3>
  <p class=MsoNormal>European Conference on Digital Libraries</p>
  <p class=MsoNormal>http://www.ecdl2003.org/</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Int. Conf. on Visual Information Systems</h3>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    IS&amp;T</h3>
  <p class=ReferencesText>The Society for Imaging Science and Technology</p>
  <p class=ReferencesText>http://www.imaging.org</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    IV</h3>
  <p class=ReferencesText>International Conference on Information Visualisation,
    IV 2000, 19-21 July 2000, London, England, UK. IEEE Computer Society,
    online publications: <span class=MsoHyperlink><span style='color:blue'><a
href="http://computer.org/proceedings/iv/0743/0743toc.htm">http://computer.org/proceedings/iv/0743/0743toc.htm</a></span></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    JDL</h3>
  <p class=MsoNormal>ACM/IEEE Joint Conference on Digital Libraries</p>
  <p class=MsoNormal>http://www.acm.org/jcdl/</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Electronic Imaging Science and Technology</h3>
  <p class=MsoNormal>SPIE / IS&amp;T / Internet Imaging</p>
  <p class=MsoNormal>http://electronicimaging.org/Program/03/</p>
  <p class=ReferencesText>The International Society for Optical Engineering. </p>
  <p class=MsoNormal><a href="http://www.spie.org/">http://www.spie.org</a></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Others</h3>
  <p class=ReferencesText>All over in information science, digital libraries,
    museum studies/informatics, computer science; the field is not coherent.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Museums and the Web </h4>
  <p class=ReferencesText>Archives &amp; Museum Informatics: annual, since
    1997</p>
  <p class=ReferencesText><span class=MsoHyperlink><span style='color:blue'>http://www.archimuse.com/mw.html </span></span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    International Cultural Heritage Informatics Meetings</h4>
  <p class=MsoNormal>Archives &amp; Museum Informatics http://www.archimuse.com/ichim.html</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Digital Resources in the Humanities </h4>
  <p class=MsoNormal>http:://www.drh.org.uk/</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    EVA </h4>
  <p class=ReferencesText>regularly throughout Europe since 1995</p>
  <p class=MsoNormal>Electronic Imaging in the Visual Arts Conference Series</p>
  <p class=MsoNormal><a href="http://www.vasari.co.uk/eva/index.htm">http://www.vasari.co.uk/eva/index.htm</a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    LITA</h4>
  <p class=MsoNormal>Library and Information Technology Association, a Division
    of the American Library Association</p>
  <p class=MsoNormal>http://www.lita.org/</p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    2.4<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Benchmarking Organizations in the Information Industry</h2>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    SPEC Standard Performance Evaluation Corporation</h3>
  <p class=ReferencesText><a href="http://www.specbench.org/">http://www.specbench.org/</a> “MISSION:
    To establish, maintain, and endorse a standardized set of relevant benchmarks
    and metrics for performance evaluation of modern computer systems</p>
  <p class=ReferencesText>Frequently Asked Questions at <a
href="http://www.specbench.org/spec/faq/">http://www.specbench.org/spec/faq/</a></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    ISOBenchmarking Association</h3>
  <p class=ReferencesText>http://www.isobenchmarking.com<span style='font-size:
8.0pt'><br style='mso-special-character:line-break'>
    <![if !supportLineBreakNewLine]>
    <br style='mso-special-character:line-break'>
    <![endif]>
    <o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Information Systems Management Benchmarking Consortium ™ (ISMBC™)</h3>
  <p class=MsoNormal><span style='font-size:8.0pt'>http://www.ismbc.org<o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    ISO Benchmarking Association™ </h3>
  <p class=MsoNormal><span style='font-size:8.0pt'><a
href="http://www.isobenchmarking.com/">http://www.isobenchmarking.com/</a><o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Knowledge Management Benchmarking Association (KMBA™)</h3>
  <p class=MsoNormal><span style='font-size:8.0pt'>http://www.kmba.org<o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Telecommunications Benchmarking International Group </h3>
  <p class=MsoNormal><span style='font-size:8.0pt'><a href="http://www.tbig.org/">http://www.tbig.org/</a><o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Embedded Microproscessor Benchmarking Consortium</h3>
  <p class=ReferencesText>http:://www.eembc.org/about.asp</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Jones 1997</h3>
  <p class=ReferencesText>Edward Jones, The Importance of Benchmarking (Connecticut
    Department of Social Services. Biometric ID Project.) First published
    Biometrics In Human Services User Group, Newsletter, May 1997 . Available: <a href="http://www.dss.state.ct.us/digital/bench.htm"><span
style='font-size:8.0pt'>http://www.dss.state.ct.us/digital/bench.htm</span></a> {August
    16, 2002] </p>
  <h1 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    3.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Image Databases</h1>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    3.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Existing Image Databases</h2>
  <p class=ReferencesText>The following is only a selection of the great
    many image databases available on the Web (in whole or in part). Descriptions
    are abstracted from the sites referenced and minimally edited for consistency.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Art</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    The AMICO Library™</h4>
  <p class=MsoNormal>http://search.amico.org </p>
  <p class=MsoNormal>contains over 100,000 works of art from the collections
    of 30+ museums in the United States, Canada and the UK which are members
    of the non-profit Art Museum image Consortium. It is available under
    subscription for use by educators worldwide and datasets from it could
    be made available for retrieval researcher.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    ARTSTOR</h4>
  <p class=ReferencesText>ARTStor propose 250,000 images in an initial release..
    However public information about the initiative is slight. No public
    URL, no release date<br style='mso-special-character:line-break'>
    <![if !supportLineBreakNewLine]>
    <br style='mso-special-character:line-break'>
    <![endif]>
  </p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    The Commercial Art Imagebase</h4>
  <p class=MsoNormal><a href="http://www.lib.colum.edu/commwais.html">http://www.lib.colum.edu/commwais.html</a> </p>
  <p class=MsoNormal>contains information on over 2,300 examples of advertising
    and related art. This index to selected images used in the study of advertising
    and commercial art at Columbia College Library can be searched in several
    ways. </p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Costume Imagebase</h4>
  <p class=MsoNormal><a href="http://www.lib.colum.edu/costwais.html">http://www.lib.colum.edu/costwais.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal>contains information on over 9,000 examples of costume
    and fashion design artwork and imagery. This index to selected images
    used in the study of fashion and costume at Columbia College Library
    can be searched in several ways. </p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The National Gallery of Art, Washington</h4>
  <p class=MsoNormal><br>
    <span style="mso-spacerun: yes">&nbsp;</span><a
href="http://www.nga.gov/collection/srchart.html">http://www.nga.gov/collection/srchart.html</a><br>
    15,000+ including many details of works</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The National Gallery, London</h4>
  <p class=MsoNormal><a
href="http://www.nationalgallery.org.uk/collection/default_online.htm">http://www.nationalgallery.org.uk/collection/default_online.htm</a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    The National Graphic Design Image Database </h4>
  <p class=MsoNormal><a href="http://ngda.cooper.edu/ngdasite/info.html">http://ngda.cooper.edu/ngdasite/info.html</a></p>
  <p class=MsoNormal>An electronic archive that preserves and disseminates
    material related to twentieth century graphic arts and design. The system
    enables interactive and interdisciplinary analysis among faculty, students
    and the design community worldwide. Educators with password registration
    and cataloging level permissions may post notes, analysis and images
    from off-site locations. The Cooper Union's 20,000 piece Graphic Design
    Slide Library is the database's original source. It includes donations
    from design organizations, private collectors, and educators, and features
    designs by noted American graphic artists. In the Fall 1998 the project
    acquired the 6,000 digital image Danziger Collection from the Art Center
    College of Design.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The National Portrait Gallery, London</h4>
  <p class=MsoNormal><a href="http://www.npg.org.uk/live/collect.asp">http://www.npg.org.uk/live/collect.asp</a></p>
  <p class=MsoNormal>over 12,500 illustrations of portraits</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Tate Gallery</h4>
  <p class=MsoNormal><a href="http://www.tate.org.uk/collections/default.jsp">http://www.tate.org.uk/collections/default.jsp</a></p>
  <p class=MsoNormal>Permanent collection 8000+ images including several
    thousand works by J.M.W. Turner</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Thinker, Fine Arts Museums of San Francisco</h4>
  <p class=MsoNormal><a href="http://www.thinker.org/">http://www.thinker.org</a><br>
    Permanent collection, over 82,000 images of works of 12,000+ artists</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    VADS Visual Arts Data Service</h4>
  <p class=MsoNormal>http://vads.ahds.ac.uk</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Cultural Studies</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    American Memory</h4>
  <p class=MsoNormal><a href="http://memory.lc.go/">http://memory.loc.go</a>v</p>
  <p class=MsoNormal>American Memory is a gateway to rich primary source
    materials relating to the history and culture of the United States from
    the collections of the Library of Congress. The site offers more than
    7 million digital items from over 100 historical collections.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Artefacts Canada</h4>
  <p class=MsoNormal>http://www.chin.gc.ca/English/Artefacts_Canada/index.html</p>
  <p class=MsoNormal>200,000 images form museums across Canada, divided into
    Arts and Humanities, Natural Sciences, and Archaeological Sites</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    AP Photo Database?</h4>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The EIKON Image Database for Biblical Studies</h4>
  <p class=MsoNormal><a href="http://eikon.divinity.yale.edu/">http://eikon.divinity.yale.edu/</a></p>
  <p class=MsoNormal>is a faculty-library initiative at Yale Divinity School
    that provides digital resources for teaching and research in the field
    of Biblical studies. Images in the EIKON database are a subset of the
    Yale Divinity School Digital Library. Some images in the EIKON database
    are restricted to Yale use, due to copyright agreements. The EIKON project
    was initiated during the 1998 -1999 academic year with a grant from the
    Wabash Center for Teaching and Learning in Theology and Religion.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Cities/Buildings Database</h4>
  <p class=MsoNormal>http://www.washington.edu/ark2/</p>
  <p class=MsoNormal>A<span style="mso-spacerun: yes">&nbsp; </span>collection
    of digitized images of buildings and cities drawn from across time and
    throughout the world, available to students, researchers and educators
    on the web. Begun in 1995, the Database was conceived as a multi-disciplinary
    resource for students, faculty, and others in the academic community.
    It has grown steadily since then, with contributions from a wide range
    of scholars, and now contains over 5000 images ranging from New York
    to Central Asia, from African villages, to the Parc de la Villette, and
    conceptual sketches and models of Frank Gehry's Experience Music Project.
    These have all been scanned from original slides or drawn from documents
    in the public domain. They are freely available to anyone with access
    to the Web for use in the classroom, student study, or for individual
    research purposes.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Collage</h4>
  <p class=MsoNormal>http://collage.nhil.com/</p>
  <p class=MsoNormal>An image database containing 20,000 works from the Guildhall
    Library and Guildhall Art Gallery London.<span style="mso-spacerun: yes">&nbsp; </span>By
    the Corporation of London and Ibase Image Systems Its categories include: </p>
  <p class=MsoNormal>Abstract Ideas; Archaeology &amp; Architecture; History;
    Leisure; Military &amp; War; Natural World; Politics; Religion &amp; Belief;
    Society; Trade &amp; Industry. One may search by People, Places, Artists,
    Engravers, and<span style="mso-spacerun: yes">&nbsp; </span>Publishers.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Cultural Materials RLG</h4>
  <p class=MsoNormal><a href="http://www.rlg.org/">http://www.rlg.org</a></p>
  <p class=MsoNormal>A growing collection of 140,000+ images from the Research
    Libraries Group which contains collections from research libraries documenting
    the entire range of human activity.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Harvard’s VIA Database</h4>
  <p class=ReferencesText>The Visual Information Access (VIA) system is a
    union catalog of visual resources at Harvard. It includes information
    about slides, photographs, objects and artifacts in the university's
    libraries, museums and archives. This system represents the first phase
    of an ongoing effort and additional information will be added on a regular
    basis. Check the repository's web sites for more information about access
    policies and coverage for their visual collections.</p>
  <p class=ReferencesText><a href="http://via.harvard.edu:748/html/VIA.html">http://via.harvard.edu:748/html/VIA.html</a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Leiden 19th-Century Portrait Database</h4>
  <p class=MsoNormal><a href="http://ind156b.wi.leidenuniv.nl:2000/">http://ind156b.wi.leidenuniv.nl:2000/</a></p>
  <p class=MsoNormal>is a database of 19389 Dutch Carte de Visite Studio
    Portraits taken from 1860-1914.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Perse<span style='font-weight:normal'>u</span>s</h4>
  <p class=ReferencesText>Growing digital library of ancient Greek and Rome,
    expanding to include other areas<br>
    http://www.perseus.tufts.edu</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    SCRAN</h4>
  <p class=MsoNormal>http://www.scran.ac.uk/homepage/</p>
  <p class=MsoNormal>is a history and culture site with more than one million
    records, include 160,000+ images, from museums, galleries, archives,
    the media and contemporary and performing arts in Scotland. SCRAN gives
    worldwide access to multimedia educational resources on international
    culture and world heritage.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Virtual Museum of Canada</h4>
  <p class=MsoNormal><a href="http://www.virtualmuseum.ca/">http://www.virtualmuseum.ca</a></p>
  <p class=MsoNormal>“thousands” of images from collections across Canada.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Astronomy and Earth Sciences</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The NASA JSC Digital Image Collection</h4>
  <p class=MsoNormal><a href="http://images.jsc.nasa.gov/">http://images.jsc.nasa.gov/</a></p>
  <p class=MsoNormal>includes more than 9000 press release photos spans the
    manned space program, from Mercury to the STS-79 Shuttle mission. The
    collection includes a full text search. A list of frequently asked questions
    is now available. NASA generally does not assert copyright for these
    photos. Some conditions.<span style="mso-spacerun: yes">&nbsp; </span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Gateway to Astronaut Photography of Earth</h4>
  <p class=MsoNormal><a href="http://eol.jsc.nasa.gov/sseop">http://eol.jsc.nasa.gov/sseop</a></p>
  <p class=MsoNormal>hosted by JSC's Office of Earth Sciences and Image Analysis,
    provides a standard way of describing the contents of the database that
    would be comparable between different applications and over the coming
    years. Statistics about specific subsets (e.g., number of photos of Namibia)
    can be compiled from the Search Page (http://eol.jsc.nasa.gov/sseop/sql.htm)<a
style='mso-endnote-id:edn1' href="trantrefs.htm#_edn1" name="_ednref1" title=""><span
class=MsoEndnoteReference><span style='mso-special-character:footnote'>
      <![if !supportFootnotes]>
      [i]
      <![endif]>
      </span></span></a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Astronomy Digital Image Library (ADIL)</h4>
  <p class=MsoNormal><a href="http://imagelib.ncsa.uiuc.edu/imagelib.html">http://imagelib.ncsa.uiuc.edu/imagelib.html</a></p>
  <p class=MsoNormal>collects astronomical, research-quality images and makes
    them available to the astronomical community and the general public.
    Patrons access the Library through the World Wide Web to search for and
    browse images. Once images are located in the Library, users may download
    them to their local machines in FITS format for further analysis.The
    Library is being developed and maintained by the Radio Astronomy Imaging
    Group at the National Center for Supercomputing Application (NCSA) on
    the campus of the University of Illinois at Urbana-Champaign (UIUC). </p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Messier Catalog</h4>
  <p class=MsoNormal>http://www.seds.org/messier/</p>
  <p class=MsoNormal>During the years from 1758 to 1782 Charles Messier,
    a French astronomer (1730 - 1817), compiled a list of approximately 100
    diffuse objects that were difficult to distinguish from comets through
    the telescopes of the day. Discovering comets was the way to make a name
    for yourself in astronomy in the 18th century -- Messier's aim was to
    catalog the objects that were often mistaken for comets. Fortunately
    for us, the Messier Catalog became well known for a much higher purpose,
    as a collection of the most beautiful objects in the sky including nebulae,
    star clusters, and galaxies. It was one of the first major milestones
    in the history of the discovery of Deep Sky objects, as it was the first
    more comprehensive and more reliable list: Only four objects were initially
    missing because of data reduction errors, which could be figured out
    later though. Today's versions of the catalog usually include also later
    additions of objects observed by Charles Messier and his collegial friend,
    Pierre Méchain, but not included in his original list. The study of these
    objects by astronomers has led, and continues to lead, to important,
    incredible discoveries.For each object, an image is presented together
    with a short description. In addition to the images, we have also included
    some data on these objects such as celestial position (right ascension
    in hours and minutes [h:m], declination in degrees and minutes [deg:m],
    both for the epoch J2000.0), apparent visual brightness in magnitudes
    [mag], apparent (angular) diameter in arc minutes [arc min], and approximate
    distance in thousands of light-years (kilo-light years [kly] please note
    that the decimal point in the distance does not represent true accuracy;
    see explanation of the terms used here). Also, we have constellation
    images which show Messier and NGC (New General Catalog) objects down
    to 12th magnitude.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The EROS Data Center Selected Image Gallery</h4>
  <p class=MsoNormal><a href="http://edcwww.cr.usgs.gov/bin/html_web_store.cgi">http://edcwww.cr.usgs.gov/bin/html_web_store.cgi</a> </p>
  <p class=MsoNormal>contains some of the millions of digital images in the
    EROS Center including aerial photographs, mainly for mapping, and various
    kinds of satellite images for scientific study. Among all these pictures,
    naturally, are some that are beautiful, some that record events of historic
    significance, and some that stir the imagination for other reasons. Categories
    for searching include: states, cities of the us, napp major metro, cities
    of the world, space, countries and continents, weather, natural hazards,
    and natural features.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Biological Sciences</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Nanoworld Image Gallery, Centre for Microscopy and Microanalysis</h4>
  <p class=MsoNormal><a href="http://www.uq.edu.au/nanoworld/images_1.html">http://www.uq.edu.au/nanoworld/images_1.html</a> </p>
  <p class=MsoNormal>at The University of Queensland ,is a database of images
    from electron microscopes.<span style="mso-spacerun: yes">&nbsp; </span>The
    copying of images, and their subsequent FREE use, is permitted with the
    following conditions: </p>
  <p class=MsoNormal><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>* that
    the source of the image(s) is clearly indicated;</p>
  <p class=MsoNormal><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>* and
    that their use is recorded by completing our Registration Form.</p>
  <p class=MsoNormal><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>* if used
    on a web page then a link to the Nanoworld must be provided.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Calphotos</h4>
  <p class=MsoNormal><span class=MsoHyperlink><span style='color:blue'>http://elib.cs.berkeley.edu/photos/ <o:p></o:p></span></span></p>
  <p class=MsoNormal>CalPhotos is a collection of 42,680 images of plants,
    animals, fossils, people, and landscapes managed by the Digital Library
    Project</p>
  <p class=MsoNormal>University of California, Berkeley. A variety of organizations
    and individuals have contributed photographs to CalPhotos.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    FlyView </h4>
  <p class=MsoNormal><a href="http://pbio07.uni-muenster.de/html/About.html">http://pbio07.uni-muenster.de/html/About.html</a> </p>
  <p class=MsoNormal>Currently consists of 3700+ images on Drosophila development
    and genetics, especially on expression patterns of genes (enhancer trap
    lines, cloned genes).The concept of FlyView includes compatibility to
    FlyBase, the main Drosophila database. Its aim is to establish the possibilty
    to compare images on the computer screen and to search for special patterns
    at different developmental stages. Therefore, all images are accompanied
    by text descriptions that can be used for searching. The success of this
    database exclusively depends on the activity of the Drosophila community.
    All Drosophila workers are asked to contribute to this database by submitting
    images and accompanying text.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Scientific Image Database</h4>
  <p class=MsoNormal><a href="http://sidb.sourceforge.net/">http://sidb.sourceforge.net/</a> </p>
  <p class=MsoNormal>is a web-driven database for images. The project was
    initiated by Hans van der Voort from SVI, a company producing the Huygens
    software package, used in deconvolution of microscopy images. (SIDB uses
    a 'light' version of huygens to interpret 3-D image data). Started as
    a project by and for undergraduate computer sciences students from the
    University of Utrecht, it matured at the Institute for Molecular Plant
    Sciences from the University of Leiden, the Netherlands, where SIDB is
    now used by many to archive images and other file types. SIDB archives
    2-D, 3-D images. Image files are stored unchanged in a central directory
    (archive). Users of the system are subdivided in groups, and whoever
    owns an image (by uploading it) can determine who else on the system
    is allowed to view and use the image. Files can be uploaded through HTML,
    or using a mounted (smb, NFS, etc..) drive. Entering meta-data is facilitated
    by user-definable templates. The meta-data fields currently in use have
    been designed for images derived by (confocal) microscopy. When combined
    with cheap, large hard drives and a fail-save backup mechanism, SIDB
    provides a perfect means to archive images within the setting of small
    to medium-sized research groups. However, it might be of use wherever
    people collaborate on images.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The IMB Jena Image Library of Biological Macromolecules</h4>
  <p class=MsoNormal><a href="http://www.imb-jena.de/IMAGE.html">http://www.imb-jena.de/IMAGE.html</a></p>
  <p class=MsoNormal>is aimed at a better dissemination of information on
    three-dimensional biopolymer structures with an emphasis on visualization
    and analysis. It provides access to all structure entries deposited at
    the Protein Data Bank (PDB) or at the Nucleic Acid Database (NDB). In
    addition, basic information on the architecture of biopolymer structures
    is available. The IMB Jena Image Library intends to fulfill both scientific
    and educational needs.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Aleocharine Image Database</h4>
  <p class=MsoNormal><a href="http://www.nhm.ukans.edu/ashe/aleo/splash2.html">http://www.nhm.ukans.edu/ashe/aleo/splash2.html</a> </p>
  <p class=MsoNormal>includes photographs, scanning electron micrographs,
    half-tone drawings and line drawings in this database are being accumulated
    as potential illustrations for a guide to the aleocharine genera of North
    America and Mexico, with additional images of taxa from other geographical
    regions for comparison.<span style="mso-spacerun: yes">&nbsp; </span>Seevers
    (1978) noted that it is probably impossible to identify most aleocharine
    genera without a substantial reference collection.<span style="mso-spacerun: yes">&nbsp; </span>It
    is our ultimate goal to provide habitus illustrations, photographs and
    line drawings of structural features of all genera.<span
style="mso-spacerun: yes">&nbsp; </span>Hopefully, these will serve as the
    “reference collection” needed to accurately identify aleocharine genera
    (when used with appropriate keys).<span style="mso-spacerun: yes">&nbsp; </span>Development
    of this image database is a on-going project, and new images will be
    added, and images of poor quality replaced, on a regular basis.<span style="mso-spacerun:
yes">&nbsp; </span>All images in this database are made available thanks
    to NSF PEET grant DEB-9521755 to James S. Ashe.<span style="mso-spacerun: yes">&nbsp; </span></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Botanical Imagebase, University of Basel</h4>
  <p class=MsoNormal><a href="http://www.unibas.ch/botimage/">http://www.unibas.ch/botimage/</a> </p>
  <p class=MsoNormal>contasins 4,341 specimens that can be searched by Species,
    Families, Genera, and Orders including</p>
  <p class=MsoNormal>• Basel (2'077)</p>
  <p class=MsoNormal>• Samos (1'107)</p>
  <p class=MsoNormal>• Tenerife (693)</p>
  <p class=MsoNormal>• Pollinators (287)</p>
  <p class=MsoNormal>• Vegetation (315)</p>
  <p class=MsoNormal>• Woody plants (1'274)</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Vascular Plant Image Gallery</h4>
  <p class=MsoNormal><a href="http://www.csdl.tamu.edu/FLORA/gallery.htm">http://www.csdl.tamu.edu/FLORA/gallery.htm</a> </p>
  <p class=MsoNormal>contains thousands of images and metadata regarding
    vascular plants organized by genus.</p>
  <p class=MsoNormal>The Texas A&amp;M Bioinformatics Working Group includes
    campus faculty, staff, and students with research and educational interests
    in the expression of biodiversity data using new information technologies.
    These pages provide an overview of the Working Group and its activities</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Plant Dictionary</h4>
  <p class=MsoNormal>(<a href="http://www.hcs.ohio-state.edu/plants.html">http://www.hcs.ohio-state.edu/plants.html</a>)</p>
  <p class=MsoNormal>is an indexed system of teaching resources for the discipline
    of Horticulture and Crop Science. It was developed to complement the
    other electronic resources developed at Ohio State University, collectively
    called HORTICULTURE and CROP SCIENCE in Virtual Perspective.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Cognitive Sciences/Psychology</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Japanese Female Facial Expression (JAFFE) Database</h4>
  <p class=MsoNormal><a href="http://www.mis.atr.co.jp/~mlyons/jaffe.html">http://www.mis.atr.co.jp/~mlyons/jaffe.html</a> </p>
  <p class=MsoNormal>contains 213 images of 7 facial expressions (6 basic
    facial expressions + 1 neutral) posed by 10 Japanese female models. Each
    image has been rated on 6 emotion adjectives by 60 Japanese subjects.
    The database was planned and assembled by Miyuki Kamachi, Michael Lyons,
    and Jiro Gyoba. We thank Reiko Kubota for her help as a research assistant.
    The photos were taken at the Psychology Department in Kyushu University.<a style='mso-endnote-id:
edn2' href="trantrefs.htm#_edn2" name="_ednref2" title=""><span class=MsoEndnoteReference><span
style='mso-special-character:footnote'>
      <![if !supportFootnotes]>
      [ii]
      <![endif]>
      </span></span></a></p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The AR Face Database</h4>
  <p class=MsoNormal><a
href="http://rvl1.ecn.purdue.edu/~aleix/aleix_face_DB.html">http://rvl1.ecn.purdue.edu/~aleix/aleix_face_DB.html</a> </p>
  <p class=MsoNormal>was created by Aleix Martinez and Robert Benavente in
    the Computer Vision Center (CVC) at the U.A.B. It contains over 4,000
    color images corresponding to 126 people's faces (70 men and 56 women).
    Images feature frontal view faces with different facial expressions,
    illumination conditions, and occlusions (sun glasses and scarf). The
    pictures were taken at the CVC under strictly controlled conditions.
    No restrictions on wear (clothes, glasses, etc.), make-up, hair style,
    etc. were imposed to participants. Each person participated in two sessions,
    separated by two weeks (14 days) time. The same pictures were taken in
    both sessions. This face database is publicly available and can be obtained
    from this web-site. It is totally free for academics whishing to test
    their systems. Commercial distribution or any act related to commercial
    use of this database is strictly prohibited.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Medicine</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The Digital Database for Screening Mammography</h4>
  <p class=MsoNormal><a
href="http://marathon.csee.usf.edu/Mammography/Database.html">http://marathon.csee.usf.edu/Mammography/Database.html</a> </p>
  <p class=MsoNormal>is a resource for use by the mammographic image analysis
    research community. Primary support for this project was a grant from
    the Breast Cancer Research Program of the U.S. Army Medical Research
    and Materiel Command. The DDSM project is a collaborative effort involving
    co-p.i.s at the Massachusetts General Hospital (D. Kopans, R. Moore),
    the University of South Florida (K. Bowyer), and Sandia National Laboratories
    (P. Kegelmeyer). Additional cases from Washington University School of
    Medicine were provided by Peter E. Shile, MD, Assistant Professor of
    Radiology and Internal Medicine. Additional collaborating institutions
    include Wake Forest University School of Medicine (Departments of Medical
    Engineering and Radiology), Sacred Heart Hospital and ISMD, Incorporated.
    The primary purpose of the database is to facilitate sound research in
    the development of computer algorithms to aid in screening. Secondary
    purposes of the database may include the development of algorithms to
    aid in the diagnosis and the development of teaching or training aids.
    The database contains approximately 2,500 studies. Each study includes
    two images of each breast, along with some associated patient information
    (age at time of study, ACR breast density rating, subtletly rating for
    abnormalities, ACR keyword description of abnormalities) and image information
    (scanner, spatial resolution, ...). Images containing suspicious areas
    have associated pixel-level &quot;ground truth&quot; information about
    the locations and types of suspicious regions. </p>
  <p class=MsoNormal>The Digital Database for Screening Mammography is organized
    into &quot;cases&quot; and &quot;volumes.&quot; A &quot;case&quot; is
    a collection of images and information corresponding to one mammography
    exam of one patient. A &quot;volume&quot; is simply a collection of cases
    collected together for purposes of ease of distribution.<span style="mso-spacerun:
yes">&nbsp;&nbsp; </span>A case consists of between 6 and 10 files. These
    are an &quot;ics&quot; file, an overview &quot;16-bit PGM&quot; file,
    four image files that are compressed with lossless JPEG encoding and
    zero to four overlay files. Normal cases will not have any overlay files.
    We have 2620 cases available in 43 volumes.</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The BRAin Image Database (BRAID)</h4>
  <p class=MsoNormal><a href="http://braid.rad.jhu.edu/interface.html">http://braid.rad.jhu.edu/interface.html</a></p>
  <p class=MsoNormal>is a large-scale archive of normalized digital spatial
    and functional data with an analytical query mechanism. One of its many
    applications is the elucidation of brain structure-function relationships.
    BRAID stores spatially defined data from digital brain images which have
    been mapped into normalized Cartesian coordinates, allowing image data
    from large populations of patients to be combined and compared. The database
    also contains neurological data from each patient and a query mechanism
    that can perform statistical structure-function correlations</p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Cytopathnet Image bases </h4>
  <p class=MsoNormal><a href="http://www.cytopathnet.org/imagedb/">http://www.cytopathnet.org/imagedb/</a></p>
  <p class=MsoNormal>are offered by Cytopathnet, a 501(c)3 non-profit organization
    which aims to provide great and innovative solutions for online education
    and professional services in the field of cytopathology and pathology.
    We are dedicated to providing cytopathology information to healthcare
    professionals and improving the standards and quality of cytopathology
    through online education and collaboration. </p>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    MedPix™ - Medical Image Database and Internet Teaching File</h4>
  <p class=MsoNormal>http://rad.usuhs.mil/synapse/</p>
  <p class=MsoNormal>contains 11351 Images, 3002 Factoids, and 2949 Patients.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Imagebases Built To Support Commerce</h3>
  <p class=ReferencesText>In the aggregate, the largest number of freely
    available images are those of objects being sold or traded in the marketplace.
    These include vast imagebases from numerous sources of automobiles, boats,
    cars, clothing, furnishings, real estate, and every consumer product
    available today. They are accompanied by metadata regarded by their owners
    as important to the sale of the item. Harvesting huge databases of such
    images from the public web would not be difficult and could support a
    range of metadata based retrieval research. No effort is made here to
    list sources where commercial objects are listed for sale</p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    3.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Existing Image Retrieval Test Databases</h2>
  <p class=ReferencesText>A Listing Based on data compiled by the CMU Calibrated
    Imaging Laboratory, see <a href="http://www-2.cs.cmu.edu/~cil/v-images.html">http://www-2.cs.cmu.edu/~cil/v-images.html</a> and
    other web sites</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    AMOVIP-DB<span style="mso-spacerun: yes">&nbsp;&nbsp; </span></h3>
  <p class=ReferencesText><a
href="http://www.iv.optica.csic.es/projects/database.html">http://www.iv.optica.csic.es/projects/database.html</a> </p>
  <p class=MsoNormal>Images &amp; sequences for vision research </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    AVHRR Pathfinder datasets</h3>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://xtreme.gsfc.nasa.gov/">http://xtreme.gsfc.nasa.gov</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    BioID Face Detection Database</h3>
  <p class=MsoNormal><a href="http://www.bioid-dev.de/facedb/facedatabase.html">http://www.bioid-dev.de/facedb/facedatabase.html</a> </p>
  <p class=MsoNormal>includes 1521 images with human faces, recorded under
    natural conditions, i.e. varying illumination and complex background.
    The eye positions have been set manually (and are included in the set)
    for calculating the accuracy of a face detector. A formula is presented
    to normalize the decision of a match or mismatch. </p>
  <p class=MsoNormal>The first attempt to finally create a real test scenario
    with precise rules on how to calculate the accuracy of a face detector
    - open for all to compare their results in a scientific way.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Barnard</h3>
  <h4 style='margin-left:0in'>
    <![if !supportLists]>
    <span style='font-family:"Times New Roman"'><span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Synthetic Data for Colour Constancy Experiments</h4>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Brown University Stimuli<span style="mso-spacerun:
yes">&nbsp; </span></h3>
  <p class=MsoNormal><a href="http://www.cog.brown.edu/~tarr/stimuli.html">http://www.cog.brown.edu/~tarr/stimuli.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>A variety
    of datasets including geons, objects, and &quot;greebles&quot;. Good
    for testing recognition algorithms. (Formats: pict) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Caltech Image Database</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://www.vision.caltech.edu/html-files/archive.html">http://www.vision.caltech.edu/html-files/archive.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>about 20 images - mostly top-down
    views of small objects and toys. (Formats: GIF) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CCITT Fax standard images</h3>
  <p class=MsoNormal><a href="http://www.cs.waikato.ac.nz/~singlis/ccitt.html">http://www.cs.waikato.ac.nz/~singlis/ccitt.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>8 images) (Formats: gif) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CMU CIL's Stereo Data with Ground Truth </h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="http://www-2.cs.cmu.edu/~cil/cil-ster.html">http://www-2.cs.cmu.edu/~cil/cil-ster.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>3 sets of 11 images, including color
    tiff images with spectroradiometry (Formats: gif, tiff) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CMU PIE Database</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://www.ri.cmu.edu/projects/project_418.html">http://www.ri.cmu.edu/projects/project_418.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>A database of 41,368 face images
    of 68 people captured under 13 poses, 43 illuminations conditions, and
    with 4 different expressions. </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CMU VASC Image Database</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://www.ius.cs.cmu.edu/idb/">http://www.ius.cs.cmu.edu/idb/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Images, sequences, stereo pairs (thousands
    of images) (Formats: Sun Rasterimage) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    CMU Vision and Autonomous Systems Center's Image Database.</h3>
  <p class=MsoNormal><a href="http://vasc.ri.cmu.edu/idb/">http://vasc.ri.cmu.edu/idb/</a> </p>
  <p class=MsoNormal>contains over 5000 images split up over nearly 200 different
    data sets including:</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Motion Data - A large set of motion series. In most cases, sampling rate
    is not available.</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Road Sequences - Many road image sequences, taken from our Navlab series
    of vehicles.</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Stereo Data - A large set of stereo (left/right) images. Baseline information
    is generally not available.</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    CIL's Stereo Data with Ground Truth - 3 sets of 11 images, including
    color tiff images with spectroradiometry</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    JISCT Data - Datasets provided by research groups at JPL, INRIA, SRI,
    CMU, and Teleos.</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Faces and Facial expressions - Testing images for the face detection
    task, and the facial expression database.</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Car Data - Testing images for the car detection task.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Columbia-Utrecht Reflectance and Texture Database </h3>
  <p class=MsoNormal><a href="http://www.cs.columbia.edu/CAVE/curet/">http://www.cs.columbia.edu/CAVE/curet/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Texture and reflectance measurements
    for over 60 samples of 3D texture, observed with over 200 different combinations
    of viewing and illumination directions.<span style="mso-spacerun:
yes">&nbsp; </span>(Formats: bmp) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Computational Colour Constancy Data </h3>
  <p class=MsoNormal><a href="http://www.cs.sfu.ca/~colour/data/index.html">http://www.cs.sfu.ca/~colour/data/index.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>A dataset oriented towards computational
    color constancy, but useful for computer vision in general. It includes
    synthetic data, camera sensor data, and over 700 images.<span
style="mso-spacerun: yes">&nbsp; </span>(Formats: tiff) &lt;i&gt; (&lt;a
    href=&quot;http://www.cs.sfu.ca/~colour/ Computational Vision Lab&lt;/a&gt; / &lt;a
    href=&quot;http://www.sfu.ca/ Simon Fraser University&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Content-based image retrieval database<span
style="mso-spacerun: yes">&nbsp; </span></h3>
  <p class=MsoNormal><a
href="http://www.cs.washington.edu/research/imagedatabase/groundtruth/">http://www.cs.washington.edu/research/imagedatabase/groundtruth/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal style='margin-left:2.0pt'>11 sets of color images for
    testing algorithms for content-based retrieval.<span style="mso-spacerun:
yes">&nbsp; </span>Most sets have a description file with names of objects
    in each image. (Formats: jpg) &lt;i&gt; (&lt;a href=&quot;http://www.cs.washington.edu/research/imagedatabase/
    Efficient Content-based Retrieval Group&lt;/a&gt; / &lt;a href=&quot;http://www.washington.edu
    University of Washington&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Corel Photos Image Set</h3>
  <p class=ReferencesText>Commercially available Corel CD-Roms with ~200,000
    images used in whole, or part by a number of groups.<span style='font-size:
12.0pt'><o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Data for Computer Vision and Computational Colour Science</h3>
  <p class=ReferencesText>These datasets were gathered as part of Kobus Barnard's
    Ph.D. research at SFU. Appropriate archival references for the data accompany
    each dataset.</p>
  <p class=ReferencesText style='margin-left:26.0pt;text-indent:-.25in;
mso-list:l4 level1 lfo31;mso-list-change:\F0B7 "J\. Trant" 20040105T1655;
tab-stops:list 26.0pt'>
    <![if !supportLists]>
    <span style='font-family:Symbol'>·<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Camera Calibration Data for Sony DXC-930. <a
href="http://www.cs.sfu.ca/~colour/data/camera_calibration/index.html">http://www.cs.sfu.ca/~colour/data/camera_calibration/index.html</a></p>
  <p class=ReferencesText style='margin-left:26.0pt;text-indent:-.25in;
mso-list:l4 level1 lfo31;mso-list-change:\F0B7 "J\. Trant" 20040105T1655;
tab-stops:list 26.0pt'>
    <![if !supportLists]>
    <span style='font-family:Symbol'>·<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Colour Constancy Synthetic Test Data.<br>
    <a
href="http://www.cs.sfu.ca/~colour/data/colour_constancy_synthetic_test_data/index.html">http://www.cs.sfu.ca/~colour/data/colour_constancy_synthetic_test_data/index.html</a></p>
  <p class=ReferencesText style='margin-left:26.0pt;text-indent:-.25in;
mso-list:l4 level1 lfo31;mso-list-change:\F0B7 "J\. Trant" 20040105T1655;
tab-stops:list 26.0pt'>
    <![if !supportLists]>
    <span style='font-family:Symbol'>·<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Colour Constancy Test Images Captured Using Sony DXC-930.</p>
  <p class=ReferencesText>http://www.cs.sfu.ca/~colour/data/colour_constancy_test_images/index.html</p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Images of Objects Under Different Illuminants.</p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Spectra of Fluorescent Surfaces.</p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Object Recognition Image Database (Old Version - 1998)</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Digital Embryos</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://vision.psych.umn.edu/www/kersten-lab/demos/digitalembryo.html">http://vision.psych.umn.edu/www/kersten-lab/demos/digitalembryo.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Digital embryos are novel objects
    which may be used to develop and test object recognition systems. They
    have an organic appearance. (Formats: various formats are available on
    request) &lt;i&gt; (&lt;a href=&quot;http://vision.psych.umn.edu/www/kersten-lab/kersten-lab.html
    Univerity of Minnesota Vision Lab&lt;/a&gt; / University of Minnesota) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Dlib Test Suite</h3>
  <p class=MsoNormal><a href="http://www.dlib.org/test-suite/testbeds.html">http://www.dlib.org/test-suite/testbeds.html</a></p>
  <p class=MsoNormal>A set of datasets that include many still images as
    well as moving images, texts and sound.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    EarthRISE</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://earthrise.sdsc.edu/">http://earthrise.sdsc.edu/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>images of Earth from the space shuttle
    - good search engine<span style="mso-spacerun: yes">&nbsp;&nbsp; </span></p>
  <p class=MsoNormal>The Earth and Space Science Browser<span
style="mso-spacerun: yes">&nbsp; </span><a href="http://focus.eecs.umich.edu/">http://focus.eecs.umich.edu/</a> </p>
  <p class=MsoNormal>1,400 images of the earth, planets, star systems, space
    craft and other earth and space science subjects.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Earth and Space</h3>
  <p class=ReferencesText><a href="http://www.si.umich.edu/Space/overview.html"><span
style='font-size:12.0pt'>http://www.si.umich.edu/Space/overview.html</span></a> for
    earth and space science data;. </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    El Salvador Atlas of Gastrointestinal VideoEndoscopy</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp; </span><a
href="http://www.gastrointestinalatlas.com/">http://www.gastrointestinalatlas.com</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Images and Videos of his-res of studies
    taken from Gastrointestinal Video endoscopy.<span style="mso-spacerun:
yes">&nbsp; </span>(Formats: jpg, mpg, gif) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    FVC2000 Fingerprint Databases</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://bias.csr.unibo.it/fvc2000/">http://bias.csr.unibo.it/fvc2000/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>FVC2000 is the First International
    Competition for Fingerprint Verification Algorithms. Four fingerprint
    databases constitute the FVC2000 benchmark (3520 fingerprints in all). &lt;i&gt; (&lt;a
    href=&quot;http://bias.csr.unibo.it/research/biolab Biometric Systems
    Lab&lt;/a&gt; / University of Bologna) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Georgia Tech images</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://ftp.eedsp.gatech.edu/database/images">ftp://ftp.eedsp.gatech.edu/database/images</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>many images (Formats: unknown) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Graz University of Technology</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://ftp.tu-graz.ac.at/pub/images">ftp://ftp.tu-graz.ac.at/pub/images</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>stereo pairs (2 image pairs) (Formats:
    TIFF) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Groningen Natural Image Database</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><span
style="mso-spacerun: yes">&nbsp;</span><a
href="http://hlab.phys.rug.nl/archive.html">http://hlab.phys.rug.nl/archive.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>4000+ 1536x1024 (16 bit) calibrated
    outdoor images (Formats: homebrew) </p>
  <p class=MsoNormal>Hyperspectral dataset of natural scenes<span
style="mso-spacerun: yes">&nbsp;&nbsp; </span><a
href="http://www.crs4.it/~gjb/ftpJOSA.html">http://www.crs4.it/~gjb/ftpJOSA.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Hyperspectral images of 29 natural
    scenes with 31 bands each collected by Bristol University for DRA UK.
    (Formats: radiometric pixels &amp; gif preview) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    IEN Image Library</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://www.ien.it/iengf/is/vislib.html">http://www.ien.it/iengf/is/vislib.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>1000+ images, mostly outdoor sequences
    (Formats: raw, ppm) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    INRIA's Robotvis Images</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://krakatoa.inria.fr/pub/IMAGES_ROBOTVIS">ftp://krakatoa.inria.fr/pub/IMAGES_ROBOTVIS</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>many images (Formats: PGM, homebrew) &lt;i&gt; (INRIA) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    INRIA's Syntim images database</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://www-syntim.inria.fr/syntim/analyse/images-eng.html">http://www-syntim.inria.fr/syntim/analyse/images-eng.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>15 color image of simple objects
    (Formats: gif) &lt;i&gt; (&lt;a href=&quot;http://www-syntim.inria.fr/syntim/
    Syntim&lt;/a&gt; / &lt;a href=&quot;http://www.inria.fr/ INRIA&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    INRIA's Syntim stereo databases </h3>
  <p class=MsoNormal><a
href="http://www-syntim.inria.fr/syntim/analyse/paires-eng.html">http://www-syntim.inria.fr/syntim/analyse/paires-eng.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>34 calibrated color stereo pairs:
    (Formats: gif) &lt;i&gt; (&lt;a href=&quot;http://www-syntim.inria.fr/syntim/
    Syntim&lt;/a&gt; / &lt;a href=&quot;http://www.inria.fr/ INRIA&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    JAFFE Facial Expression Image Database </h3>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;</span><a
href="http://www.mic.atr.co.jp/~mlyons/jaffe.html">http://www.mic.atr.co.jp/~mlyons/jaffe.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>The JAFFE database consists of 213
    images of Japanese female subjects posing 6 basic facial expressions
    as well as a neutral pose. Ratings on emotion adjectives are also available,
    free of charge, for research purposes. (Formats: TIFF Grayscale images.) &lt;i&gt; (&lt;a
    href=&quot;http://www.mic.atr.co.jp/ ATR Research, Kyoto, Japan&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    JISCT Stereo Evaluation</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://ftp.vislist.com/IMAGERY/JISCT/">ftp://ftp.vislist.com/IMAGERY/JISCT/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>44 image pairs.<span
style="mso-spacerun: yes">&nbsp; </span>These data have been used in an evaluation
    of stereo analysis, as described in the April 1993 ARPA Image Understanding
    Workshop paper ``The JISCT Stereo Evaluation'' by R.C.Bolles, H.H.Baker,
    and M.J.Hannah, 263--274. (Formats: SSI) &lt;i&gt; (SRI) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Johns Hopkins polarization images</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://ftp.cs.jhu.edu/pub/natimages/">ftp://ftp.cs.jhu.edu/pub/natimages/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>several sets of four images (Formats:
    compressed Sun Rasterimage) &lt;i&gt; (Johns Hopkins) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    JPEG Test Images</h3>
  <p class=MsoNormal>Lena</p>
  <p class=MsoNormal>Standard image of ‘Lena’ used in JPG tests</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    KIEL Appearance Image Library dataset </h3>
  <p class=MsoNormal><a
href="http://www.ks.informatik.uni-kiel.de/~jpa/images.html">http://www.ks.informatik.uni-kiel.de/~jpa/images.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>dozens of images (Formats: PNG) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Linkoping University</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://isy.liu.se/images">ftp://isy.liu.se/images</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>image<span style="mso-spacerun:
yes">&nbsp; </span>database (including a<span style="mso-spacerun: yes">&nbsp; </span>&lt;a
    href=&quot;ftp://isy.liu.se/images/calib.iccalibrated outdoor stereo<span style="mso-spacerun: yes">&nbsp; </span>scene&lt;/a&gt;;
    see<span
style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>&lt;a href=&quot;ftp://isy.liu.se/images/READMEREADME&lt;/a&gt; and<span
style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>&lt;a href=&quot;ftp://isy.liu.se/images/Stereo.txtStereo.txt&lt;/a&gt;)
    (Formats: homebrew) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Los Alamos fingerprint images</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://ftp.c3.lanl.gov/pub/WSQ/print_data">ftp://ftp.c3.lanl.gov/pub/WSQ/print_data</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>many images (Formats: raw 8-bit) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Lunar Datasets</h3>
  <p class=ReferencesText>Other datasets available for research and browsing
    include (<a href="http://www.nrl.navy.mil/clementine/clib/"><span
style='font-size:12.0pt'>http://www.nrl.navy.mil/clementine/clib/</span></a> for
    lunar data;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Machine Vision </h3>
  <p class=ReferencesText><span style="mso-spacerun: yes">&nbsp;</span><a
href="ftp://ftp.cse.psu.edu/pub/vision/MACHINE_VISION/images/">ftp://ftp.cse.psu.edu/pub/vision/MACHINE_VISION/images/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Images from the textbook by Jain,
    Kasturi, Schunck (20+ images) (Formats: GIF TIFF) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Mammography Image Databases<span style="mso-spacerun:
yes">&nbsp; </span></h3>
  <p class=MsoNormal><a
href="http://marathon.csee.usf.edu/Mammography/Database.html">http://marathon.csee.usf.edu/Mammography/Database.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>100 or more images of mammograms
    with ground truth.<span style="mso-spacerun: yes">&nbsp; </span>Additional
    images available by request, and links to several other mammography databases
    are provided. (Formats: homebrew) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Michigan State images</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://ftp.cps.msu.edu/pub/prip">ftp://ftp.cps.msu.edu/pub/prip</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>many images (Formats: unknown) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    MIT face images and more </h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="ftp://whitechapel.media.mit.edu/pub/images">ftp://whitechapel.media.mit.edu/pub/images</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>hundreds of images (Formats: homebrew) &lt;i&gt; (MIT) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    MIT Vision Texture</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://www-white.media.mit.edu/vismod/imagery/VisionTexture/vistex.html">http://www-white.media.mit.edu/vismod/imagery/VisionTexture/vistex.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Image archive (100+ images) (Formats:
    ppm) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Modis Airborne simulator, Gallery and data set<span
style="mso-spacerun: yes">&nbsp; </span></h3>
  <p class=MsoNormal><a href="http://ltpwww.gsfc.nasa.gov/MODIS/MAS/">http://ltpwww.gsfc.nasa.gov/MODIS/MAS/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>High Altitude Imagery from around
    the world for environmental modeling in support of NASA EOS program (Formats:
    JPG and HDF) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    MPEG-7 test data set</h3>
  <p class=MsoNormal><a href="http://www.cselt.it/mgeg/standards.htm">http://www.cselt.it/mgeg/standards.htm</a>,
    7,000 still images, </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    National Design Repository</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://www.designrepository.org/">http://www.designrepository.org</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Over 55,000 3D CAD and solid models
    of (mostly) mechanical/machined engineerign designs. (Formats: gif,vrml,wrl,stp,sat) &lt;i&gt; (&lt;a
    href=&quot;http://gicl.mcs.drexel.edu Geometric &amp; Intelligent Computing
    Laboratory&lt;/a&gt; / &lt;a href=&quot;http://www.drexel.edu Drexel
    University&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    NIST Fingerprint and handwriting </h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="ftp://sequoyah.ncsl.nist.gov/pub/databases/data">ftp://sequoyah.ncsl.nist.gov/pub/databases/data</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>datasets - thousands of images (Formats:
    unknown) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    NIST Fingerprint data<span style="mso-spacerun:
yes">&nbsp; </span></h3>
  <p class=MsoNormal><a href="ftp://ftp.cs.columbia.edu/jpeg/other/uuencoded">ftp://ftp.cs.columbia.edu/jpeg/other/uuencoded</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>compressed multipart uuencoded tar
    file &lt;i&gt; (Columbia) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    NIST Mugshot Identification Database (NIST Special Database 18)<span style="mso-spacerun: yes">&nbsp;&nbsp; </span></h3>
  <p class=MsoNormal><a href="http://www.nist.gov/srd/nistsd18.htm">http://www.nist.gov/srd/nistsd18.htm</a> </p>
  <p class=MsoNormal>is being distributed for use in development and testing
    of automated mugshot identification systems.<a style='mso-endnote-id:edn3'
href="trantrefs.htm#_edn3" name="_ednref3" title=""><span class=MsoEndnoteReference><span
style='mso-special-character:footnote'>
      <![if !supportFootnotes]>
      [iii]
      <![endif]>
      </span></span></a></p>
  <p class=MsoNormal>The database consists of three CD-ROMs, containing a
    total of 3248 images of variable size using lossless compression. Each
    CD-ROM requires approximately 530 megabytes of storage compressed and
    1.2 gigabytes uncompressed (2.2:1 average compression ratio). There are
    images of 1573 individuals (cases) 1495 male and 78 female. The database
    contains both front and side (profile) views when available. Separating
    front views and profiles, there are 131 cases with two or more front
    views and 1418 with only one front view.</p>
  <p class=MsoNormal>This NIST Special Database has the following features:</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    3248 segmented 8-bit gray scale mugshot images (varying sizes) of 1573
    individuals</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    1333 cases with both front and profile views (see statistics above)</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    131 cases with two or more front views and 89 cases with two or more
    profiles</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    images scanned at 19.7 pixels per mm</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    image format documentation and example software.</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    NLM HyperDoc Visible Human Project<span
style="mso-spacerun: yes">&nbsp; </span></h3>
  <p class=MsoNormal><a
href="http://www.nlm.nih.gov/research/visible/visible_human.html">http://www.nlm.nih.gov/research/visible/visible_human.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Color, CAT and MRI image samples
    - over 30 images (Formats: jpeg) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Olivetti face database</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="http://www.cam-orl.co.uk/facedatabase.html">http://www.cam-orl.co.uk/facedatabase.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>400 images (Formats: pgm) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Optical flow test image </h3>
  <p class=MsoNormal><a href="ftp://csd.uwo.ca/pub/vision/TESTDATA/">ftp://csd.uwo.ca/pub/vision/TESTDATA/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>see &lt;em&gt;Performance of Optical
    Flow Techniques&lt;/em&gt; under &lt;a href=&quot;v-source.htmlRESEARCH
    CODE&lt;/a&gt; (6 synthetic and 4 real image sequences) (Formats: Sun
    Rasterimage) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    OSU (MSU) 3D Object Model Database </h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="http://eewww.eng.ohio-state.edu/~flynn/3DDB/Models/">http://eewww.eng.ohio-state.edu/~flynn/3DDB/Models/</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>several sets of 3D object models
    collected over several years to use in object recognition research (Formats:
    homebrew, vrml) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    OSU (MSU/WSU) Range Image Database</h3>
  <p class=MsoNormal><a href="http://eewww.eng.ohio-state.edu/~flynn/3DDB/RID/">http://eewww.eng.ohio-state.edu/~flynn/3DDB/RID/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Hundreds of real and synthetic images
    (Formats: gif, homebrew) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    OSU/SAMPL Database: Range Images, 3D Models, Stills, Motion Sequences</h3>
  <p class=MsoNormal><a href="http://sampl.eng.ohio-state.edu/~sampl/database.htm">http://sampl.eng.ohio-state.edu/~sampl/database.htm</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Over 1000 range images, 3D object
    models, still images and motion sequences (Formats: gif, ppm, vrml, homebrew) &lt;i&gt; (&lt;a
    href=&quot;http://sampl.eng.ohio-state.edu Signal Analysis and Machine
    Perception Laboratory&lt;/a&gt; / &lt;a href=&quot;http://www.osu.edu
    The Ohio State University&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Otago Optical Flow Evaluation Sequences</h3>
  <p class=MsoNormal><a
href="http://www.cs.otago.ac.nz/research/vision/Research/OpticalFlow/opticalflow.html">http://www.cs.otago.ac.nz/research/vision/Research/OpticalFlow/opticalflow.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Synthetic and real sequences with
    machine-readable ground truth optical flow fields, plus tools to generate
    ground truth for new sequences. (Formats: ppm,tif,homebrew) &lt;i&gt; (&lt;a
    href=&quot;http://www.cs.otago.ac.nz/research/vision/index.html Vision
    Research Group&lt;/a&gt; / &lt;a href=&quot;http://www.otago.ac.nz/ University
    of Otago&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Particle image sequences</h3>
  <p class=MsoNormal><a href="ftp://ftp.limsi.fr/pub/quenot/opflow/testdata/piv/">ftp://ftp.limsi.fr/pub/quenot/opflow/testdata/piv/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Real and synthetic image sequences
    used for testing a Particle Image Velocimetry application.<span style="mso-spacerun:
yes">&nbsp; </span>These images may be used for the test of optical flow
    and image matching algorithms. (Formats: pgm (raw)) http://www.limsi.fr/Recherche/IMM/PageIMM.html</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    RADIUS project test imagery</h3>
  <p class=MsoNormal><a href="ftp://ftp.balltown.cma.com/pub/images">ftp://ftp.balltown.cma.com/pub/images</a></p>
  <p class=MsoNormal>many formats</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Sequences for Flow Based Reconstruction</h3>
  <p class=MsoNormal><a href="http://bion.nada.kth.se/~zucch/CAMERA/PUB/seq.html">http://bion.nada.kth.se/~zucch/CAMERA/PUB/seq.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>synthetic sequence for testing structure
    from motion algorithms (Formats: pgm) &lt;i&gt; (&lt;a href=&quot;http://bion.nada.kth.se
    CVAP&lt;/a&gt;)</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    SEQUENCES FOR OPTICAL FLOW ANALYSIS (SOFA)</h3>
  <p class=MsoNormal><a href="http://www.cee.hw.ac.uk/~mtc/sofa">http://www.cee.hw.ac.uk/~mtc/sofa</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>9 synthetic sequences designed for
    testing motion analysis applications, including full ground truth of
    motion and camera parameters. (Formats: gif (&lt;a href=&quot;http://www.cee.hw.ac.uk/~mtc/research.html
    Computer Vision Group&lt;/a&gt; / &lt;a href=&quot;http://www.cee.hw.ac.uk/
    Dept of Computing and Electrical Engineering, Heriot-Watt University&lt;/a&gt;)</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    State of<span style="mso-spacerun: yes">&nbsp; </span>California Department
    of Water Resources</h3>
  <p class=MsoNormal>560,000 images of wihc ~17,000 were used in the CHABOT
    and CYPRESS projects at the University of California, Berkeley</p>
  <p class=MsoNormal>Ogle &amp; Stonebraker,1995</p>
  <p class=MsoNormal>http://elib.cs.berkeley.edu/photos/dwr/about.html</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Stereo Images with Ground Truth Disparity and Occlusion</h3>
  <p class=MsoNormal><a href="http://www-dbv.cs.uni-bonn.de/stereo_data/">http://www-dbv.cs.uni-bonn.de/stereo_data/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>a small set of synthetic images of
    a hallway with varying amounts of noise added.<span style="mso-spacerun:
yes">&nbsp; </span>Use these images to benchmark your stereo algorithm. (Formats:
    raw, viff (khoros), or tiff) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Stuttgart ISPRS Image Understanding datasets</h3>
  <p class=MsoNormal><a href="ftp://ftp.ifp.uni-stuttgart.de/pub/wg3">ftp://ftp.ifp.uni-stuttgart.de/pub/wg3</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>stereo and/or infrared images with
    approximate ground truth (4 compressed datasets) (Formats: PGM) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Stuttgart Range Image Database</h3>
  <p class=MsoNormal><a href="http://range.informatik.uni-stuttgart.de/">http://range.informatik.uni-stuttgart.de</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>A collection of synthetic range images
    taken from high-resolution polygonal models available on the web (Formats:
    homebrew) &lt;i&gt; (&lt;a href=&quot;http://www.informatik.uni-stuttgart.de/ipvr/bv/bv_home_engl.html
    Department Image Understanding&lt;/a&gt; / &lt;a href=&quot;http://www.uni-stuttgart.de
    University of Stuttgart&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The AR Face Database</h3>
  <p class=MsoNormal><a
href="http://rvl1.ecn.purdue.edu/~aleix/aleix_face_DB.html">http://rvl1.ecn.purdue.edu/~aleix/aleix_face_DB.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Contains over 4,000 color images
    corresponding to 126 people's faces (70 men and 56 women). Frontal views
    with variations in facial expressions, illumination, and occlusions.
    (Formats: RAW (RGB 24-bit)) &lt;i&gt; (&lt;a href=&quot;http://rvl.www.ecn.purdue.edu/RVL/
    Purdue Robot Vision Lab&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    The USC-SIPI image database</h3>
  <p class=MsoNormal><a href="http://sipi.usc.edu/services/database/Database.html">http://sipi.usc.edu/services/database/Database.html</a></p>
  <p class=MsoNormal>is a collection of digitized images. It is maintained
    primarily to support research in image processing, image analysis, and
    machine vision. The first edition of the USC-SIPI image database was
    distributed in 1977 and many new images have been added since then. The
    database is divided into volumes based on the basic character of the
    pictures. Images in each volume are of various sizes such as 256x256
    pixels, 512x512 pixels, or 1024x1024 pixels. All images are 8 bits/pixel
    for black and white images, 24 bits/pixel for color images. The following
    volumes are currently available: </p>
  <p class=MsoNormal>Textures Brodatz textures, texture mosaics, etc.</p>
  <p class=MsoNormal>Aerials High altitude aerial images</p>
  <p class=MsoNormal>Miscellaneous Lenna, the baboon, and other favorites</p>
  <p class=MsoNormal>Sequences Moving head, fly-overs, moving vehicles</p>
  <p class=MsoNormal style='tab-stops:192.0pt'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    The Vision Texture database</h3>
  <p class=MsoNormal><a
href="http://www-white.media.mit.edu/vismod/imagery/VisionTexture/vistex.html">http://www-white.media.mit.edu/vismod/imagery/VisionTexture/vistex.html</a></p>
  <p class=MsoNormal>is a collection of texture images. The database was
    created with the intention of providing a large set of high quality textures
    for computer vision applications. Unlike other texture collections, the
    images in VisTex do not conform to rigid frontal plane perspectives and
    studio lighting conditions. The goal of VisTex is to provide texture
    images that are representative of real world conditions. While VisTex
    can serve as a replacement for traditional texture collections, it includes
    examples of many non-traditional textures. The database has 4 main components:</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Reference Textures: 100+ homogeneous textures in frontal and oblique
    perspectives.</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Texture Scenes: Images with multiple textures. (&quot;real-world&quot;)
    scenes.</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Video Textures: Sequences of temporal textures. (UNDER CONSTRUCTION)</p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;&nbsp;&nbsp; </span>*
    Video Orbits: Images within a common projective group.(UNDER CONSTRUCTION)</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Traffic Image Sequences and 'Marbled Block' Sequence</h3>
  <p class=MsoNormal><a href="http://i21www.ira.uka.de/image_sequences">http://i21www.ira.uka.de/image_sequences</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>thousands of frames of digitized
    traffic image sequences as well as the 'Marbled Block' sequence (grayscale
    images) (Formats: GIF) &lt;i&gt; (&lt;a href=&quot;http://i21www.ira.uka.de
    IAKS/KOGS&lt;/a&gt; / &lt;a href=&quot;http://www.uni-karlsruhe.de Universitaet
    Karlsruhe (TH)&lt;/a&gt;) &lt;/i&gt;</p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    U Bern Face images</h3>
  <p class=MsoNormal><a href="ftp://ftp.iam.unibe.ch/pub/Images/FaceImages">ftp://ftp.iam.unibe.ch/pub/Images/FaceImages</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>hundreds of images (Formats: Sun
    rasterfile) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    U Michigan textures</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="ftp://freebie.engin.umich.edu/pub/misc/textures">ftp://freebie.engin.umich.edu/pub/misc/textures</a></p>
  <p class=MsoNormal>(Formats: compressed raw) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    U Oulu wood and knots database</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="ftp://ftp.ee.oulu.fi/pub/tklab/">ftp://ftp.ee.oulu.fi/pub/tklab/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Includes classifications - 1000+
    color images (Formats: ppm) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    U Plymouth Image Archive</h3>
  <p class=MsoNormal><a href="http://www.cis.plym.ac.uk/cis/3Darchive.html">http://www.cis.plym.ac.uk/cis/3Darchive.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>1800 views of 5 synthetic 3D objects,
    the views being collected from the whole upper viewing hemisphere<span
style="mso-spacerun: yes">&nbsp;&nbsp; </span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    UMass Vision Image Archive</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="http://periscope.cs.umass.edu/~vislib/">http://periscope.cs.umass.edu/~vislib/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Large image database with aerial,
    space, stereo, medical images and more. (Formats: homebrew) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    UNC's 3D image database</h3>
  <p class=MsoNormal><a
href="ftp://sunsite.unc.edu/pub/academic/computer-science/virtual-reality/3d">ftp://sunsite.unc.edu/pub/academic/computer-science/virtual-reality/3d</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>many images (Formats: GIF) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    University of Oulu Physics-based Face Database</h3>
  <p class=MsoNormal><a href="http://www.ee.oulu.fi/research/imag/color/pbfd.html">http://www.ee.oulu.fi/research/imag/color/pbfd.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>contains
    color images of faces under different illuminants and camera calibration
    conditions as well as skin spectral reflectance measurements of each
    person. Machine Vision and Media Processing Unit. University of Oulu
    http://www.oulu.fi </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Usenix face database</h3>
  <p class=MsoNormal><a href="ftp://ftp.uu.net/published/usenix/faces">ftp://ftp.uu.net/published/usenix/faces</a></p>
  <p class=MsoNormal>hundreds of images in several formats<span
style="mso-spacerun: yes">&nbsp;&nbsp; </span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    USC-SIPI image database </h3>
  <p class=MsoEndnoteText><span style='font-size:12.0pt'>was first made available
      in 1977 (<a href="http://sipi.usc.edu/services/database/Database.html">http://sipi.usc.edu/services/database/Database.html</a>)
      .<o:p></o:p></span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    USF Range Image Data with Segmentation Ground Truth</h3>
  <p class=MsoNormal><a
href="http://marathon.csee.usf.edu/range/seg-comp/SegComp.html">http://marathon.csee.usf.edu/range/seg-comp/SegComp.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>80 image sets (Formats: Sun rasterimage) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Utah Range Image database </h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="ftp://cs.utah.edu/pub/range-database/">ftp://cs.utah.edu/pub/range-database/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>33 images (Formats: homebrew formats) </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Vienna University of Technology, Computer Science Department, Image Database,
    Institute of Computer Aided Automation, Pattern Recognition and Image
    Processing Group</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span><a
href="http://www.prip.tuwien.ac.at/prip/image.html">http://www.prip.tuwien.ac.at/prip/image.html</a><span
style="mso-spacerun: yes">&nbsp; </span></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>An image database including some
    textures<span style="mso-spacerun: yes">&nbsp;&nbsp; </span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    View Sphere Database</h3>
  <p class=MsoNormal><a
href="http://www-prima.inrialpes.fr/Prima/hall/view_sphere.html">http://www-prima.inrialpes.fr/Prima/hall/view_sphere.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Images of 8 objects seen from many
    different view points. The view sphere is sampled using a geodesic with
    172 images/sphere. Two sets for training and testing are available. (Formats:
    ppm) http://www-prima.inrialpes.fr/Prima/ </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Vision-list Imagery Archive</h3>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp; </span><a
href="ftp://ftp.vislist.com/IMAGERY/">ftp://ftp.vislist.com/IMAGERY/</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>Many images, many formats </p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Yale Face Database</h3>
  <p class=MsoNormal><a
href="http://cvc.yale.edu/projects/yalefaces/yalefaces.html">http://cvc.yale.edu/projects/yalefaces/yalefaces.html</a></p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>165 images (15 individuals) with
    different lighting, expression, and occlusion configurations.<span
style="mso-spacerun: yes">&nbsp; </span></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    Yale Face Database B</h3>
  <p class=MsoNormal>Center for Computational Vision and Control, Yale University
    http://cvc.yale.edu/ </p>
  <p class=MsoNormal><span style="mso-spacerun: yes">&nbsp;</span>-<span
style="mso-spacerun: yes">&nbsp; </span>5760 single light source images of
    10 subjects each seen under 576 viewing conditions (9 poses x 64 illumination
    conditions). (Formats: PGM) <a
href="http://cvc.yale.edu/projects/yalefacesB/yalefacesB.html">http://cvc.yale.edu/projects/yalefacesB/yalefacesB.html</a></p>
  <h3 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    <span
style='font-family:"Times New Roman"'><span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>
    <![endif]>
    James Wang’s Resarch Group, University of Pennsylvania,<span style="mso-spacerun: yes">&nbsp; </span>Test
    Data</h3>
  <p class=ReferencesText>James Wang’s group, for example, maintains a demonstration
    on-line against 70,000+ images and several downloadable databases for
    research comparison </p>
  <p class=ReferencesText>- 10,000 test images (misc. database used in WBIIS);</p>
  <p class=ReferencesText>- 60,000 test images (corel1m database used in
    SIMPLIcity, 1.9GB);</p>
  <p class=ReferencesText>- 1,000 test images (test database used in SIMPLIcity
    paper).<span class=MsoHyperlink><span style='color:blue'> <a
href="http://wang.ist.psu.edu/docs/related/">http://wang.ist.psu.edu/docs/related/</a></span></span></p>
  <h1 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    4.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Project Documents</h1>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    4.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Cornell CDIC Meeting, 1999</h2>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    4.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Kenney 2000a</h2>
  <p class=MsoNormal>Anne R. Kenney. “Test Database for Digital Visual Resources
    in Art History. <i>CLIR Issues</i><span style='font-style:normal'>.,
    No. 18. November/December 2000. Available <a
href="http://www.clir.org/pubs/issues/issues18.html#test">http://www.clir.org/pubs/issues/issues18.html#test</a> [July
    31, 2002].</span></p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    4.3<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Kenney 2000b</h2>
  <p class=ReferencesText>Anne Kenney. “Creating a Test Database for Digital
    Visual Resources”. Coalition for Networked Information Fall 2000 Task
    Force Meeting. San Antonio, TX, December 7-9, 2000. Unpublished Presentation
    slides</p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    4.4<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    2001 Planning Meeting Notes</h2>
  <p class=MsoNormal>“Planning Meeting for Test Database for Digital Visual
    Resources”. Association for Research Libraries, Washington, DC. May 31,
    2001, Unpublished Report.</p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    4.5<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Lynch Scenarios</h2>
  <p class=MsoNormal>Clifford Lynch, “Scenarios for the Development of an
    Imaging Benchmark Database”. Unpublished draft. February 7, 2002.</p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    4.6<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    CNI Project Description</h2>
  <p class=MsoNormal>Image Retrieval Benchmark Database. <a
href="http://www.cni.org/projects">http://www.cni.org/projects</a></p>
  <h2 style='margin-left:0in;text-indent:0in'>
    <![if !supportLists]>
    4.7<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>
    <![endif]>
    Jorgensen 2002</h2>
  <p class=MsoNormal>Proposal brought to planning meeting, May 2001</p>
  <p class=MsoNormal><span style='font-size:12.0pt'>
    <![if !supportEmptyParas]>
&nbsp;
    <![endif]>
    <o:p></o:p></span></p>
</div>
<div style='mso-element:endnote-list'>
  <![if !supportEndnotes]>
  <br clear=all>
  <hr align=left size=1 width="33%">
  <![endif]>
  <div style='mso-element:endnote' id=edn1>
    <p class=MsoNormal><a style='mso-endnote-id:edn1' href="trantrefs.htm#_ednref1" name="_edn1"
title=""><span class=MsoEndnoteReference><span style='font-size:8.0pt'><span
style='mso-special-character:footnote'>
      <![if !supportFootnotes]>
      [i]
      <![endif]>
      </span></span></span></a><span
style='font-size:8.0pt'> The website provides examples of metadata that might
      surprise humanists using images:<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of missions in
        catalog: 143<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of frames in
        catalog: 433435<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Special film types<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Number
        of frames that are color visible light: 347896<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Number
        of frames that are color infrared: 42143<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Number
        of frames that are black and white: 23793<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of frames taken
        with ESC: 127<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Camera / Film formats<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Number
        of frames taken by Skylab Multispectral Photographic Camera: 33285<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Number
        of frames taken by Skylab Earth Terrain Camera: 5478<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Number
        of frames taken by Linhof: 29557<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Number
        of frames taken by Hasselblad: 328432<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of frames taken
        by 35 mm: 15939<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of frames with
        an entry for tilt angle (suggesting they are earth-looking): 367518<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, number of remaining frames with an entry for focal length:
        349195<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, number of remaining frames with normal exposure: 227040<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, number of frames designated with HO tilt angle: 41268<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, subset taken with 40-89 mm lens: 13287<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, subset taken with 90-249 mm lens: 18293<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, subset taken with 250 + mm lens: 8824 Of these, number of
        frames designated with LO or NV tilt angle: 80596<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, subset taken with 40-89 mm lens: 6033<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, number with center and nadir point data: 657 Of these, subset
        taken with 90-249 mm lens: 32841<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>Of
        these, number with center and nadir point data: 7247 Of these, subset
        taken with 250 + mm lens: 41477<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Of these, number with
        center and nadir point data: 12495<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>FRAMES &lt;= 25% cloud
        cover<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of frames &lt;=
        25% cloud cover in catalog: 218230<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of these frames
        with an entry for tilt angle (suggesting they are earth-looking):
        204489<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, number of remaining frames with an entry for focal length:
        196922<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, number of remaining frames with normal exposure: 133566<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, number of frames designated with HO tilt angle: 14615<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, subset taken with 40-89 mm lens: 4552<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>Of
        these, subset taken with 90-249 mm lens: 6826<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, subset taken with 250 + mm lens: 3125 Of these, number of
        frames designated with LO or NV tilt angle: 47497<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>Of
        these, subset taken with 40-89 mm lens: 2524<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Of
        these, number with center and nadir point data: 432 Of these, subset
        taken with 90-249 mm lens: 19056<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="mso-spacerun:
yes">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>Of
        these, number with center and nadir point data: 4544 Of these, subset
        taken with 250 + mm lens: 25828<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Of these, number with
        center and nadir point data: 8424<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>FRAMES &gt;= 70% cloud
        cover<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of frames &gt;=
        70% cloud cover in catalog: 65426<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>SUNGLINT<o:p></o:p></span></p>
    <p class=MsoNormal><span style='font-size:8.0pt'>Number of frames taken
        with a sun elevation between 42 and 57 degrees. 75342<o:p></o:p></span></p>
    <p class=MsoEndnoteText><span style='font-size:8.0pt'>
      <![if !supportEmptyParas]>
&nbsp;
      <![endif]>
      <o:p></o:p></span></p>
  </div>
  <div style='mso-element:endnote' id=edn2>
    <p class=MsoNormal><a style='mso-endnote-id:edn2' href="trantrefs.htm#_ednref2" name="_edn2"
title=""><span class=MsoEndnoteReference><span style='font-size:8.0pt'><span
style='mso-special-character:footnote'>
      <![if !supportFootnotes]>
      [ii]
      <![endif]>
      </span></span></span></a><span
style='font-size:8.0pt'> The Facial Expression Resources Page distinguishes
      this field of cognitive studies from facial recognition and provides
      links to research groups and other resources concerning facial expression
      perception, recognition and synthesis. It lists researchers in Cognitive
      Modeling; Experimental Psychology/Cognitive Science; Automatic Facial
      Expression Recognition &amp; Cognitive Engineering; anf Facial Expression
      Synthesis. <o:p></o:p></span></p>
    <p class=MsoEndnoteText><span style='font-size:8.0pt'>
      <![if !supportEmptyParas]>
&nbsp;
      <![endif]>
      <o:p></o:p></span></p>
  </div>
  <div style='mso-element:endnote' id=edn3>
    <p class=MsoNormal><a style='mso-endnote-id:edn3' href="trantrefs.htm#_ednref3" name="_edn3"
title=""><span class=MsoEndnoteReference><span style='font-size:8.0pt'><span
style='mso-special-character:footnote'>
      <![if !supportFootnotes]>
      [iii]
      <![endif]>
      </span></span></span></a> <span style='font-size:8.0pt'>The Face Recognition
      Home Page,<span
style="mso-spacerun: yes">&nbsp; </span><a
href="http://www.cs.rug.nl/users/peterkr/FACE/face.html">http://www.cs.rug.nl/users/peterkr/FACE/face.html</a>,
      lists 75 Research Groups with their urls and half a dozen university
      face databases being used for facial recognition research.</span></p>
  </div>
</div>
</body>
</html>
