<html>
<script src="utility.txt"></script>
<script src="popup.txt"></script>
<STYLE>
.popupLink { outline: none }
.popup { POSITION: absolute; VISIBILITY: hidden; BACKGROUND-COLOR: #d0ddee; width: 250; BORDER-LEFT: 1px solid black; BORDER-TOP: 1px solid black; BORDER-BOTTOM: 3px solid black; BORDER-RIGHT: 3px solid black; PADDING: 3px; z-index: 10 }
</STYLE>
<head>
<title>Citations: Voorhees and Donna Harman - Ellen (ResearchIndex)</title>
<meta name="keywords" content="Ellen M. Voorhees and Donna Harman. Overview of the 5th Text Retrieval Conference (TREC5) . In The 5th Text Retrieval Conference (TREC-5), NIST SP 500-238, pages 1--28, 1997.">
<meta name="description" content="Ellen M. Voorhees and Donna Harman. Overview of the 5th Text Retrieval Conference (TREC5) . In The 5th Text Retrieval Conference (TREC-5), NIST SP 500-238, pages 1--28, 1997.">
</head>
<body bgcolor="#ffffff" vlink="#7700ff" link="#0000ff" alink="#7700ff">
<style type="text/css">
<!--
body { font-family: arial, Helvetica, sans-serif; font-size: 10pt; }
.l { font-family: arial, Helvetica, sans-serif; font-size: 11pt; }
.m { font-family: arial, Helvetica, sans-serif; font-size: 10pt; }
.s { font-family: arial, Helvetica, sans-serif; font-size: 9pt; }
.t { font-family: arial, Helvetica, sans-serif; font-size: 8pt; }
.h { font-family: arial, Helvetica, sans-serif; font-size: 10pt; }
.tl:link { color: #0000ff; text-decoration:none; }
.cl:link { color: #6666ff; text-decoration:none; }
.tl:visited { color: #0000ff; text-decoration:none; }
.cl:visited { color: #6666ff; text-decoration:none; }
.tl:hover { color: #0000ff; text-decoration:underline; }
.cl:hover { color: #6666ff; text-decoration:underline; }
.c { color: #777777; text-decoration:none; }
.i { color: #777777; }
-->
</style>
<span class=m>
25 citations found. Retrieving documents...<br>
<table class=m border=0 cellpadding=1 cellspacing=0 width=100%><tr><td bgcolor="#d0ddee"><span class=h> <b>Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the eighth Text REtrieval Conference (TREC-8). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Eighth Text REtrieval Conference (TREC-8), pages 1--24, 2000. NIST Special Publication 500-246. Electronic version available at http://trec.nist.gov/pubs. html.</b><br><br><a href="http://citeseer.ist.psu.edu/cs"><img border=0 align=center src="cssmall.gif"></a> &nbsp;<a href="http://citeseer.ist.psu.edu/cs">Home/Search</a> &nbsp; <span class=i>Document Not in Database</span> &nbsp; <a href="http://citeseer.ist.psu.edu/contextsummary/259941/0">Summary</a> &nbsp; <a href="http://citeseer.ist.psu.edu/nrelatedgid/259941">Related Articles</a> &nbsp; <a href="http://citeseer.ist.psu.edu/check/259941">Check</a> &nbsp; </span></td></tr></table><br>
This paper is cited in the following contexts:<hr>
<a href="http://citeseer.ist.psu.edu/rinaldi02towards.html">Towards Answer Extraction: An Application to Technical .. - Rinaldi, Dowdall.. (2002)</a>
 
</font> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/543798"><font color=#6f6f6f>(Correct)</font></a></a><p>....Answer Extraction systems typically allow the user to ask arbitrary questions and aim at retrieving, in a given corpus, a small snippet of text which provides an answer. <b> Research in this area has been promoted in the past couple of years by, in particular, the QA track of the TREC competitions <!--cite--><font color=green>[18, 21]</font>.</b> The participants in this competition have the opportunity to measure how well their systems can retrieve answers to a predefined set of questions from a very large collection of documents. <b>They</b> run their system on the given questions and return for each a ranked list of five answers in the form ....
<br><br>
....words approach inherited from IR will never be able to distinguish different strings that contain the same words in different syntactic configurations and that therefore encode different meanings, such as absence of evidence and evidence of absence . <b> Results from the two first TRECQA tracks <!--cite--><font color=green>[19, 21]</font> showed clearly that traditional IR techniques are not sufficient for satisfactory Question Answering.</b> When the answer is restricted to a very small window of text (50 bytes) systems that relied only on those techniques fared significantly worse than systems that employed some kind of language ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>, eds. Proceedings of the Ninth Text REtrieval Conference (TREC-9), Gaithersburg, Maryland, November 13-16, 2000.</font><hr>
<a href="http://citeseer.ist.psu.edu/455563.html">Morphological Disambiguation for Hebrew Search Systems - Carmel, Maarek</a>
 
</font> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/455563"><font color=#6f6f6f>(Correct)</font></a></a><p>....average recall and precision of the search results and the Recall Precision graph which shows both criteria simultaneously. <b>Typically</b>, when precision goes up, recall goes down and vice versa. <b> Such measures can be evaluated for individual queries, or averaged over a set of queries as described in <!--cite--><font color=green>[14]</font>.</b> Recall and precision are not absolute measures in the sense that they strongly depend on the chosen test collection and therefore can only be used for comparative purpose. <b>The</b> performance of two search engines can be compared by comparing the average recall precision measures of the engines for ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the Sixth Text REtrival conference (TREC-6). In Procceedings of the Sixth Text REtrieval Conference. National Institute of Standards and Technology, August 1997. This article was processed using the L a T E X macro package with LLNCS style </font><hr>
<a href="http://citeseer.ist.psu.edu/clarke01exploiting.html">Exploiting Redundancy in Question Answering - Clarke, Cormack, Lynam (2001)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2026768/455321">(16&nbsp;citations)</a>&nbsp; <a href="http://citeseer.ist.psu.edu/correct/455321"><font color=#6f6f6f>(Correct)</font></a></a><p>....annually by the U.<b>S</b>. <b> National Institute of Standards and Technology (NIST) 22] For TREC 9, the most recent conference, the task consisted of 682 questions posed over a 3GB target corpus comprised of newspaper articles, where an answer for each question was guaranteed to appear in the corpus <!--cite--><font color=green>[21]</font>.</b> Answers take the form of text fragments extracted from the target corpus. <b>For</b> each experimental run, ve attempts were given to answer each question. <b>The</b> attempts were ranked, and the primary evaluation measure is based on the rank of the rst fragment containing a correct answer. <b>Two</b> types of ....
<br><br>
....the selection rules. <b>This</b> general approach of question analysis followed by IR followed by IE is nearly ubiquitous in QA systems [1, 4, 8, 10,13,14,16,20,23] Using relatively simple question parsing and answer selection components our QA system provides good performance. <b> For the TREC 9 QA task <!--cite--><font color=green>[21]</font> the system placed in the top three for both 50 and 250 byte runs.</b> Our experience with the TREC QA task indicated that three speci c features make the greatest contribution to the Parsing Passage Retrieval Question Answers Passages Selection Rules Query Corpus Selection Answer Figure ....
<br><br>
[Article contains additional citation context not shown here]
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>, editors. Proceedings of the Ninth Text REtrieval Conference, Gaithersburg, MD, 2000. See trec.nist.goc.</font><hr>
<a href="http://citeseer.ist.psu.edu/stricker99two.html">Two Steps Feature Selection and Neural Network.. - Stricker, Vichot.. (1999)</a>
 
</font> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/325657"><font color=#6f6f6f>(Correct)</font></a></a><p>....which have been judged irrelevant by a relevance assessor of TREC. 2. <b>Those</b> which have never been looked at; they are assumed to be irrelevant. <b> The documents from the first category have been checked because they were suspected to be relevant by some previous system (see TREC overview papers <!--cite--><font color=green>[Voorhees and Harman, 1999]</font> for more details on the pooling technique used in TREC) Therefore, these documents can be said to be close to the relevant documents: they are not representatives of the class of the irrelevant documents.</b> Some first experiments have shown that the results are better if we consider only ....
<br><br>
<font color="#999999">. Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the 7 th Text Retrieval Conference (TREC-7). In The Seventh Text Retrieval Conference (TREC-7), NIST Special Publication 500-242, 1999. </font><hr>
<a href="http://citeseer.ist.psu.edu/312381.html">Overview of the University of Pennsylvania's TIPSTER Project - Baldwin, Morton, Bagga</a>
 
</font> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/312381"><font color=#6f6f6f>(Correct)</font></a></a><p>....of the previous evaluation. <b>Precision</b> 80.3 322 (322 79) Recall 57.6 322 (322 237) Compression 83.0 Accuracy 65.3 (322 272) 910 Discussion We view the results of the first evaluation as promising in that they compare favorably with inter assessor consistency using the entire document. <b> <!--cite--><font color=green>[15]</font> reports unanimous relevance judgments by three assessors for 71.7 of the documents.</b> Interpolating this figure to two assessors yields an 80.1 agreement figure. <b>Using</b> summaries which on average are only 17.2 of the original document, our assessors matched the TREC assessors for 75.0 of the ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the fifth Text REtrieval Conference (TREC-5). In Proceedings of the Fifth Text REtrieval Conference (TREC-5), pages 1--28. NIST 500-238, 1997.</font><hr>
<a href="http://citeseer.ist.psu.edu/baldwin98dynamic.html">Dynamic Coreference-Based Summarization - Baldwin, Morton (1998)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/211860/213372">(7&nbsp;citations)</a>&nbsp; <a href="http://citeseer.ist.psu.edu/correct/213372"><font color=#6f6f6f>(Correct)</font></a></a><p>....results of the previous evaluation. <b>Precision</b> 80.3 322 (322 79) Recall 57.6 322 (322 237) Compression 83.0 Accuracy 65.3 (322 272) 910 Discussion We view the results of the first evaluation as promising in that they compare favorably with inter assessor consistency using the entire document. <b> <!--cite--><font color=green>[11]</font> reports unanimous relevance judgments by three assessors for 71.7 of the documents.</b> Interpolating this figure to two assessors yields an 80.1 agreement figure. <b>Using</b> summaries which on average are only 17.2 of the original document, our assessors matched the TREC assessors for 75.0 of the ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the fifth Text REtrieval Conference (TREC-5). In Proceedings of the Fifth Text REtrieval Conference (TREC-5), pages 1--28. NIST 500-238, 1997.</font><hr>
<a href="http://citeseer.ist.psu.edu/allan98event.html">Event Tracking - Allan, Lavrenko, Papka (1998)</a>
 
</font> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/173727"><font color=#6f6f6f>(Correct)</font></a></a><p>....evaluation approach is different than the more established TREC filtering task. <b>The</b> latter provides a large amount of training data with queries and relevance judgments, and requires that sites generate filtering queries that will work on a test set provided later. <b> In the TREC 6 filtering track,<!--cite--><font color=green>[21]</font> the training data includes anywhere from 6 to 887 relevant documents, with a mean of 123 (the routing track had between 8 and 2,431 relevant documents with a mean of 576) Although there are settings where that much training information is possible, it is difficult to argue that the setting is .</b>...
<br><br>
....tf is the number of times the feature occurs in the story, df i is the total number of the times the feature occurs in the collection, and N is the number of stories in the collection. <b> This weighting function is a simplification of the more complex weighting scheme currently used in InQuery<!--cite--><font color=green>[21]</font>; it assumes that all stories are of roughly the same length, that the collection is never empty, and that df i is not zero.</b> In order that the tracking system model a real setting, the collection information cannot be known in advance. <b>For</b> that reason, the corpus wide parts of the weighting ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the sixth text retrieval conference. In E. M. Voorhees and D. K. Harman, editors, The Sixth Text REtrieval Conference (TREC-6), 1998. NIST Special Publication, forthcoming.</font><hr>
<a href="http://citeseer.ist.psu.edu/allan98event.html">Event Tracking - Allan, Lavrenko, Papka (1998)</a>
 
</font> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/173727"><font color=#6f6f6f>(Correct)</font></a></a><p>....the 25 events, each of the stories was assigned a judgment on a ternary scale: about the event, not about the event, or mentioning the event but only briefly in a story that is generally not about the event. <b>The</b> exhaustive judgments of this corpus are in contrast to more common pooled strategies. <b><!--cite--><font color=green>[20]</font> An unfortunate side effect of requiring exhaustive judgments is that the cost of creating them limits the size of the corpus.</b> The TDT corpus and relevance judgments are available from the Linguistic Data Consortium. <b>The</b> LDC is currently creating a second and larger TDT corpus that includes a ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the fifth text retrieval conference. In E. M. Voorhees and D. K. Harman, editors, The Fifth Text REtrieval Conference (TREC-5), pages 1--28, November 1997. NIST Special Publication 500-238.</font><hr>
<a href="http://citeseer.ist.psu.edu/126480.html">The TREC-7 Filtering Track: Description and Analysis - Hull</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/136877/126480">(27&nbsp;citations)</a>&nbsp; <a href="http://citeseer.ist.psu.edu/correct/126480"><font color=#6f6f6f>(Correct)</font></a></a><p>....used by each of the groups in their experiments. <b>The</b> information presented here is based on the material provided by the participants in their draft papers, and so should be considered preliminary and incomplete. <b> For more information, please consult the site report papers included in this volume <!--cite--><font color=green>[5]</font>.</b> IBM A and Rutgers K did not provide notebook papers so there is no information available on these systems. <b>Both</b> participated only in the routing subtask. <b>AT</b> T participated in batch filtering and routing. <b>One</b> routing run (fr5) was based on a scaled down version of their TREC 6 routing system. <b>The</b> ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>, editors. The 7th Text Retrieval Conference (TREC-7), 1999. To appear. </font><hr>
<a href="http://citeseer.ist.psu.edu/126480.html">The TREC-7 Filtering Track: Description and Analysis - Hull</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/136877/126480">(27&nbsp;citations)</a>&nbsp; <a href="http://citeseer.ist.psu.edu/correct/126480"><font color=#6f6f6f>(Correct)</font></a></a><p>....descriptions of the information need, ranging from 50 250 words in length with an average length of roughly 100 words. <b>They</b> are divided into title, description, narrative and concept fields. <b> For an example of the style of these long topics, see the introductory paper in the TREC 6 proceedings <!--cite--><font color=green>[4]</font>.</b> Since topics 1 50 have been used at several previous TREC conferences, there are relevance judgements available for the 1988 and 1989 AP collection. <b>However</b>, the 1988 judgements do not have the quality and coverage typically associated with TREC, since they come from the TREC 1 experiments. <b>The</b> ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the 6th Text Retrieval Conference (TREC6) . In The Sixth Text Retrieval Conference (TREC-6), NIST SP 500-240, pages 1--24, 1998.</font><hr>
<a href="http://citeseer.ist.psu.edu/28797.html">The TREC-6 Filtering Track: Description and Analysis - Hull</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/136877/28797">(27&nbsp;citations)</a>&nbsp; <a href="http://citeseer.ist.psu.edu/correct/28797"><font color=#6f6f6f>(Correct)</font></a></a><p>....Amherst [UMass] INQ4) University of North Carolina [UNC] isf) 3.1 Summary of approaches In this section, we briefly describe the techniques used by each of the groups for the filtering track 1 . <b> For more information, please consult the individual participants papers included in this volume <!--cite--><font color=green>[5]</font>.</b> Almost all participants treat filtering as a special case of routing, using a ranked retrieval system, followed by thresholding based on the document score. <b>The</b> vast majority of systems use the same basic technique for finding the threshold: observe the score on the training set where the ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>, editors. The 6th Text Retrieval Conference (TREC-6), 1998. To appear. </font><hr>
<a href="http://citeseer.ist.psu.edu/28797.html">The TREC-6 Filtering Track: Description and Analysis - Hull</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/136877/28797">(27&nbsp;citations)</a>&nbsp; <a href="http://citeseer.ist.psu.edu/correct/28797"><font color=#6f6f6f>(Correct)</font></a></a><p>....subtrack defined later in this section. 2. <b>1 Topics and Documents The corpus for the TREC 6 filtering experiments comes from the Foreign Broadcast Information Service (FBIS) which selects (and translates) text documents or transcripts from various nonAmerican broadcast and print publications <!--cite--><font color=green>[4]</font>.</b> The 130,000 training documents date mostly from 1993 and early 1994 while the 120,000 test documents date come from late 1994 and 1995. <b>All</b> documents have date stamps attached and have been ordered according to their date. <b>The</b> date stamps represent (more or less) the release date of the FBIS ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the 5th Text Retrieval Conference (TREC5) . In The 5th Text Retrieval Conference (TREC-5), NIST SP 500-238, pages 1--28, 1997.</font><hr>
<a href="http://citeseer.ist.psu.edu/750788.html">Overview of TREC 2004 - Ellen Voorhees National (2001)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2026771/750788">(38&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/750788"><font color=#6f6f6f>(Correct)</font></a></a><p>No context found.<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the eighth Text REtrieval Conference (TREC-8). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Eighth Text REtrieval Conference (TREC-8), pages 1--24, 2000. NIST Special Publication 500-246. Electronic version available at http://trec.nist.gov/pubs. html.</font><hr>
<a href="http://citeseer.ist.psu.edu/750786.html">Overview of TREC 2001 - Ellen Voorhees Donna (2001)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2026771/750786">(38&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/750786"><font color=#6f6f6f>(Correct)</font></a></a><p>No context found.<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the eighth Text REtrieval Conference (TREC-8). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Eighth Text REtrieval Conference (TREC-8), pages 1-24, 2000. NIST Special Publication 500-246. Electronic version available at http: //trec.nist.gov/pubs.html.</font><hr>
<a href="http://citeseer.ist.psu.edu/750588.html">Overview of TREC 2005 - Ellen Voorhees National (2001)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2026771/750588">(38&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/750588"><font color=#6f6f6f>(Correct)</font></a></a><p>No context found.<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the eighth Text REtrieval Conference (TREC-8). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Eighth Text REtrieval Conference (TREC-8), pages 1--24, 2000. NIST Special Publication 500-246. Electronic version available at http://trec.nist.gov/pubs.html.</font><hr>
<a href="http://citeseer.ist.psu.edu/674022.html">Overview of TREC 2003 - Voorhees (2001)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2026771/674022">(38&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/674022"><font color=#6f6f6f>(Correct)</font></a></a><p>No context found.<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the eighth Text REtrieval Conference (TREC-8). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Eighth Text REtrieval Conference (TREC-8), pages 1--24, 2000. NIST Special Publication 500-246. Electronic version available at http://trec.nist.gov/pubs. html.</font><hr>
<a href="http://citeseer.ist.psu.edu/655069.html">Overview of the TREC 2003 Robust Retrieval Track - Ellen Voorhees National</a>
 
</font> &nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/655069"><font color=#6f6f6f>(Correct)</font></a></a><p>No context found.<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the sixth Text REtrieval Conference (TREC-6). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Sixth Text REtrieval Conference (TREC-6), pages 1--24, August 1998. NIST Special Publication 500-240. Electronic version available at http://trec.nist.gov/pubs.html. </font><hr>
<a href="http://citeseer.ist.psu.edu/652244.html">Overview of the Ninth Text REtrieval Conference (TREC-9) - Voorhees, Harman</a>
 
</font> &nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/652244"><font color=#6f6f6f>(Correct)</font></a></a><p>No context found.<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the eighth Text REtrieval Conference (TREC-8). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Eighth Text REtrieval Conference (TREC-8), pages 1-24, 2000. NIST Special Publication 500-246. Electronic version available at http: //trec.nist.gov/pubs.html.</font><hr>
<a href="http://citeseer.ist.psu.edu/613279.html">The Philosophy of Information Retrieval Evaluation - Voorhees</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2348714/613279">(2&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/613279"><font color=#6f6f6f>(Correct)</font></a></a><p>.... <b>(as described in section 2) has sometimes showed mean di erences in mean average precision scores computed with and without a group s unique relevant documents as large as 6 8 , compared to mean percentage di erences of less than 2 for automatic runs for the monolingual TREC collections <!--cite--><font color=green>[24, 25]</font>.</b> The same analysis on the CLEF 2000 multilingual collection showed an average di erence of less than 1 [1] The somewhat larger average di erences do not invalidate the collections since comparative results are generally remain quite stable. <b>However</b>, experiments who nd many unjudged ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of TREC 2001. In Proceedings of TREC 2001 (Draft), 2001. To appear.</font><hr>
<a href="http://citeseer.ist.psu.edu/613279.html">The Philosophy of Information Retrieval Evaluation - Voorhees</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2348714/613279">(2&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/613279"><font color=#6f6f6f>(Correct)</font></a></a><p>.... <b>(as described in section 2) has sometimes showed mean di erences in mean average precision scores computed with and without a group s unique relevant documents as large as 6 8 , compared to mean percentage di erences of less than 2 for automatic runs for the monolingual TREC collections <!--cite--><font color=green>[24, 25]</font>.</b> The same analysis on the CLEF 2000 multilingual collection showed an average di erence of less than 1 [1] The somewhat larger average di erences do not invalidate the collections since comparative results are generally remain quite stable. <b>However</b>, experiments who nd many unjudged ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the eighth Text REtrieval Conference (TREC-8). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Eighth Text REtrieval Conference (TREC-8), pages 1-24, 2000. NIST Special Publication 500-246. Electronic version available at http://trec.nist.gov/pubs.html.</font><hr>
<a href="http://citeseer.ist.psu.edu/585089.html">Overview of TREC 2002 - Voorhees (2001)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2026771/585089">(38&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/585089"><font color=#6f6f6f>(Correct)</font></a></a><p>....higher at 2.2 . A similar investigation of the TREC 8 ad hoc collection showed that every automatic run that had a mean average precision score of at least . <b>1 had a percentage di erence of less than 1 between the scores with and without that group s uniquely retrieved relevant documents <!--cite--><font color=green>[11]</font>.</b> That investigation also showed that the quality of the pools is signi cantly enhanced by the presence of recall oriented manual runs, an e ect noted by the organizers of the NTCIR (NACSIS Test Collection for evaluation of Information Retrieval systems) workshop who performed their own manual ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the eighth Text REtrieval Conference (TREC-8). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Eighth Text REtrieval Conference (TREC-8), pages 1-24, 2000. NIST Special Publication 500-246. Electronic version available at http: //trec.nist.gov/pubs.html.</font><hr>
<a href="http://citeseer.ist.psu.edu/200601.html">Overview of the Seventh Text REtrieval Conference (TREC-7) - Voorhees, Harman (1998)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/1060111/200601">(5&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/200601"><font color=#6f6f6f>(Correct)</font></a></a><p>....that best describe the topic. <b>The</b> description field is a one sentence description of the topic area. <b> For TREC 7 (topics 351 400) the description field contains all of the words in the title field, to remove the confounding effects of word choice on length experiments as was exhibited in TREC 6 <!--cite--><font color=green>[11]</font>.</b> The narrative gives a concise description of what makes a document relevant. <b>Ad</b> hoc participants who used automatic query construction techniques were required to use particular parts of the topics in TREC 5 and TREC 6. <b>The</b> TREC 7 task description had no such requirements, but participants did ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the sixth Text REtrieval Conference (TREC-6). In Voorhees and Harman [12], pages 1--24. NIST Special Publication 500-240.</font><hr>
<a href="http://citeseer.ist.psu.edu/200601.html">Overview of the Seventh Text REtrieval Conference (TREC-7) - Voorhees, Harman (1998)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/1060111/200601">(5&nbsp;citations)</a>&nbsp; <b><font face=Arial,Helvetica,Geneva color=purple>Self-citation (Ellen)</font></b> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/200601"><font color=#6f6f6f>(Correct)</font></a></a><p>....the most unique relevant documents (i.e. relevant documents that were contributed to the pool by exactly one group) Almost all of the unique documents were retrieved by manual runs. <b> Note that the pattern of the sources of unique relevant documents is very similar to the pattern found for TREC 5 <!--cite--><font color=green>[10]</font>.</b> 4 Evaluation The entire purpose of building a test collection is to be able to evaluate the effectiveness of retrieval systems. <b>Providing</b> a common evaluation scheme is an important element of TREC. 4.1 Current practice All TREC tasks that involve returning a ranked list of documents are ....
<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>. Overview of the fifth Text REtrieval Conference (TREC-5). In E.M. Voorhees and D.K. Harman, editors, Proceedings of the Fifth Text REtrieval Conference (TREC-5), pages 1--28, November 1997. NIST Special Publication 500-238.</font><hr>
<a href="http://citeseer.ist.psu.edu/rinaldi02towards.html">Towards Answer Extraction: An Application to Technical .. - Rinaldi, Dowdall.. (2002)</a>
 
</font> &nbsp; <a href="http://citeseer.ist.psu.edu/correct/543798"><font color=#6f6f6f>(Correct)</font></a></a><p>No context found.<br><br>
<font color="#999999">Ellen M. <i>Voorhees and Donna Harman</i>, eds. The Eighth Text REtrieval Conference (TREC-8). NIST, 2000.</font><hr>
<a href="http://citeseer.ist.psu.edu/schwitter00answer.html">Answer Extraction - Towards better Evaluations of NLP.. - Schwitter, Molla.. (2000)</a>
 
</font>  &nbsp; <a href="http://citeseer.ist.psu.edu/context/2152994/295247">(1&nbsp;citation)</a>&nbsp; <a href="http://citeseer.ist.psu.edu/correct/295247"><font color=#6f6f6f>(Correct)</font></a></a><p>No context found.<br><br>
<font color="#999999"> Ellen M. <i>Voorhees and Donna Harman</i>. 1998.</font><br>
<SCRIPT LANGUAGE="JavaScript">
<!--
var k = new Array();
k['n'] = "http://newsseer.com/";
k['h'] = "http://citeseer.ist.psu.edu/cs";
browser = navigator.appName;
version = parseInt(navigator.appVersion);
n4 = (document.layers) ? true:false;
mozilla = (browser=="Netscape" && version>=5) ? true:false;
ie4 = (navigator.userAgent.indexOf("MSIE 4")!=-1) ? true:false;
ie5 = (navigator.userAgent.indexOf("MSIE 5")!=-1) ? true:false;
ie6 = (navigator.userAgent.indexOf("MSIE 6")!=-1) ? true:false;
ie = (navigator.userAgent.indexOf("MSIE")!=-1) ? true:false;
function GetKey(key) {
        eventChooser = (!ie) ? key.which : event.keyCode;
        if (document.all) { key = window.event; }
        if (n4) { if (key.modifiers && Event.ALT_MASK || key.modifiers && Event.CTRL_MASK) { return; } }
        if (mozilla) { if (key.altKey || key.ctrlKey) { return; } }
        which = String.fromCharCode(eventChooser).toLowerCase();
        for (var i in k) { if (which == i) { window.location = k[i]; } }
        }
document.onkeypress = GetKey;
// -->
</script>
<!-- cdv: 0.2 cid: 0 gid: 259941 did: 0 --><br><!-- abs --><font size=-1><a href="http://citeseer.ist.psu.edu/rd/0/http%3AqSqqSqciteseer.ist.psu.eduqSqonline-nature01qSq" onmouseover="self.status='http://citeseer.ist.psu.edu/online-nature01/'; return true" onmouseout="self.status=''; return true">Online articles have much greater impact</a> &nbsp; <a href="http://citeseer.ist.psu.edu/rd/0/http%3AqSqqSqciteseer.ist.psu.eduqSqlawrence99digital.html" onmouseover="self.status='http://citeseer.ist.psu.edu/lawrence99digital.html'; return true" onmouseout="self.status=''; return true">More about CiteSeer.IST</a> &nbsp; <a href="http://citeseer.ist.psu.edu/rd/0/http%3AqSqqSqciteseer.ist.psu.eduqSqcs%3Fsf%3D1" onmouseover="self.status='http://citeseer.ist.psu.edu/cs?sf=1'; return true" onmouseout="self.status=''; return true">Add search form to your site</a> &nbsp; <a href="http://citeseer.ist.psu.edu/rd/0/http%3AqSqqSqciteseer.ist.psu.eduqSqsubmitDocument.html" onmouseover="self.status='http://citeseer.ist.psu.edu/submitDocument.html'; return true" onmouseout="self.status=''; return true">Submit documents</a> &nbsp; <a href="http://citeseer.ist.psu.edu/feedback.html">Feedback</a> &nbsp; <!-- exs --><!-- exe --><br></font><!-- abe --><!--kbr--><!--kbr2--><br><font size=-1>CiteSeer.IST - Copyright <a href="http://www.psu.edu/">Penn State</a> and <a href="http://www.nec-labs.com/">NEC</a></font><br>
<SCRIPT LANGUAGE="JavaScript">
<!--
if (window != top) top.location.href = location.href;
// -->
</SCRIPT>
<!done>
<!-- Time: 1.0829 Browser: Netscape 5; Host: 128.122.140.21 UID: 52639597 Request ID: 68628 LM: Thu, 07 Dec 2006 19:19:28 GMT E: +60s Cached: 0 -->
</span></body></html>