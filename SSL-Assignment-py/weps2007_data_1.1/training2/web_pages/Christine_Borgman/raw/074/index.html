<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head profile="http://gmpg.org/xfn/11">



	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>Social Sciences Online</title>

	
	
	<meta name="generator" content="WordPress 2.0.2"><!-- leave this for stats --> 

	<link rel="stylesheet" href="style.css" type="text/css" media="screen">
	<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="blog.html">

	<style type="text/css" media="screen">
	

		
	
		/* 	To ease the insertion of a personal header image, I have done it in such a way,
			that you simply drop in an image called 'personalheader.jpg' into your /images/
			directory. Dimensions should be at least 760px x 200px. Anything above that will
			get cropped off of the image. */
		
		
		#headerimg 	{ background: url('blog_files/personalheader.jpg') no-repeat top left;}
		

	</style>

		<link rel="archives" title="July 2005" href="blog.html">
	<link rel="archives" title="June 2005" href="blog.html">

	</head><body>

<div id="page">


<div id="header">
	<div id="headerimg">
		<h1><a href="blog.html">Social Sciences Online</a></h1>
		<div class="description">Past, Present and Future</div>
	</div>
</div>
<hr>

	<div id="content" class="narrowcolumn">

			
						
			<div class="post">
				<h2 id="post-37"><a href="blog.html">Social Sciences Online: Past, Present and Future - Round Up of Discussion</a></h2>
				<small>July 1st, 2005 <!-- by Debra Hiom --></small>
				
				<div class="entry">
					<p>How
has the Internet changed the practice of social science? Eight years
ago, when the Internet was still relatively new for the academic
community, SOSIG staff were asked to predict how IT might change the
working practices of social scientists [Ferguson, N, Hiom, D &amp;
Worsfold, E. <em> IT and the Social Sciences</em>, Information UK
Outlooks, 30, 1997]. At that time the Internet was not widely used, but
social scientists have been quick to realise its potential, seeing the
Internet as both a <em>research tool</em>: enabling new research methods for data collection, analysis and dissemination); and a <em>research topic</em>: being a social phenomenon in itself, and an agent for political, economic and social change.</p>
<p>The SOSIG blog offered thoughts and reflections from practitioners
on the way that the Internet had changed their working practices, and
invited comment from the community. You need only look at the papers
and discussion to realise quite how much impact the Internet has had on
social science learning and research in a relatively short period of
time:</p>
<p>As Christine Hine indicates, the Internet has become embedded into
everyday life for many parts of the population and therefore offers a
valuable research medium for social scientists. Take a look at <a href="blog.html">Jacqui Taylor’s </a> papers and subsequent discussion for an interesting overview of some of the pros and cons of Internet mediated research.</p>
<p>Academics now have to deal with the Google generation of students
who are already Internet savvy when they arrive at university but at
the same time still lack any real information literacy skills. <a href="blog.html">David Dolowitz </a>argues
that the academic and information professions need to engage more fully
with the e-learning process in order to be able to help guide their
students to appropriate uses of the Internet in their studies.</p>
<p>In terms of information sources, we are now doing far more than
recreating the past in electronic form; instead we are generating
completely new types of resources (see <a href="blog.html">Andrew Ashwin’s and Kieren Pitt’s </a>article
on interactive learning resources). In addition, new ways of
collaborating and sharing data are being used to support the research
process (take a look at the e-Social Science papers: <a href="blog.html">Borgman, Fraser and Procter</a>).</p>
<p>Of course these new forms of information don’t always necessarily make life easier (as <a href="blog.html">Melanie Wright</a>
argue, the Internet has opened up access to data and the subsequent
potential for enabling high quality research, at a speed and extent
that we certainly didn’t fully envisage eight years ago when writing
our original article. </p>
<p>I would like to thank all the authors for their interesting and
thought provoking articles and to everyone who participated in this
virtual event by reading and commenting on the papers. The ability to
post comments will be switched off from 5pm today but an archive of all
the papers and discussion will be made available on the SOSIG site.</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">General comment</a> <strong>|</strong>   Comments Off</p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-33"><a href="blog.html">internet access to social science e-journal articles</a></h2>
				<small>June 24th, 2005 <!-- by sripriya.s --></small>
				
				<div class="entry">
					<p>INTERNET
access to vast number of users globally in their sitting place. it
helps in the access to social science journals articles in fulltext in
printed format, so it’s very helpfull to the users in research
activities in finding their related subject…….s.sipriya
</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">1 Comment »</a></p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-30"><a href="blog.html">Invited paper: Disciplinary Differences in e-Research: An Information Perspective - Christine Borgman</a></h2>
				<small>June 23rd, 2005 <!-- by cborgman --></small>
				
				<div class="entry">
					<p>e-Research
is a collective term for the various initiatives on e-Science, e-Social
Science, e-Humanities, and cyberinfrastructure. e-Research refers to
distributed, collaborative, information-intensive forms of inquiry. The
overall aim is “to do faster, better, and different interdisciplinary
research (and scholarship) across the university,” as summed up by Tony
Hey, head of the U.K. e-Science programs. e-Social Science research
currently is organized into two themes: (1) research and development of
technology, tools, and data sources to support collaborative social
science research, and (2) social study of e-Research. e-Research in all
disciplines will depend upon the generation, analysis, visualization,
management, and curation of data and documents, and upon access to
those resources. Interdisciplinary research will depend upon sharing
data within and between communities. Decades of research in information
studies and in socio-technical systems has shown that disciplines vary
greatly in their use of data and documents, in their local or
distributed access to information resources, and in their degree of
collaboration. Understanding more about the use of information is
essential to the construction of an information infrastructure to
facilitate research.</p>
<p>Christine Borgman<br>
Professor and Presidential Chair in Information Studies</p>
<p>University of California</p>
<p>Christine L. Borgman is Professor and Presidential Chair in
Information Studies at the University of California, Los Angeles
(UCLA). She is a co-principal investigator for the Center for Embedded
Networked Sensing (CENS) and for the Alexandria Digital Earth Prototype
(ADEPT) project, both funded by the National Science Foundation. She is
the author of more than 150 publications in the fields of information
studies, computer science, and communication. She won the Best
Information Science Book of the Year Award (American Society for
Information Science &amp; Technology) for From Gutenberg to the Global
Information Infrastructure: Access to Information in a Networked World
(MIT Press, 2000). She is writing a book on Scholarship in the Digital
Age while on sabbatical at the Oxford Internet Institute. Prof. Borgman
is a member of the U.S. National Committee on Data for Science and
Technology (CODATA), and the Advisory Board to the Electronic Privacy
Information Center. She is Retiring Chair of the Information,
Computing, and Communication Section of the American Association for
the Advancement of Science (AAAS) and is a Fellow of the AAAS.
</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">e-Social Science</a> <strong>|</strong>   Comments Off</p> 
				
//www.sosig.ac.uk/socsciweek/blog/wp-trackback.php?p=30" />
</rdf:RDF>				-->
			</div>
	
						
			<div class="post">
				<h2 id="post-29"><a href="blog.html">Invited Paper: Distributed Real-time Research in e-Social Science (Mike Fraser)</a></h2>
				<small>June 23rd, 2005 <!-- by mikef --></small>
				
				<div class="entry">
					<p>As
part of the MixedMediaGrid node of the National Centre for e-Social
Science, myself and colleagues at the University of Bristol and Kings
College London have been designing and developing applications to
support the distributed qualitative analysis of multimedia data. Inter
alia, the software supports ‘data sessions’: periods of time in which
researchers collaboratively analyse particular sequences of video data
and related materials in order to gain analytic insights and
perspectives from one another. Due to the research group-oriented
nature of data sessions, application clients are targeted at supporting
group-to-group, rather than analyst-to-analyst, collaboration. Given
this goal, we have been highly sensitive to the ethical and legal
issues of transmitting video. An important consideration of the system
is that each user has a local copy of the digital video corpus for that
data session, which is distributed via the existing external trusted
channels already employed by the community, rather than over the
network. For us, this approach addresses major technical and ethical
issues alike. Firstly, the real-time transmission of video would
significantly increase the bandwidth requirements of the
infrastructure. It is likely that, even with continuous high-quality
networking between all sites, real-time transmission of video data
would be at best unpredictable. Such latencies would affect the
causality and/or quality of video playback, and would most likely vary
these between multiple sites. Such problems would disrupt the causality
and relevance of events during analysis. More importantly, it would
make references between researchers to those events - conveyed between
sites through talk about them over audio links and/or annotations over
them using electronic whiteboard markers – more difficult. Secondly,
our decision to use existing channels of video data distribution means
that we can rely on existing ethical and legal practice to form part of
distributed data sessions. In addition to avoiding the need for complex
on-line access control and secure channels, data distribution can be
controlled in ways which allow researchers to understand and decide
when, how and where video data is distributed based on their detailed
knowledge of the consents and agreements associated with particular
items of data, as well as continuing to rely on existing consent
procedures and ethics committees.</p>
<p>Across the e-Science programme proclamations about changes in ways
of working for the natural sciences have been made. Grid middleware and
interfaces have been produced which embody scientific methodologies,
yet enable calculations to be performed over very large data sets very
quickly. The natural sciences have yet to uptake the technology in
droves, primarily due to issues of usability and stability of the
software. Parallel technologies are even further in their infancy.
Nonetheless it has been recognised that the social sciences might
benefit from similar approaches. However, the diversity of methods and
methodologies across the social sciences presents particular challenges
to computer science developers in terms of supporting large numbers of
users with varying approaches.</p>
<p>In the particular case of the MixedMediaGrid domain, qualitative
methodologies and techniques are supported in individual bespoke
packages, yet collaboration support between researchers over data is
sparse, particularly in real time. It remains an open question whether
qualitative social scientists as a whole wish to share their data with
others – perhaps it represents too much effort in fieldwork to risk
sharing; perhaps because many researchers plan to primarily derive new
methods and methodologies rather than empirical results from their
analyses. We are lucky enough to be currently working in specific
fields in which real-time collaborative analysis of data occurs between
different international research groups as a matter of course. When we
arrive at a position that software can be released into broader
communities alongside development effort, the challenge for us will be
to provide adequate mechanisms for communication, ensuring consent and
ethical constraints are not breached and so on. In turn, the challenge
for the social science researchers who currently retain individual
analysis, control and storage of their data is this: will the potential
benefits of additional expert perspectives on your data – whilst still
retaining ultimate control and ownership – change your working practice
of individual analysis? We do not expect such changes to happen
overnight, or in some cases at all, in fields where such practices are
currently uncommon. Nonetheless, as technologies develop and the
opportunities present themselves, accountabilities for not sharing data
will become increasingly personal, political and organisational rather
than practical.</p>
<p>Dr. Mike Fraser is a member of the Department of Computer Science at
the University of Bristol. His research is concerned with the social
aspects of collaborative technologies. Dr. Fraser is currently director
and principal investigator of the MixedMediaGrid e-Social Science node,
and principal investigator of the VidGrid pilot project, also funded
under the e-Social Science programme. He is a member of the Research
Board of the National Centre for e-Social Science and of the e-Science
programme’s Usability Task Force.</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">e-Social Science</a> <strong>|</strong>   Comments Off</p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-21"><a href="blog.html">Invited paper: e-Social Science - Rob Procter</a></h2>
				<small>June 23rd, 2005 <!-- by rprocter --></small>
				
				<div class="entry">
					<p>Over
the past five years, researchers around the world have been talking
about a revolutionary vision for science. This vision has various
names: in the UK, it is referred to as ‘e-Science’ or – and evidence of
a growing appreciation of its broader relevance – ‘e-Research’. The
vision is inspired by two increasingly strongly inter-related
developments. The first of these is to do with research methods and the
second concerns research infrastructure and tools:</p>
<p>“e-Science is about global collaboration in key areas of science and
the next generation of infrastructure that will enable it.” John
Taylor, Director General of Research Councils, UK Office of Science and
Technology.</p>
<p>To understand the rationale behind e-Science, we need to look more
closely at the key developments in research methods and infrastructure
that are driving the vision forward. Taking research methods first, the
realisation is growing that many of today’s research challenges do not
fit comfortably within the boundaries defined by established
disciplinary and organisational structures. According to this
viewpoint, researchers will have to adopt more large scale,
collaborative and multidisciplinary methods. To take but one example,
systems biology – whose aim is to model the interactions between genes,
proteins and cells – requires contributions from biology, the physical
sciences, engineering, mathematics and computation. Moreover, progress
depends on ease of access to the vast repositories of genomic and other
data that now exist around the world, and on collaboration between the
researchers who have created them. </p>
<p>Initially largely independent of – but now increasingly driven by
(and, it has to be acknowledged, driving) developments in – research
methods, a blueprint for a new and more powerful distributed computing
infrastructure, known variously as the ‘Grid’ or cyberinfrastructure,
has been evolving. The internet (and the World Wide Web, in particular)
has helped make access to distributed resources such as data routine.
However, though the Web provides a simple, easy-to-use interface to
distributed resources, it is unlikely to meet the needs of large scale,
collaborative and multidisciplinary research. Despite the metaphor, the
Web is far from the seamless place it appears to be: it is a
fragmented, heterogeneous world, with few standards and limited
interoperability. This soon becomes apparent when researchers in
different organisations try to share their data. Lack of uniformity in
databases and data formats, and absence of mechanisms for managing
access across multiple sites can make this very tedious and very often
impractical. The Grid will address such problems and enable researchers
to access computers, databases and other resources simply and
transparently, without having to consider where those facilities are
located and regardless of their underlying heterogeneity.</p>
<p>As the e-Science vision has been refined and elaborated, its wider
potential has begun to be understood. In July of 2004, the ESRC created
the National Centre for e-Social Science with a remit to explore and
develop ways in which e-Science research methods and infrastructure can
be applied in the social sciences. The Centre is made up of a <a href="http://www.ncess.ac.uk/about/hub/index.shtml">co-ordinating hub</a>,
based at the universities of Manchester and Essex, plus a series of
research nodes located at institutions throughout the UK. As part of
its programme, the Centre has organised and is hosting the first
international conference on e-Social Science, which is taking place
between 22-24 June in Manchester.</p>
<p>Some of the benefits of e-Social Science are easy to grasp.
Computer-based modelling and simulation, for example, is a well
established social science research tool. As models get more complex,
they need computing power. The Grid will make it much easier for
researchers to access this computing power on demand. There are similar
benefits to be had from the Grid for statistics-based research
generally. These areas are being investigated by NCeSS nodes at Leeds
and Lancaster Universities. For example, the former is building a
simulation of the entire UK population at the level of individuals and
households, and the general ambition is to enable more realistic and
interdisciplinary approaches to modelling complex social phenomena.</p>
<p>The benefits of the Grid for the sharing of data may appear more
modest. After all, practices and infrastructure for sharing and
re-using data are already well established in the social sciences. Data
centres such as the UK Data Archive, MIMAS and EDINA host a wide range
of datasets – the Census, British Household Panel Survey to name but
two. This makes it easy for researchers to access individual datasets,
but heterogeneity in databases and data formats means that linking
different datasets together – as will be essential for answering
increasingly complex research questions – can still prove very
difficult. The Grid can provide solutions to these problems and its
impact is likely to be considerable. In partnership with data centres,
NCeSS has begun pilot studies of ‘grid enabling’ selected datasets.</p>
<p>There are vast amounts of data generated as people go about their
daily activities which are, as yet, barely exploited for research
purposes. For example, use of public services is captured in
administrative records; in the private sector, patterns of consumption
of goods and services are captured in credit and debit card records;
patterns of movement are logged by sensors, such as traffic cameras and
satellites, and in mobile phone records; public spaces are monitored by
CCTV; the movement of goods is increasingly tracked by devices such as
RFID tags. Exploiting these data sources to their full research
potential requires new mechanisms for ensuring secure and confidential
access to sensitive data, and new tools for integrating, structuring,
visualisation and analysis. Here, again, the Grid has the potential to
provide solutions and the Nottingham NCeSS node is investigating a
number of these.</p>
<p>Collaborative research, especially where participants are widely
distributed and so have limited opportunities to meet face-to-face,
requires communication tools that are easy to use, flexible and
scaleable. Such tools are not sufficient in themselves to ensure that
researchers will collaborate but they may help reduce some of the
obstacles. The Grid community has developed the Access Grid, a suite of
advanced, large scale video conferencing tools but much yet remains to
be done to identify and develop the full rang of tools necessary to
support collaborative research. The Bristol NCeSS node is investigating
a number of issues in the design and use of collaborative research
tools.</p>
<p>Inevitably, much of what is presently understood about e-Social
Science is an extrapolation of existing practice and is focused around
areas where it is believed the Grid can address known limitations of
research methods. How e-Social Science will develop – in particular,
what kinds of new research methods and communities will emerge – will
only become clear if researchers are prepared to explore and experiment
with the opportunities the Grid provides. To learn more about e-Social
Science and the NCeSS programme, visit <a href="http://www.ncess.ac.uk/">www.ncess.ac.uk</a></p>
<p>_____________________________________________________________</p>
<p>Rob Procter is Professor and Research Director of the ESRC-funded
National Centre for e-Social Science (NCeSS). His work within NCeSS is
mainly devoted to coordinating and developing the NCeSS research
programme. His broader research interests lie within the field of
socio-technical issues in the design, implementation, evaluation and
use of interactive computer systems, with a particular emphasis on
ethnomethodologically-informed ethnographic studies of work practices
and of technologies-in-use. Rob is a member of the JISC Virtual
Research Environments Programme Advisory Board, the e-Science Usability
Task Force, the e-Science User Group and the Arts and Humanities
Research Council ICT Programme Steering Committee.</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">1 Comment »</a></p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-24"><a href="blog.html">Invited paper: e-Government Information: the same old problem … newly digitized! - Alastair Allan</a></h2>
				<small>June 21st, 2005 <!-- by aallan --></small>
				
				<div class="entry">
					<p>Alastair J. Allan<br>
University of Sheffield</p>
<p> The migration of government to web-based format away from
traditional paper-based versions has been rapid since 1997. In some
cases, the eight year gap has been long enough for a complete move to
e-only. For a host of reasons, digitized information has become the
format of choice within government. The assumption has always been that
if something has been computerized, then it must have been improved and
it will have become better. The purpose of this paper is to explore
that assumption.</p>
<p><strong>History</strong><br> The methods of publishing government
information have not remained constant. In the 1940s and 1950s, there
were still a few documents recorded in manuscript. The significant
changes of that era were firstly, the growing involvement of government
in publishing the results of its R&amp;D work. Secondly, this in
particular, was a reason for the extended use of microformats at this
time – a trend that grew from nothing into a large output. Thirdly, an
expansion of government was seen and, in particular, the growth of the
number, nature and function of inter-governmental organizations (IGOs)
with the obvious grouping being that of the United Nations. The 1960s
was the period in which was seen the emergence of consensus government
and with it, the growing belief within government that it needed to
produce more information and more documents. At the same time, a
further expansion of government was witnessed with the accelerating
growth in the number of government agencies (or quangos) all of which
were producing information. The 1970s not only saw a period where
academic research into government intensified but also marked the start
of government beginning to use computers and computer-based formats for
information dissemination. Probably the most significant factor of the
decade, though, was the rapid development of new reprographic and
publishing technologies that enabled less formal and more immediate
dissemination of government information.</p>
<p> The 1980s was an era both of expansion and of contraction. There
was marked boom in informal government publication partly arising from
the developments in reprography and also from the new emergence of
desk-top publishing that was enabled by developing computerization. On
the other hand, this period saw the first steps in several countries
towards the privatization of government publishing. One of several such
moves in the direction of contraction was the development of the
’mosaic theory’; the idea was that a tiny snippet of information could
be used by an enemy to build a whole picture along with thousands of
other shards. This belief was behind moves to restrict the flow of
information to the public. The 1990s, of course, saw the birth and
development of the World Wide Web.</p>
<p><strong>Comparison</strong><br> The starting point for this
comparison of pre and post-web government publishing is a paper that
delivered by this author in March 1984:</p>
<p>	Allan, Alastair J. (1985):  ‘Access to official publications: the user’s view’ in <em>Whitehall and Westminster: proceedings of the Seminar on Official Publishing</em>;  London;  21 March 1984; ed. V.J.Nurcombe.<br>
London.  LA, RSIS;  pp 22-32.  (0946347050)</p>
<p> Two separate strands were identified at that time as being
symptomatic of the barriers that faced users when trying to exploit
official information. The first set was grouped as ‘Access’ and the
second was headed ‘Availability’.</p>
<ul>
<li>
Access		
<ul>
<li>Diverse publishers;</li>
<li>Barriers with jargon and conventions.</li>
<li>Info’ Rich : Info’ Poor</li>
</ul>
</li>
<li>
Availability
<ul>
<li>Bibliographical control.</li>
<li>Archiving.</li>
<li>Hostile formats.</li>
</ul>
</li>
</ul>
<p><strong>Access:  Diverse publishers</strong></p>
<ul>
<li>Rapidly growing number of publishers;</li>
<li>No main sales point;</li>
<li>Expanding desk-top publishing;</li>
<li>Privatization;</li>
<li>No High St. bookshop access.</li>
</ul>
<p>These features identified in 1984 still exist 20 years later. The
growth in numbers has been even greater with web publishing; the lack
of a main sales point is now different in that many government agencies
do not have a main web page through which all documents can be traced.
The last feature may seem too obvious but ‘pdf’ format documents can
not be bought through the booktrade – they can only be acquired through
the web.<br>
</p><hr>
<p>Look at this website:<br>
	<a href="http://www.lib.lsu.edu/gov/fedgov.html">http://www.lib.lsu.edu/gov/fedgov.html</a></p>
<p>This is a page from the LSU libraries: the Louisiana State
University. This page lists all the US Federal websites. Each one is a
publisher. There are over 1 100.</p>
<p>______________________________________________________________________________________<br>
Look at this website:<br>
	<a href="http://www.dfes.gov.uk/azindex/atoz/s.shtml">http://www.dfes.gov.uk/azindex/atoz/s.shtml</a></p>
<p>This is a page from the British Department for Education and Skills
and is part of the department’s alphabetical index of websites. Each
one of these contains government information on education. Some are
part of the main site but many others are part of the nest of sites run
by the DfES. There is no central reference point and navigation for <em>anyone</em>, not just the inexperienced, becomes very difficult.<br>
___________________________________________________________________________________</p>
<p><strong>Access:  Barriers from jargon &amp; conventions</strong></p>
<ul>
<li>Organization of legislative documents;</li>
<li>Lawyers’ citation systems.</li>
</ul>
<p>These two aspects of complication for users have now grown mainly because of the intrusion of inconsiderate web design.</p>
<ul>
<li>Organization of legislative documents;</li>
<li>Lawyers’ citation systems;</li>
<li>Meaningless URLs;</li>
<li>Listings using definite article “The …”;</li>
<li>Listings omitting the author names.</li>
</ul>
<p>The first two features are long-lasting difficulties that users have
always had in disentangling the shorthand used by lawyers and
legislators. These have not diminished over the years. New barriers
that have resulted from web design obviously include the long and
complicated URLs but less obviously the seeming inability of many
government websites to deal effectively with either personal or
corporate authors. Far more avoidable is the inability of web designers
either to produce an alphabetical order that is correct or the tendency
to list documents under the definite (‘the’) or indefinite (a’) article.</p>
<p>______________________________________________________________________________________<br>
Look at this website:<br>
        <a href="http://www.scotland.gov.uk/Publications/Search">http://www.scotland.gov.uk/Publications/Search</a><br>
This is the publications page from the Scottish Executive. Select the
topic “Arts, Heritage and Recreation” and then sort by A-Z and then
click “Show”. You will see that the first letter in the alphabet is not
“A” but the inverted comma (“). The second letter is A !! But notice
that the next six documents are all filed under the indefinite article,
which, as all librarians know, you never do.</p>
<p>______________________________________________________________________________________</p>
<p><strong>Access: Info’ Rich:  Info’ Poor</strong></p>
<ul>
<li>Commercial private sector interests given a higher priority than citizen access;</li>
<li>Privatization;</li>
<li>Access charges;</li>
<li>Technological illiteracy;</li>
<li>Information gap.</li>
</ul>
<p>The debate about the gap between the information rich and the
information poor raged widely in the 1980s and was, in Britain, fuelled
by increasing access charges to government information with the
argument being that the information was already the property of the
citizens of the country and should not be sold to them again. Twenty
years later, the web has blown away the debate about access charges
but, in truth, this is the only aspect that has changed. These are the
current issues:-</p>
<ul>
<li>Commercial private sector interests given a higher priority than citizen access;</li>
<li>Privatization.</li>
<li><strong>Few</strong> access charges;</li>
<li>Technological illiteracy;</li>
<li>Digital divide.</li>
</ul>
<p>Now, the ‘information gap’ is known as the ‘digital divide’ and is
possibly an even more critical issue than it was. Although twenty years
ago technological illiteracy was an acknowledged barrier, the scale of
this problem has grown massively. The need to be able to access and
navigate the web has become critical and the barrier of cost (to afford
the equipment and network charges) has become one that is becoming
extremely serious.</p>
<p><strong>Availability:  Bibliographical control</strong><br>
In the 1980s, it was commonly acknowledged that a substantial
proportion of government documents were ‘fugitive’ and had escaped
legal deposit and were missing from the national bibliography and the
national collection:</p>
<ul>
<li>No complete national listing;</li>
<li>Gaps in national library’s archive.</li>
</ul>
<p>Twenty years later, more problems have accumulated:</p>
<ul>
<li>No complete national listing;</li>
<li>Gaps in national library’s archive;</li>
<li>Partial paper holdings;</li>
<li>Deposited ‘pdf’</li>
</ul>
<p>The problems of an incomplete national bibliography are even more
extreme because the documents that are only published on the web in
‘pdf’ format escape listing and are not deposited with the national
libraries. There is, indeed, another problem in that some publishers
are sending ‘pdf’ documents to the national libraries but they are
unable to exploit these resources. A related issue is the fact that
some series are partly published in paper and partly digitized which
leads to confused and confusing holdings.</p>
<p><strong>Availability:  Hostile formats</strong><br>
If, in the 1980s, the profession believed that with illegible
photocopies, microforms and a very few sets of machine readable data
files that it had a full set of hostile formats, then it had no
conception of what was to come …. !</p>
<ul>
<li>Microformats;</li>
<li>MRDF;</li>
<li>Illegible photocopies</li>
</ul>
<p>Now there is a larger set:</p>
<ul>
<li>General website inaccessibility issues;</li>
<li>JAVAscript</li>
<li>‘pdf’;</li>
<li>Spreadsheets;</li>
<li>Search boxes.</li>
</ul>
<p>The general inaccessibility issues also include issues that are more
properly termed navigation difficulties and usability failures. All of
them together represent the problems that inexperienced users face when
looking for information on a strange and complex government website.
The JAVA issues are part of this set of difficulties as are the block
to fluid navigation posed by ‘pdf’ files. Spreadsheets and search boxes
are web tools that experienced users take in their stride but both can
make access to information troublesome.</p>
<p>______________________________________________________________________________________<br>
Look at this website:<br>
	<a href="http://www.swansea.gov.uk/index.cfm?articleid=13">http://www.swansea.gov.uk/index.cfm?articleid=13</a></p>
<p>This is the on-line services page from Swansea City Council. There
are 17 topics listed under ‘Apply’ and 15 of them are in ‘pdf’ format.
This is definite barrier to the users and certainly a block to fluid
navigation. Additionally, they are all dead ends because ‘pdf’ files
never have hyperlinks.<br>
___________________________________________________________________________________</p>
<p><strong>Availability:  Archives</strong><br>
The need to maintain full and accessible archives is becoming even more
of a problem than it was twenty years ago. Once the archiving function
was taken care of by the large national and university libraries but
now the individual sites have to ensure that the archives are
maintained and, frankly, many sites lack both the ability and ambition
to do so. The list below represents the issues for 2005 and the only
recent addition is the unpredictability of technological support. </p>
<ul>
<li>No reliable archives;</li>
<li>Irregular deposit;</li>
<li>Broken holdings;</li>
<li>Variety of solutions;</li>
<li>Little motivation to improve;</li>
<li>Unpredictable technological support.</li>
</ul>
<p>In many ways this is the most frustrating of all the problems that
government information is throwing up because the masses of the
information make it so difficult for the researcher or citizen to be
tuned to current publishing. The fact that expensively produced and
important information can be simply etherized because no-one cares
sufficiently to retain it is a damning statement on government’s
attitude to citizen empowerment; government accountability and research.</p>
<p>______________________________________________________________________________________<br>
Look at this website:<br>
	<a href="http://www.official-documents.co.uk/menu/com2005.htm">http://www.official-documents.co.uk/menu/com2005.htm</a></p>
<p>This is the “Official Documents” page for the UK parliament that is
run by TSO, the government publisher. This page is a list of all the
House of Commons papers that have been digitized. Wrong !! On this
page, there are only 13 paper linked and over 700 were published.<br>
If you go to:<br>
        <a href="http://www.publications.parliament.uk/pa/cm/cmselect.htm">http://www.publications.parliament.uk/pa/cm/cmselect.htm</a></p>
<p>you will find dozens, if not hundreds of other papers not listed on the “Official Documents” archive page.<br>
___________________________________________________________________________________</p>
<p><strong>Summary</strong><br>
In the 1980s, concerns were regularly expressed about the fugitive
nature of government information and the difficulties that were faced
by users when they needed to find and use it.</p>
<ul>
<li>Poor access;</li>
<li>Difficult availability;</li>
<li>Confusing systems;</li>
<li>Complex organization;</li>
<li>Fugitive publications.</li>
</ul>
<p>All these issues mainly relate to paper publications and occurred
because documents could not be traced, purchased or found in libraries.
In 2005, we have a whole host of new issues that relate to web-based
digitized publication and the implication is that ‘government’ (in
whatever form and in whatever country) doesn’t care sufficiently to put
its house in order:</p>
<ul>
<li>Info’ overload;</li>
<li>Publication dumps;</li>
<li>Confusing navigation;</li>
<li>Illogical organization;</li>
<li>Invisible sites.</li>
</ul>
<p>Whilst these points are a summary of the arguments above, in some
ways they are arguments in themselves. Information overload represents
the mass of government information that is largely uncontrolled and
archived and for which there is often no adequate pathway. The
publication dumps are those sites with masses of unrelated documents
that are unindexed and for which there are no easy access routes but
which are added to websites in a thoughtless way. The confusing
navigation is the way in which sites are composed for those inside
government and their web designers and the illogical organization is a
feature of sites being built to reflect governmental organization
rather than user need. The invisible sites, rather like the publication
dumps, are those websites that are full but which cannot be traced
through normal search engines because no care has been taken to ensure
that they can be found.</p>
<p><strong>Summary – the user’s predicament.</strong><br>
Technology should make things more simple. The user has four needs and
regularly these are thwarted by over complex sites or those constructed
for government rather than public usage:-</p>
<ul>
<li><em>Where can I find it ?</em></li>
<li><em>How do I know it’s what I want ?</em></li>
<li><em>Is it the latest version?</em></li>
<li><em>Will I be able to find it again?</em></li>
</ul>
<p><strong>Re-intermediation.</strong><br>
The answer is re-intermediation. That is the process whereby the
librarian moves in-between their users and the websites and guides them
to the information they need.<br>
But part of the ”same old problem” is that, in the UK, librarians often
do not understand government information and find it too much of a
challenge to navigate through it for their users.<br>
______________________________________________________________________________________</p>
<p><strong>e-Government Information:<br>
the same old problem    —–(newly digitized !)</strong></p>
<p>prepared by</p>
<p>Alastair Allan<br>
University of Sheffield Library / Dept. of Information Studies.<br>
Sheffield.  S10 2TN.  Great Britain</p>
<p><a href="mailto:a.allan@sheffield.ac.uk">a.allan@sheffield.ac.uk</a></p>
<p>June 2005.</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">6 Comments »</a></p> 

			</div>
	
						
			<div class="post">
				<h2 id="post-22"><a href="blog.html">Invited paper: The Internet and democratisation of access to data - Robin Rice</a></h2>
				<small>June 21st, 2005 <!-- by rrice --></small>
				
				<div class="entry">
					<p>In
Marge Piercy’s feminist utopian novel, Woman on the Edge of Time, the
heroine from the future–Connie, has a wristwatch which she can speak
questions to and receive back facts. Written in 1976 before wap phones
or other ‘wearable chip’ technology was invented, or even the PC, this
and other prescient aspects of the book seemed like science fiction
indeed.</p>
<p><strong>Now the use of the Internet for fact-checking has become common-place, a modern day luxury.</strong>
Information has gone from being a scarce commodity leading to ‘power’
to something we are overloaded by, even need to defend ourselves
against. Tools such as Google help us sift the false information from
the true through a democratic system of hyper-link voting (the web page
which matches the keywords entered AND has the most links pointing to
it wins). Wikipedia, a collective reference work to which anyone is
entitled to contribute, though there are a core of moderators to keep
its excesses in control, may – like the fictional <em>Hitchhiker’s Guide to the Galaxy</em>
within Douglas Adam’s 1979 tale of the same name—surpass the dominant
publisher’s authoritative but dry and dusty encyclopedia, just as
weblogs may replace textbooks as the learning objects from which
students learn.<br>
<strong><br>
The Internet has been used for sharing of social science data since its
inception, or at least from the time it was available to academics.</strong>
Even before the days of the Web, if a file could be transferred across
a network it was a lot better than posting heavy half-inch tapes in
boxes through ’snailmail’. Before the Web there was still email, and
subject specific newsgroups, usually accessed via Telnet over
command-driven monochrome terminals. And FTP (file transfer protocol)
servers, with Archie search engines (searching on filenames and paths
only). Gopher seemed like the answer to all our problems with its vast
hierarchical menus getting us beyond the limitations of filenames. It
was no wonder at all that no one but geeks, wonks, and a few scholars
and librarians bothered to enter cyber-space. But it was the World Wide
Web, invented only in 1993 and slowly, painstakingly, populated with
useful pages of text, pictures, audio and video, that became the
‘killer app’ that would democratise access to information on the
Internet most radically.</p>
<p>It seems that the social sciences have been simply evolving steadily
since the advent of computers and networking, compared to other
disciplines which have been revolutionised (think of biology—human
genetics, particle physics, or astronomy). Even our largest
quantitative datasets remain small compared to these other fields, if
more complex in structure and meaning. <strong>Have social science methods changed much, with the exponential increase in computing power?</strong>
Data collection has arguably been changed more by computers than
analysis itself, which has been dominated for decades by a few
well-known statistical, and qualitative, analysis packages. Coming to
grips with the complexities of secondary datasets—how they were
collected, whether a particular variable is a fair proxy for an
abstract concept of interest (such as poverty or privilege, for
example), whether weights can overcome problems of non-response and
whether other errors or biases in the data can be interpreted
correctly—these remain the difficult part of secondary analysis,
compared to the computation itself. Likewise with qualitative
analysis—most researchers would rather analyse data they collected
themselves than traverse the minefield of interpretation involved in
using secondary datasets such as interviews or transcripts collected by
others. So the problem of access for research data is more than
discovery; the user requires tools to make the data usable, and fairly
intimate knowledge of how the dataset was collected, variables derived,
etc. There is also a tension between protecting the subjects’
confidentiality, and releasing as much demographic background on the
respondents as possible to maximise the re-usability of the data.</p>
<p><strong>Have the national services such as the UK Data Archive and SOSIG largely solved the access problem?</strong>
Certainly they have proven to be part of the solution, through
value-added metadata and preservation work, and narrowing down the
extent of Internet searching to relevant, scholarly materials. We have
benefited from their long-term presence, along with the Census
Programme and newer services from academic data providers such as MIMAS
and EDINA. Online access tools such as Nesstar and Neighbourhood
Statistics may lead the way in exposing students to rich online data
sources and enriching researchers’ ability to quickly conduct
exploratory data analysis and data mining of large-scale social
datasets.</p>
<p>So, what new areas on the horizon will herald fundamental changes affecting the practice of social science researchers?</p>
<p><strong>The world of open access publishing and digital repositories
seems to be the most important new trend in democratising access to
data.</strong> A number of international initiatives, from the Berlin
Declaration on Open Access to Knowledge in the Sciences and Humanities
to the OECD Declaration on Access to Research Data from Public Funding,
have put the spotlight on open access and its importance for the future
of scholarship, as well as access to scholarship by developing
countries. (See <a href="http://www.zim.mpg.de/openaccess-berlin/berlindeclaration.html">http://www.zim.mpg.de/openaccess-berlin/berlindeclaration.html</a> and <a href="http://www.oecd.org/document/0,2340,en_2649_34487_25998799_1_1_1_1,00.html">http://www.oecd.org/document/0,2340,en_2649_34487_25998799_1_1_1_1,00.html</a> .) </p>
<p><strong>Is there a UK broad-based commitment to open access publishing? </strong>The
Wellcome Trust has most recently made a commitment to require
researchers funded by them to deposit their articles in an open access
repository (<a href="http://www.wellcome.ac.uk/doc_WTX025191.html">http://www.wellcome.ac.uk/doc_WTX025191.html</a>).
On the other hand, the government’s response to the UK Science and
Technology Select Committee report last year which supported the
establishment of institutional repositories and the value of a
comprehensive network of such repositories, failed to back the Report’s
recommendations for funding to support the national collaborative work
that will be required and of mandating that research material should be
mounted within the repositories. (See <a href="http://www.publications.parliament.uk/pa/cm200304/cmselect/cmsctech/399/399.pdf">http://www.publications.parliament.uk/pa/cm200304/cmselect/cmsctech/399/399.pdf</a> or <a href="http://www.publications.parliament.uk/pa/cm200304/cmselect/cmsctech/399/39902.htm">http://www.publications.parliament.uk/pa/cm200304/cmselect/cmsctech/399/39902.htm</a>) </p>
<p>Recent funding by JISC toward the development of institutional
repositories does reflect some level of national commitment to open
access and institutional repositories. (<a href="http://www.jisc.ac.uk/index.cfm?name=repos_announcement">http://www.jisc.ac.uk/index.cfm?name=repos_announcement</a>)
Although it is early days, this could be the beginning of a thousand
flowers blooming, and a sea-change in the work of social science
researchers, librarians and archivists, as universities rise to the
challenge of ‘curating’ their own scholarly assets, including perhaps,
the actual or derived datasets upon which published research papers are
based. <strong>Is there any chance of this becoming a widespread trend
with only a smattering of project-based funding? Is it even desirable,
compared to providing additional funds for centralised, domain-specific
trusted repositories such as the UK Data Archive?</strong></p>
<p>Please feel free to share your own ideas and comments.</p>
<p>___________________________________________________</p>
<p>Robin Rice (<a href="mailto:R.Rice@ed.ac.uk">R.Rice@ed.ac.uk</a>) is Data Librarian to the University of<br>
Edinburgh. She has a Masters degree in Library and Information Studies
from the University of Wisconsin-Madison, where she worked as a data
librarian through the 1990’s. She was recently seconded to be Phase One
Project Coordinator to help set up the Digital Curation Centre (<a href="http://www.dcc.ac.uk/">www.dcc.ac.uk</a>) based at Edinburgh and three other institutions.</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">4 Comments »</a></p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-27"><a href="blog.html">Invited paper: How has the internet changed the way we access data? - Melanie Wright</a></h2>
				<small>June 21st, 2005 <!-- by mwright --></small>
				
				<div class="entry">
					<p>How
has the internet changed the way we access data? Well, in every way
imaginable is perhaps the most complete, if flippant answer. I only
need look back on my own decade at the <a href="http://www.data-archive.ac.uk"> UK Data Archive</a> to begin to flesh this out.  </p>
<p>When I arrived at the UKDA in 1996, we were re-launching our
webpages after having had a web presence for 2 years to include
downloadable data access application forms (which still had to be
filled out and posted back to us offline). Our immensely powerful but
unix-command-line-based catalogue, BIRON, was in the process of being
ported to a web interface. We had been disseminating data on CD-ROMs
for a little while, but most users still wanted DAT tapes, cartridges,
or magnetic reels. (We had to ask users whether their computers could
read “high density” floppy disks.) We had just begun allowing
“guestftp” where data users could come to an ftp site and with a
special username and password, download the files which had been placed
there through a unix ftp command line interface. Users could email us
for assistance, but an equal number tended to pick up the phone, and a
number even still wrote us snailmail. Datasets were usually delivered
within a month of receiving a request, but large orders might well take
longer. And we had just received some funding from the EU to
investigate, with some of our sister archives in Europe, the
possibility of using the internet for processing and disseminating data
(the first Nesstar pilot project). </p>
<p>Look at the UKDA today - as the managing service provider of the <a href="http://www.esds.ac.uk/">Economic and Social Data Service</a>,
users register, order, and receive their data almost entirely
downloaded via the internet (users can still order CD-ROMs or DVDs, at
a price). Users can browse, analyse, and visualise data online via a
number of different interfaces (<a href="http://nesstar.esds.ac.uk/webview/index.jsp">Nesstar</a>, <a href="http://www.esds.ac.uk/international/support/software.asp">Beyond 20/20</a>, <a href="http://www.esds.ac.uk/International/access/commonGIS.asp">Common GIS</a>).
Most users receive their data instantaneously upon ordering; for those
back-catalogue datasets requiring publishing they may wait up to 3 or 4
days. There has been an explosion of users and usage - from about 3,500
datasets delivered in 1996 to around 20,000 in the last year. Not just
data, but a wealth of supporting materials can be downloaded in a
click, and integrated online help desks ensure queries are answered as
quickly and thoroughly as possible. <a href="http://www.esds.ac.uk/aandp/access/login.asp">One Stop Shop registration</a>
means there is a single port of call for accessing government social
surveys, academic-created longitudinal data, modern and historical
censuses, international macroeconomic time series data, digitised
historical data, and data from other archives internationally.</p>
<p>Calling it a revolution is cliche, but there is hardly a better word
for it. And as in radical political change, alongside structural,
organisational changes come attitudinal changes. User expectations are
light years from where they were in 1996. In data services, there are
in my mind, three major influences which have caused a paradigm shift
in user expectations and therefore in the way data services do their
business. These three influences neatly fall into the three fundamental
services provided by data centres such as the UKDA: finding data,
accessing data, and using data. And they are: Google, Amazon, and GUI
menu-driven analysis software (SPSS for Windows).</p>
<p>Google has completely changed the way that people expect to locate
resources on the internet. Whereas the old BIRON catalogue focused on
precision and flexibility, being able to very closely define and limit
searches to produce only completely relevant results, Google has
created a generation of users who are used to a simple interface
returning a mountain of chaff to be picked through for kernels of
worth. Our early experience with the move of BIRON to an online
interface was that users simply didn’t use the advanced search
features, and indeed then, as now, most users search on specific
dataset titles, using the catalogue purely as a means for getting
something they already know they want, rather than as a true resource
discovery tool. Rather than using the catalogue search engine to
identify new resources which might assist them, users will more likely
use the “subject browsing” approach, which has been strongly influenced
by my second identified trend setter, Amazon.</p>
<p>There is no doubt that Amazon has set the standard for e-commerce.
The processes for locating and acquiring books has become a direct
metaphor for all online shopping, and data services are not exempt from
this. The expectation of ease and speed of the ordering process, as
well as the willingness of users to entrust services with intimate
details (like credit card numbers) has been strongly influenced by the
Amazon model. Even now, some of our future plans for development of the
service are following Amazon’s lead, employing user profiling to make
data recommendations, for example (<i>users who liked the <a href="http://www.esds.ac.uk/government/bsa/">British Social Attitudes</a> study also enjoyed the <a href="http://www.data-archive.ac.uk/findingData/ebsTitles.asp">Eurobarometers</a></i>).
Amazon has also influenced user perceptions of how quickly the process
should operate and how integrated finding and ordering should be.</p>
<p>The final influence is on user perceptions of how straightforward
and easy data should be to use. Back in the days of mag tapes, only a
few data specialists really had the skills to manage and analyse the
largescale surveys. Users had to know how to read data into statistical
software packages and how to write command-line syntax to analyse it.
Now point-and-click is the norm, and users expect to be able to load
up, analyse, and visualise data without having any clear vision or
understanding of the underlying file structure at all. Taking this to
its logical conclusion is the development of online analysis services
such as Nesstar and Beyond 20/20 where users never need to be in
possession of the underlying data at all, but use the online interface
to analyse and visualise data, downloading tabulations or graphs and
charts rather than underlying data. </p>
<p>What does the future hold for data services? The real challenges in
many ways are in my view caused by the major successes of the internet.
Easy to access, easy to use, voluminous data about individual people
only heightens the risk that linking these data together will enable
individual confidentiality to be breached. The analysis possibilities
afforded by Grid technologies explodes this risk (and this potential) a
thousandfold. Democritisation of access means that acadaemia will need
to re-establish its claim to special trustworthy status in relation to
potentially sensitive or disclosive data. Allowing access to
potentially disclosive data under special license is one way forward
which we are strongly pursuing.</p>
<p>As users become less and less technically specialist, and the
interfaces become easier and easier to use, the risk of incorrect or
methodologically flawed analyses increases dramatically. To counteract
this, more and more work will need to go into training and support of
the use of data. The creation of teaching datasets and online tutorials
at many different levels of sophistication will be a growth area. With
usage exploding and more and more “naive” users, support demands will
grow, and we must become inventive in discovering ways to harness user
expertise for other users. Capturing more information about
publications, websites, and grey literature outputs arising from data
analysis is one way; enabling users to find other users who share their
research interests is another, and ESDS is actively pursuing both of
these. </p>
<p>Some might view these three influences and say, this is how the
internet has destroyed data services — dumbing down our search tools,
pandering to the lowest-common-denominator naive user, enabling far too
many people to conduct far too many risky and suspect analyses on data
they aren’t trained to understand, and increasing the risk of
confidentiality breaks and disclosure logarithmically. Others might
say, the internet has been the greatest boon imaginable, allowing more
socially relevant data and information be disseminated to more people,
enabling more 5-star research to be conducted, upon which more
evidence-based policy is evolved, allowing for a more enlightened and
better world. </p>
<p>What’s your view?
</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">2 Comments »</a></p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-19"><a href="blog.html">Invited paper: Social science research and the Internet: intriguing tangent, or core business? - Christine Hine</a></h2>
				<small>June 21st, 2005 <!-- by chine --></small>
				
				<div class="entry">
					<p>In
this piece I describe the route that brought me to use the Internet in
my research, in order to raise some questions about the relationship
between Internet research and the social science endeavour.
Specifically, I want to ask whether the Internet might mean more to
social science than just a niche area inhabited by trendy and/or lazy
researchers. Is the Internet, instead, something that social
researchers across the board need to take seriously? How might use of
the Internet become a part of the standard research tool kit?</p>
<p>My own introduction to the Internet as a research field happened in
classic ethnographic style, when the people that I was studying went
online and I followed them. I was studying genetics researchers in the
mid-1990s, and increasingly I found that the people I met in the
laboratory were communicating by email, sharing data online, and
getting information and advice from discussion forums. Wanting to know
more about what was happening on the Internet, and wanting to know what
it meant for the people involved, I followed them online. I found
discussion groups forming on the Internet around diverse aspects of
scientific practice. Like my original field site in the laboratory,
these online settings also seemed to have a distinctive culture that
seemed ripe for participant observation. At the same time, I was aware
that the scientists I met in the laboratory had quite different
expectations about the Internet: some were net connoisseurs who
routinely turned to online groups for their work, while other were
suspicious about its abilities to provide reliable advice, or simply
lacked the background to make sense of its possibilities. Later on I
came to think of this as the Internet as culture/Internet as cultural
artefact duality: whilst the Internet had become a space for cultural
formations to emerge, the experience and use of that space was very
much shaped by people’s cultural expectations about the Internet. </p>
<p>My first excursions onto the Internet with scientists were followed
by many more, as I found that I could do new forms of research (and I
chose still to call them ethnography), no longer tied to the laboratory
where I started. I could explore the way that researchers were finding
new ways of communicating and doing science across wide geographical
distances. That initial interest in the Internet as a space for rich
and diverse social interactions has stayed with me across several
shifts of subject matter, and I have increasingly relied on multi-sited
approaches to ethnography that allow me to combine online and offline
and explore the connections between them. </p>
<p>At the stage that I started doing Internet research the field was in
an infancy characterised by immense enthusiasm for the radical
potential of the technology to reshape the very fabric of social life.
There was considerable excitement about the possibilities for new forms
of social interaction and fluid notions of identity that the Internet
seemed to offer. Latterly, the emphasis on the Internet as something
radically new has faded somewhat, and the focus has turned to the
embedding of Internet in everyday life. Just as with other media, we
can look at the ways in which the Internet is domesticated, becoming a
meaningful aspect of lives lived in complex domains comprised of
diverse forms of communication. The Internet has become an important
space to study social formations and identity, but we don’t expect the
medium to lead automatically to particular outcomes. This
transformation in thinking about the Internet doesn’t, however, seem to
have had as much impact as I would expect upon the mainstream of social
research.</p>
<p>Just as research into the mass media is so often marginalised as a
separate specialism of the discipline, so too does Internet research
risk being framed as an intriguing tangent that has little to say to
the rest of the discipline. I think this sells short the potential of
the Internet as a research medium and as a component of the social
fabric. I would hypothesise that whatever substantive interest you
might have as a social researcher, you will be able to find a place on
the Internet where it is being discussed. Whatever your field of
research, I would guess that some of the people you may be interviewing
face-to-face, observing or conducting surveys with will be taking part
in some form of online interaction. The Internet, then, provides at the
very least an opportunity for social research. Pushing the point a
little further, though, we might ask whether our accounts of social
life can continue to be credible if they exclude the Internet. It seems
to me that the mainstream needs to take on board the significance of
the Internet and other kinds of mediated communication as important
facets of everyday life. Social research needs to take account of the
fact that people conduct their social existence through a wide range of
communication media, and that we can’t any longer assume that
face-to-face research gives us a truer picture than mediated research
methods and field sites.</p>
<p>Coming back to the question of Internet as culture/Internet as
cultural artefact, one problem with using the Internet in social
research is that research questions can often not be addressed solely
with online observations. Answering questions about what Internet use
means in the context of everyday life often means we need to move the
research offline. Analysing web sites is a fascinating route into
exploring the cultural constructions of an issue, but often we will
want to find out more about the sites of production of those web sites.
Sometimes an online interview, conducted via email, will suffice to
give a picture of the facet of life that we are interested in, but
often face-to-face interviews will serve to triangulate the picture
that the online interviews give. The curiosity of social researchers
should almost automatically take them across the online/offline
boundary, since the things we want to know do not confine themselves
easily to particular communication media. In the process we can learn
something about research methods too, not only reflecting on whether
the online experience was adequate to count as an interview, but also
examining our assumptions about face to face encounters.</p>
<p>I have tried to argue that the Internet provides an opportunity for
new approaches to social research and for a social research that
respects the role of mediated communications in everyday life. It also,
I suggest, provides an occasion for methodological reflection. Some
initial questions for discussion are:</p>
<ul>
<li>How far are Internet research methods accepted in mainstream social research?</li>
<li>What situations remain inaccessible to online research?</li>
<li>What new situations could online methods make accessible?</li>
<li>Is face-to-face research still the gold standard, and why?</li>
<li>Can online interviews live up to the face-to-face model?</li>
</ul>
<p>__________________________________________________________________</p>
<p>Christine Hine is Senior Lecturer in the Department of Sociology at
the University of Surrey. Her main research centres on the sociology of
science and technology, including ethnographic studies of scientific
culture, information technology and the Internet. Her published work on
research methods and the Internet includes Virtual Ethnography (Sage,
2000) and the edited collection Virtual Methods (Berg, 2005). She is
currently exploring the sociology of cyberscience, as recipient of an
ESRC research fellowship. A book on the deployment of information and
communications technologies in biological systematics, and an edited
collection on the social shaping of new infrastructures for knowledge
production are in preparation in connection with that project.
Christine has recently been elected President of the European
Association for the Study of Science and Technology
(http://www.easst.net).</p>
<p>Christine Hine<br>
Department of Sociology<br>
University of Surrey<br>
Guildford, Surrey, GU2 7XH, UK<br>
<a href="http://www.soc.surrey.ac.uk/christine_hine.htm">http://www.soc.surrey.ac.uk/christine_hine.htm</a></p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">12 Comments »</a></p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-18"><a href="blog.html">Invited paper: The Internet: a World Wide Social Science Laboratory? - Jacqui Taylor</a></h2>
				<small>June 21st, 2005 <!-- by jtaylor --></small>
				
				<div class="entry">
					<p>Internet-mediated
research (IMR) is the term given to cover experiments conducted via the
Internet, rather than in the traditional laboratory or in the field
(e.g. home, school or workplace). It is different from the research
involved when conducting a review of the literature, as IMR involves
the primary collection of data from participants. IMR covers a variety
of research techniques including, for example, online surveys, online
discussion room transcript analysis and participants responding to
experimental stimuli presented via web-pages.</p>
<p><strong>Advantages and disadvantages of IMR, compared to traditional research methods</strong></p>
<p>Some of the problems with traditional social science research (i.e. conducted face-to-face) include:</p>
<ul>
<li>the sample size is often very small due to practical reasons relating to time, money and laboratory space</li>
<li>samples may not be representative of the general population, e.g.
participants tend to be University students, young, mobile and of the
local nationality</li>
<li>research is limited to laboratory and researcher and participant
time, which may lead to ecologically invalid situations in the
laboratory (e.g. research taking place 9-5pm Monday to Friday only) or
may preclude some research from happening (e.g. weekend research is
rare!)</li>
<li>experimenter bias can be high due to the experimenter being physically present and potentially influential</li>
<li>it is hard to know whether the results are specific for the culture where the experiment was conducted</li>
</ul>
<p>IMR has many advantages over traditional research and is able to
overcome or alleviate some of the problems highlighted above, some of
the advantages of IMR include:</p>
<ul>
<li>large samples are easy to gather as the online laboratory can potentially be open 24/7 </li>
<li>a very high response rate from a diverse sample of people</li>
<li>researchers can gain access to special populations of people (e.g.
those unable to participate in face-to-face research due to mobility or
health problems)</li>
<li>low cost (no printing or data input or lab space)</li>
<li>high speed - responses back in hours/days not weeks/months </li>
<li>the sample can potentially be balanced cross-culturally</li>
</ul>
<p>However, critics of IMR argue that there are factors which are
problematic for internet-mediated social science research, some of
these include:</p>
<ul>
<li>difficulty in controlling the study environment - although most
types of research translate well to the Internet, some may not, e.g.
people on the Internet use different hardware and software with
variable connection speeds so there is no way to ensure that all
participants receive exactly the same stimuli </li>
<li>participants are largely unmonitored, so there may be dishonesty
regarding age or gender, participants may receive help from others,
they may cheat or they may respond more than once</li>
<li>participants are self-selected (therefore they may not be random or representative of the general population)</li>
</ul>
<p>However, there are solutions to these factors, respectively:</p>
<ul>
<li>research requiring highly accurate timings may be better suited to non-networked PCs</li>
<li>multiple participation can be identified by analysing the IP address </li>
<li>there are ways to invite participants of the required age or gender
make up and give them authorised access to online research sites</li>
<li>large samples allow enough statistical power to wipe out anomalous data</li>
</ul>
<p><strong>Past, present and future of IMR</strong></p>
<p>The remainder of this discussion will focus on the past, present and
future of conducting social science research via the Internet. I have
dated the past as from the mid-late 1980s when I first conducted online
research and when the Internet started to be used regularly by social
scientists. Twenty years on from here, I will consider the current use
of IMR, specifically looking at some areas of IMR in my own discipline
of Psychology. I would like to address the future part of the
discussion by asking you some questions!</p>
<p><em>The past</em></p>
<p>In 1989, I began my PhD research on ‘A Social Psychological Analysis
of Online Communication’ as I was interested in how the Internet was
changing the content of communication and the way people viewed
themselves and other group members when communicating online. In this
way then, I was investigating the impact of the Internet itself and
this tended to be the focus of the early IMR. This early research
environment was quite different from current environments, as
participants tended to be novice computer users, the technology was
slow and often unreliable and the software difficult to use.</p>
<p><em>Current use of IMR</em></p>
<p>Much of the current IMR replicates traditional experiments, to avoid
some of the problems experienced when experiments are conducted
face-to-face in laboratories or in real world environments. IMR
continues to study the way the Internet affects our behaviour (e.g. are
individuals becoming more isolated? is the concept of community
changing?). However, now participants are experienced computer users,
the Internet is more pervasive in everyday life and accessibility is
ever-increasing. The number of studies on the Internet is more than
doubling each year, for example, the APS now lists more than 100 links
to online psychology experiments. The breadth of topics and methods in
IMR is ever-increasing and now includes areas from all areas of
psychology, for example:</p>
<ul>
<li>individual differences, e.g. online personality assessment</li>
<li>communication and psycholinguistic research, e.g. detailed analysis of conversations</li>
<li>educational psychology, e.g. pedagogical studies of e-learning</li>
<li>counselling and clinical psychology, e.g. online therapy and support groups</li>
<li>psychophysics, e.g. studies of perception</li>
<li>social psychology, e.g. experiments on group decision making</li>
<li>cognitive psychology, e.g. knowledge acquisition with online vs traditional text</li>
</ul>
<p><em>The future for IMR?</em></p>
<p>As technology progresses the design of social science research is
likely to become more creative and the data analysis is likely to get
quicker and easier. There is also great potential for cross-cultural
research to validate many social scientific findings, so far obtained
from one culture. Some issues for discussion will be proposed here. </p>
<ul>
<li>with the cost of webcams falling rapidly and their availability and
use increasing, many ethical questions need to be asked of social
scientists, for example ‘Can we use video-cams to observe people in
their group settings or their natural environments?’. </li>
<li>similarly, it is becoming easier to record interaction over the
Internet. Studies of user behaviour on the Internet may involve logging
users’ conversations, should users be told that this is happening?
Should you be able to keep a copy of users’ conversations with others
from a chat room and analyse the transcripts?</li>
<li>it has been proposed that IMR can be used in lieu of traditional
studies in undergraduate curricula, thus enabling Universities to
eliminate many of the expenses associated with providing the lab space
and equipment needed to conduct ‘traditional’ experiments, is this a
good idea? Will students still learn the same research skills?</li>
<li>are the characteristics of the online participant population similar or different from the face-to-face population?</li>
</ul>
<p>What are your views? Have a go (see listing of websites at the end)
– be a participant in internet-mediated social science research! Then
send me your comments…</p>
<p><strong>Conclusion</strong></p>
<p>IMR can potentially be used in nearly all social science research
areas. Some of the possible disadvantages of this new method can be
avoided by taking appropriate measures. The advantages of having a
large world-wide pool of participants at the click of a mouse are very
attractive. As Reips (2001) concluded, </p>
<p>“For the first time in the history of social science it seems
possible to overcome some of the essential objections against the
traditional experiment. Data from the emerging field of Web
Experimentation might help us to be able to generalize much better than
ever across demographic, cultural and numerical boundaries - and this
while saving money.”<br>
</p><hr>
<p><strong>Have a go – be a participant in internet-mediated social science research!</strong></p>
<p>Here are 3 websites which will give you an idea of the types of study now taking place: <br>
(1) <a href="http://www.psych.uni.edu/psychexperiments/Default.htm">http://www.psych.uni.edu/psychexperiments/Default.htm</a><br>
Kenneth McGraw at the University of Mississippi runs PsychExperiments Website<br>
PsychExperiments is an on-line cognitive and social psychology laboratory site. <br>
(2) <a href="http://www.psychologie.unizh.ch/genpsy/Ulf/Lab/WebExpPsyLab.html">http://www.psychologie.unizh.ch/genpsy/Ulf/Lab/WebExpPsyLab.html</a><br>
Ulf-Dietrich Reips at the University of Zürich, founded the Web
Experimental Psychology Lab in 1995. Since then many studies have been
conducted and these are all available to view and you can still
participate in some of these. <br>
(3) <a href="http://psych.hanover.edu/Research/exponnet.html">http://psych.hanover.edu/Research/exponnet.html</a><br>
A listing sponsored by the APA from Krantz which provides links to
experiments on the internet that are psychologically related. This site
is really well organized, expts are listed by both by general topic
area and also chronologically ordered. </p>
<p>_____________________________________________________________</p>
<p>Dr Jacqui Taylor (University Lecturer, Researcher and Chartered Psychologist)</p>
<p>Jacqui Taylor’s research area is human computer interaction (HCI)
and in particular computer mediated communication. She has been
conducting research in this area and lecturing on the Applied
Psychology &amp; Computing degree at Bournemouth University for 13
years.</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">3 Comments »</a></p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-28"><a href="blog.html">The development of on-line learning and teaching resources: The E-Learning Global Welfare project</a></h2>
				<small>June 20th, 2005 <!-- by icsp2005 --></small>
				
				<div class="entry">
					<p>Introduction and background</p>
<p>E-learning Global Welfare is a teaching and learning project
developed by the convenors of the International and Comparative Social
Policy Group of the UK Social Policy Association (ICSP
http://www.globalwelfare.net). The idea for the project emerged as a
result of disciplinary developments, the impact of general advances in
the availability of web-accessed welfare-related material on student
learning, and discussions held at the inaugural meeting of the ICSP in
July 2003. The project is funded for one year by C-SAP with support
from SWAPltsn and the Universities of Sheffield and Queens, Belfast.</p>
<p>The academic study of global welfare is of multi-disciplinary
concern and is increasingly important as a curriculum area in a number
of disciplines where academic and practice-related enquiry has moved
beyond the national horizon. This shift from a domestic focus has
occurred for example in fields such as Social Policy, Social Work and
Management Studies where teaching now refers more widely to the
international and global context. In the field of global welfare
studies, web-based information such as that made available by
governmental and non-governmental organisations has significantly
improved potential accessibility to policy documents and welfare
indicators by students and researchers. However, the vast range of
information and the number of sites with varying quality of content and
ease of searchability, can act as a real barrier to the effective use
of e-resources. These disciplinary developments and issues signaled the
need for a pedagogic resource which assisted in identifying, locating,
navigating and making effective use of information available on the web.</p>
<p>Teaching and Learning Activities</p>
<p>Through the E-Learning Global Welfare project, the ICSP group aim to
facilitate and enhance teaching and learning in the area of global
welfare studies through the development of the ICSP website into a
unique on-line pedagogic and research resource for students and
teachers to facilitate the identification, navigation and practical use
of a range of sources and types of information in global welfare
studies. </p>
<p>Specific activities include:</p>
<p>1) The development of subject related web links and networks (http://www.globalwelfare.net/links.htm).</p>
<p>2) The provision of links to a range of educational materials and
resources for use in teaching and in the study of global welfare</p>
<p>3) The design and uploading of a range of on-line tests, activities
and policy exercises
(http://www.globalwelfare.net/teachingentrancepage.html) </p>
<p>4) The manipulation of relevant international datasets to render them accessible and useful for lecturers and students.</p>
<p>This element is intended to capitalize on the resources offered by
the Economic and Social Data Service (ESDS) International. We have
negotiated the linking of our website to theirs and following recent
on-line discussions (June 2005), we have established a dialogue around
further collaboration. </p>
<p>5) Linking and collaborating with other projects.</p>
<p>The E-learning Global Welfare project is also linked to a
collaborative E-Library project http://www.globalwelfarelibrary.org
with GASPP (Globalism and Social Policy Programme http://www.gaspp.org)
and Dr. Theo Papadopoulos (Social Policy Virtual Library, University of
Bath http://www.social-policy.org). All partners are active
participants in the creation and development of this educational tool,
contributing respectively to three areas of development:</p>
<p>1) specific on-line learning resources for teachers and students<br>
2) an international e-library<br>
3) an international policy digest</p>
<p>Future impact of on-line resources </p>
<p>We anticipate that the resources produced through this project will
impact positively on the work of teachers, students and researchers who
choose to access our website. The materials and resources developed
through this project will perform an important function in expanding
knowledge and understanding of global welfare studies. However, one of
the key questions generated by ICSP experiences of the production of
on-line teaching and learning resources, is how and to what extent is
it possible to increase incentives to facilitate and encourage
academics to share pedagogic ideas and experience?<br>
ICSP 2005
</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">Learning and Teaching</a> <strong>|</strong>   Comments Off</p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-23"><a href="blog.html">Invited paper: The Net and Higher Education - David Dolowitz</a></h2>
				<small>June 20th, 2005 <!-- by ddolowitz --></small>
				
				<div class="entry">
					<p>Since
the rise of windows based software and interactive Internet technology
professors have integrated e-learning into their teaching practices.
This is true whether they have involved the use of web-based virtual
learning environments (VLE’s), such as <em>Blackboard</em> and <em>Web CT</em>,
or the placement of specific website information in course syllabi and
handouts. Simultaneously, students (particularly those seeing
themselves as <em>information literate</em>) have responded by relying
on e-technologies for an increasing amount of information. However, as
many of us can attest to, this information is often of the ‘lowest
common denominator’, is poorly used, often involves some degree of
plagiarism, and when not plagiarised electronic information is seldom
evaluated for quality, accuracy or relevance. This is starting to leave
the impression amongst many professors that while students can access
e-technology many are in the dark when it comes to knowing when and how
to use these technologies to enhance their learning experiences. </p>
<p>I suggest that if students are going to maximise the opportunities
presented by e-technologies they are going to need guidance. For this
to happen, two sub-processes will need to take place. First, students
are going to have to be convinced that they do not enter higher
education knowing everything there is to know about e-learning, its
web-based processes, and how these can best be used in conjunction with
traditional research tools and techniques. Second, as a profession we
are going to have to develop our own teaching and learning strategies
(and expectations) in order to guide students through an <em>active</em> and <em>appropriate</em> engagement with the <em>academic</em>
side of the e-learning, including making the appropriate and accurate
use of electronically gathered information part of the overall
assessment process. </p>
<p>To be precise, the effective use of the e-learning environment will
require more than the use of VLE software. While these packages can be
useful tools, when used in unreflective ways (by either the professor
or the student) signs are emerging that they tend to undermine the
reflective learning processes involved in the higher learning and
thinking processes, especially those expected of third and fourth year
students. For instance, a small scale study at the University of
Liverpool found that when <em>Blackboard</em> was used to make
syllabuses, lecture notes and handouts available to students at any
time, not only did attendance at lectures and classes fall but it was
also discovered that an increasing amount of class discussion, essay
material, and exam information was drawn directly from the resources
placed into the VLE. Thus, instead of using the VLE to supplement their
own research (as intended); students were using the information to
replace independent initiatives. On the other hand, evidence also
emerged to suggest that when the VLE was used to supplement lecture
material though: weekly assignments and practice exercises, and the
creation of informal discussion groups; the quality of submitted work,
attendance, and the quality of class contributions tended to improve.</p>
<p>While many lecturers consider e-learning in the context of VLE
packages in actuality the largest standalone tool within the e-learning
environment is the Internet. As with VLE’s instructors wanting their
students to use the Net wisely should consider how they can encourage
their students to view the Net: first, as a <em>toolkit</em> containing a number of different <em>tools</em>, each capable of a different task (more or less appropriate for the job at hand); and second, a <em>toolkit</em>
which should primarily be used in conjunction with more traditional
resource, not as a replacement tool (particularly for those
institutions with exceptional research facilities and resources). </p>
<p>This will likely require a serious consideration of how and why any
given instructor (or department) wants students to use the Net, the
academic level of the course involved, and which online resource/s will
be best suited to the learning tasks being undertaken. In this, a
minimum of three issues should be considered: 1) how, given the level
(first year vs. senior level), needs (quantitative data vs.
qualitative, writing vs. oral, project vs. paper, individual vs. group,
etc.), course material and structure, can online resources be most
effectively combined with more traditional offline resources to
maximise student understanding and performance while undertaking the
learning task being assessed; 2) given the learning task and the level
of academic competence students are expected demonstrate, which online
tools and resources will be appropriate; 3) how can the resources
available via the Net be used to improve the overall quality of the
student learning experience – particularly in light of available
offline resources. </p>
<p>In addition, many of our students are also going to have to receive
some form of guidance as to the appropriate ways of mixing traditional
and non-traditional resources in the completion of their research
assignments. At its most basic instructors should consider how they can
help their students know 1) when it is more or less appropriate to use
the Internet 2) which online tools are most likely to provide the best
returns in light of the task involved 3) how to evaluate the validity,
reliability, and accuracy of information 4) and how to deal with the
ethical issues that will emerge in relation to the information
accessed, how it is used, what is stored, and how much (or how many
copies) is stored. </p>
<p>Overall, the key will be to help students know <em>how</em>, <em>when</em> and <em>why</em>
they should use the Net in light of course requirements, the stage of
academic development expected of the student, and the type of skills
they are expected to have acquired and demonstrated by the end of their
module. In parting it is best to see the Net as having tools linked to
advanced and introductory texts. Thus just as advanced research texts
are almost useless to students just beginning to explore a subject,
search engines are next to useless for students who don’t know anything
about the topic they are investigating. However, just as introductory
texts have been written to guide students through the basics of a
topic, many subject directories have been develop so as to introduce
individuals to a subject area, and are thus better suited to first year
students than to final year students who have already attained an
advanced understanding of a topic. </p>
<p>_________________________________________________________________</p>
<p>Dr. Dolowitz is a Reader in the School of Politics and Communication
Studies, University of Liverpool. In addition to his research into
policy transfer and the ideological underpinnings of New Labour he is
actively involved in researching and writing about the different ways
the Internet can be utilised in the teaching and learning process.
</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">5 Comments »</a></p> 
				

			</div>
	
						
			<div class="post">
				<h2 id="post-26"><a href="blog.html">Invited paper: What are the potential uses of Blogs in Teaching and Learning? - Andy Ramsden</a></h2>
				<small>June 20th, 2005 <!-- by aramsden --></small>
				
				<div class="entry">
					<p>I
intend to answer this question through mulling over some aspects of
blogs and encourage you the community, to collectively answer the
question. So I’m hoping that we all engage with the discussion.</p>
<p>The first step is to outline the background to the discussion. I’m
not going to address “what is a blog?” as this is well documented on
the web. Instead I’ll discuss the rapid emergence of the blogosphere –
the collective term covering all weblogs - and the increased interest
in educational circles of the educational potential of blogs.</p>
<p>A Blog as a potential learning technology is both a relatively
recent phenomenon and very dynamic. Blogs emerged in the late 1990’s
and the activity of blogging – keeping a blog - has grown rapidly
since. For instance, at the start of 1999 there where only 23 known web
logs (Blood (2000), <a href="http://www.rebeccablood.net/essays/weblog_history.html">http://www.rebeccablood.net/essays/weblog_history.html</a>).
However, by the end of 2005 it is estimated that there will be 53.4
million blogs (Perseus Blog Survey (2005)
http://www.perseus.com/blogsurvey/geyser.html). We must all agree, an
incredible growth in use over 6 years.</p>
<p>This rapid growth in the blogosphere, has transferred to the
educational sector. An indicator of this is the emergence of academic
research on the use of Blogs within the literature (see Williams J. B.
and Jacobs J (2004), <a href="http://www.ascilite.org.au/ajet/ajet20/williams.html">http://www.ascilite.org.au/ajet/ajet20/williams.html</a>), and the establishment of blogs on how to use blogs in education (for example, Weblogs in Higher Education <a href="http://www.mchron.net/site/edublog.php">http://www.mchron.net/site/edublog.php</a>)</p>
<p>Most authors refer to the following key drivers for the use of Blogs as a learning technology.</p>
<ul>
<li>Ease of use where the author can publish to the web without using any programming code</li>
<li>No need for installing any server software on the users machine</li>
<li>The user has extensive control over how their blog looks and operates</li>
<li>Whenever the user edits his or her blog the results are instantly updated and available to others</li>
<li>Like any other website, blogs can be simply linked and navigated</li>
</ul>
<p>- Lamshed, Berry &amp; Armstrong (2002) <a href="http://www.binaryblue.com/au/docs/blogs.pdf">http://www.binaryblue.com/au/docs/blogs.pdf</a> </p>
<p>In others words, they are </p>
<ul>
<li>simple to use</li>
<li>offer instant gratification</li>
<li>are customisable.</li>
</ul>
<p>So how can blogs be used in teaching and learning? This can be
addressed by discussing in terms of learning models, and through some
practical examples. </p>
<p>The educational value of blogs is discussed by Ferdig &amp; Trammel (2004) (<a href="http://www.thejournal.com/magazine/vault/articleprintversion.cfm?aid=4677">http://www.thejournal.com/magazine/vault/articleprintversion.cfm?aid=4677</a>)
and nicely summed up by William and Jacobs (2004) as “the discursive
nature of knowledge construction is best addressed by the immediacy and
commentary based system of blogging … there will be a natural tendency
for refection and analysis on the part of the student, given feedback
systems are integral to the blogging interface, but also … the
contextualisation of learning through hypertext links … encourages
revisiting and revising of learned concepts, enriching the learning
experience”</p>
<p>This chain of thought is strongly associated with constructivist
learning theories of Vygotsky (social) and Piaget (cognitive). Where
the characteristics of this social software – the low threshold for
publishing – encourages a collaborative, student centred approach which
is both “involving and evolving” for the participants (I’d like to
credit to Dan Sutch, Futurelab, for this term).</p>
<p>However, the constructivist model is not the only one which can be
effectively employed by Blogging. When and where appropriate there is
the potential for the behaviourist model. Again the low threshold for
publishing means that lecturers can easily filter and publish
information. The filter style of blogging is where “the author filters
a mass of information available online and makes available on their
site what they consider to be the most useful, interesting or important
for their audience” Lamshed, Berry &amp; Armstrong (2002)<br>
<a href="http://www.binaryblue.com/au/docs/blogs.pdf">http://www.binaryblue.com/au/docs/blogs.pdf</a></p>
<p>In moving from the learning model (abstract) to potential practical uses a good starting point is Scott’s (2003) (<a href="http://www.edtechpost.ca/gems/matrix2.gif">http://www.edtechpost.ca/gems/matrix2.gif</a>) “Blogs in Education” matrix. </p>
<p>The matrix is based upon who reads and who writes the blog, in terms
of the student or the instructor, and incorporates the idea of the
intended audience. Scott’s (2003) matrix suggests that the potential
use for academics tends to be narrowly focused on the course blog of
administration and links or maintaining a blog for their own
professional practice, networking and personal knowledge sharing. The
uses by students in terms of writing are more innovative, incorporating
a personal reflection tool and knowledge management, to a group
collaboration tool. The practical applications for students are much
broader and cover all aspects of learning and assessment.</p>
<p>I’d suggest a limitation is the matrix doesn’t capture the dynamic
nature associated with blogs as learning technology. In particular, the
conversational nature of blogs, with integral feedback mechanisms that
foster communication and social networks. As Scott admits it was
developed with a formal educational structure in mind (<a href="http://www.edtechpost.ca/mt/archive/000393.html">http://www.edtechpost.ca/mt/archive/000393.html</a>). That said it is still a very useful way of mapping educational uses to tasks.</p>
<p>Given the exponential growth of blogs, and the wide range of
potential uses, I’d like to discuss one blog in particular, and then
raise some questions that can be used to facilitate further discussion.</p>
<p>The blog of interest is Dr Tufte’s Economics Classes Blog (<a href="http://econtufte.blogspot.com/">http://econtufte.blogspot.com/</a>).
I’ve chosen this blog not because it is an exemplar in all areas, but
because I think it does demonstrate some of the issues of using this
technology.</p>
<p>The blog contains posts and comments written by students in Dr.
Tufte’s economics classes at Southern Utah University. The most recent
posts is concerned with the price of gas. There were 7 comments which
included contributions by Dr Tufte. Admittedly, the context of use is
unknown, in terms of the aims of the blog, student numbers and
motivation. However, some observations can be made;</p>
<p>1. It is a collaborative blog, where students author on one blog.
This should enhance critical thinking skills, as the students need to
carefully formulate and articulate opinions with the awareness that
they are read by their peers.</p>
<p>2. There seems to be regular contributions and comments by students,
and the inclusion of links within contributions. This should be
facilitating the social construction of knowledge.</p>
<p>3. It is easy to set up and should be relatively well embedded
within the teaching. The link between the curriculum and the “real
world” has the potential for enhancing student motivation (see<br>
<a href="http://www.mobile-learning.blog-city.com/a_theoretical_basis_for_why_lecturers_should_podcast.htm">http://www.mobile-learning.blog-city.com/a_theoretical_basis_for_why_lecturers_should_podcast.htm</a> which develops this chain of thought for podcasting). </p>
<p>4. However, when you start to analyse the contributions then
questions are raised about the role of the moderator. What role should
the instructor play? Are some of the moderators’ comments inhibiting
further discussion? What strategies need to be adopted to enhance
interactivity?</p>
<p>My concluding remarks are that blogs offer considerable potential as
a learning technology. However, this technology is still relatively
new. So some questions, which I’d like to raise for you, the reader,
are;</p>
<p>1. Have you used Blogs in your teaching or learning? If so, how would you summarise the experience?</p>
<p>2. Do you have any anxieties about using Blogs within teaching and learning?</p>
<p>3. How do you think blogs can be effectively used in teaching and
learning? Are they suited to specific tasks/disciplines, or are they
transferable across all areas? </p>
<p>___________________________________________________________________<br>
Andy Ramsden is a Learning Technology Adviser, with the Learning Technology Support Service (<a href="http://www.ltss.bris.ac.uk/">http://www.ltss.bris.ac.uk</a>)
at the University of Bristol. He also lecturers on a masters programme
in the Graduate School of Education. His particular research interests
include blogs, podcasts and mobile learning (<a href="http://www.mobile-learning.blog-city.com/">http://www.mobile-learning.blog-city.com</a>).
</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">10 Comments »</a></p> 
				
>
			</div>
	
						
			<div class="post">
				<h2 id="post-25"><a href="blog.html">Invited paper: Using online learning resources in business and economics education - Andrew Ashwin &amp; Kieren Pitts</a></h2>
				<small>June 20th, 2005 <!-- by bized --></small>
				
				<div class="entry">
					<p>The
subject matter of business and economics changes rapidly and those
engaged in the teaching and learning process require up to date and
relevant materials that are both challenging accurate and interactive.
There is an increasing emphasis in the 16 - 19 age bracket on
vocational learning and at higher education on the flexible design of
learning materials. Biz/ed is a unique online learning resource for
students and lecturers in further and higher education in business and
economics and related subjects. Biz/ed is a JISC service and is working
towards developing resources that meet these different needs as well as
providing resources for traditional ‘academic’ courses. </p>
<p>A key aspect of this work is how learners access and use the
resources available. In some cases, the student will be using an
interactive model or simulation such as the Virtual Economy not only to
access information but to explore the impact on economic and
non-economic objectives of the learners’ changes to government fiscal
policy. In other cases the learner might be presented with a series of
Macromedia Flash based animations illustrating a particular concept or
set of relationships and the opportunity is presented for the student
to explore some of these relationships in a non-threatening environment
to build understanding. </p>
<p>The requirement for almost real time resources does mean that the
possibilities for online interactive learning resources are likely to
expand. Resources are capable of being used not only for traditional
classroom-based learning environments but also increasingly for
distance learning and e-learning courses and for use within virtual
learning environments.</p>
<p>In the future, a far greater degree of interaction and
sophistication in the design and development of online resources will
be necessary. Such developments will involve a variety of different
media types including streamed video and the level of interaction will
be likely to increase from the simple ‘drag and drop’ scenario that
characterises some ‘interactive’ resources to a more experimental
approach which involves the user making decisions that have different
outcomes and which provide the basis for further decision making.</p>
<p>The challenge for educators and resource providers is to identify
and explore different ways of encouraging deep approaches to learning.
We believe that deep learning can be encouraged through the appropriate
design of resources that encourage students to become involved in the
subject. Resource design should be based on the principle that students
come to the subject having some existing knowledge and awareness.
Resources should attempts to tap into that existing knowledge, present
new challenges and perspectives to internalise new concepts that help
the student to come to a better understanding of what it means to
‘think in the subject’. By this we mean the skills, attitudes,
knowledge, approach and methods that are adopted by economists and
business students to tackle problems and issues. Those who exhibit deep
learning are able to take the concepts and methods of the subject
therefore and apply these to new situations and problems and be able to
demonstrate an understanding of the whole, yet see the relationship and
relevance of the parts, in contributing to that understanding. </p>
<p>Deep learning also helps students see issues from a new changed
perspective; they have, to all intents and purposes broken through a
portal that provides a new understanding of the subject. This new
understanding involves changed assumptions and a belief in the nature
of reality as it applies to that subject.</p>
<p>To develop resources that meet such lofty ideals presents a massive
challenge. There are numerous constraints relating to such resource
development – inertia on the part of education, technological
constraints, time and financial constraints, resource access and the
limitations of an online medium in delivering the varied and
challenging resources that are necessary to help build deep learning.</p>
<p>Online mediums however also present huge possibilities. The
potential to access a range of information and data and to share that
data has never been greater; the technologies for providing high
quality graphics, animations and video content is improving both in
quality and access and the challenge for Biz/ed is to take the
technology and work with the limitations to achieve an improvement in
the quality of resources that lead to improvements in the quality of
learning outcome for end users.<br>
________________________________________________________<br>
<strong>Questions</strong><br>
Is simplicity or sophistication the way forward for interactive learning resources?</p>
<p>Do learning objects form the basis of what lecturers are looking for
in developing learning resources or should providers such as Biz/ed
focus on producing complete games/simulations? </p>
<p>_________________________________________________________________</p>
<p><strong>Andrew Ashwin - Content Developer</strong><br>
Andrew joined Biz/ed in May 2003 as a content developer with
responsibility for the overall academic direction of the site. Since
joining, Andrew has produced a wide range of resources and been
instrumental in changing the look and feel of the site and in helping
to further its relevance and dynamism.</p>
<p>Andrew has a BEd in History and a Diploma in Economics from the
University of London and followed this with a preliminary year of an
MSc in Economics at Birkbeck College and an MBA in International
Educational Leadership at the University of Hull, gained in 2002. He
also holds a Diploma in Performance Coaching. He has taught economics
and business studies, as well as history, in schools and colleges to
all ages since 1979. </p>
<p>Andrew is an experienced examiner and moderator in both A level
economics and economics and business courses and was Principal Examiner
for the new Business and Economics (Nuffield) GCSE course launched in
1994. Andrew is now Chief Examiner for this course and is involved in
further curriculum development in this area.</p>
<p>Andrew has an interest in learning styles and concept acquisition
and is pursuing a PhD at the University of Birmingham in this area. He
has used his experience and knowledge in education and in pedagogy to
provide a coherent and clear philosophy behind the academic direction
of the resources produced by Biz/ed. In particular, Andrew believes in
the importance of providing resources that add value to the educator
and student and to this end is keen to ensure that the student is able
to engage in the resources produced. </p>
<p>Andrew has presented papers at a number of conferences on the
pedagogy behind Biz/ed’s work and has written articles for the Journal
of the Economics and Business Education Association. Andrew also wrote
a chapter on e-Learning for the publication ‘Teaching and Learning in
Business Education 14 – 19’ (David Fulton publishers, 2005).</p>
<p><strong>Dr Kieren Pitts – Senior Technical Researcher</strong><br>
Kieren joined Biz/ed during June 2001, having freelanced for the ILRT
at various times since 1999. He is currently employed as a senior
technical researcher for Biz/ed. His principal responsibility is
undertaking or co-ordinating technical developments for Biz/ed.</p>
<p>Kieren has a BSc in Biological Sciences and an MSc in Biological
Research Methods, both from the University of Exeter, and a PhD in
insect ecology from the University of Bristol.</p>
<p>As principal technical innovator for Biz/ed, Kieren has continued to
work on technical innovations that improve and develop the service.
Kieren’s work has led to some interesting developments, for example a
series of six interactive simulations exploring the principles of
supply and demand. Kieren had the opportunity to present the metadata
aggregation tool at the Australasian Society for Computers In Learning
In Tertiary Education (ASCILITE) conference in December 2003 and
co-presented a paper (on online interactive simulations) at the
Educational Innovation in Economics and Business (EDiNEB) conference
during June 2004.</p>
<p>Kieren’s principal research interest concerns the use of interactive
media in education. Kieren is responsible for coordinating games and
interactive media research within the ILRT’s e-Learning group. Through
his activities as part of the e-Learning group Kieren has developed
links with other parts of the University (including the Graduate School
of Education) and other organisations within the UK.
</p>
				</div>
		
				<p class="postmetadata">Posted in <a href="blog.html">3 Comments »</a></p> 
				

			</div>
	
		
		<div class="navigation">
			<div class="alignleft"></div>
			<div class="alignright"></div>
		</div>
		
	
	</div>

	<div id="sidebar">
		<ul>
			
			<li>
				<form method="get" id="searchform" action="blog.html">
<div><input value="" name="s" id="s" type="text">
<input id="searchsubmit" value="Search" type="submit">
</div>
</form>			</li>

			<!-- Author information is disabled per default. Uncomment and fill in your details if you want to use it.
			<li><h2>Author</h2>
			<p>A little something about you, the author. Nothing lengthy, just an overview.</p>
			</li>
			-->

			<li>
						</li>

			<li class="pagenav"><h2>Help</h2><ul><li class="page_item"><a href="http://www.intute.ac.uk/socialsciences/archive/esrc_socsciweek/2005/howto.html">How to use the SOSIG Social Science Week Blog</a></li>
</ul></li>
			<li><h2>Discussion topics</h2>
				<ul>
					<li><a href="blog.html">Access to Data</a> (3)
</li>
	<li><a href="blog.html">e-Social Science</a> (3)
</li>
	<li><a href="blog.html">General comment</a> (2)
</li>
	<li><a href="blog.html">Learning and Teaching</a> (4)
</li>
	<li><a href="blog.html">Research Methods</a> (2)
</li>
				</ul>
			</li>

				<li id="linkcat-2"><h2>Links</h2>
	<ul>
<li><a href="http://www.intute.ac.uk/socialsciences/archive/esrc_socsciweek/2005/socsciweek2005.html">Social Sciences Online homepage</a></li>

	</ul>
</li>
				
			<li><h2>Account</h2>
			<ul>
								<li><a href="blog.html">Login</a></li>
			</ul>
			</li>

			<li><h2>Newsfeed links</h2>
			<ul>
               			<li><a href="blog.html">RSS 1.0</a></li>
                		<li><a href="blog.html">RSS 0.92</a></li>
			</ul>
			
		</li></ul>
	</div>



<hr>
<div id="footer">
	<p>
		Social Sciences Online is powered by 
		<a href="http://wordpress.org/">WordPress</a>
	</p>
</div>
</div>

<!-- Gorgeous design by Michael Heilemann - http://binarybonsai.com/kubrick/ -->

		

</body></html>